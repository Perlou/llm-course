# LLMå¤šæ¨¡æ€åº”ç”¨æ·±åº¦è§£æ

> ä»é›¶å¼€å§‹ï¼Œå…¨é¢ç†è§£å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹

---

## ç›®å½•

1. [ä»€ä¹ˆæ˜¯å¤šæ¨¡æ€](#1-ä»€ä¹ˆæ˜¯å¤šæ¨¡æ€)
2. [å¤šæ¨¡æ€LLMå‘å±•å†ç¨‹](#2-å¤šæ¨¡æ€llmå‘å±•å†ç¨‹)
3. [æ ¸å¿ƒæŠ€æœ¯æ¶æ„](#3-æ ¸å¿ƒæŠ€æœ¯æ¶æ„)
4. [ä¸»æµå¤šæ¨¡æ€æ¨¡å‹](#4-ä¸»æµå¤šæ¨¡æ€æ¨¡å‹)
5. [æŠ€æœ¯å®ç°è¯¦è§£](#5-æŠ€æœ¯å®ç°è¯¦è§£)
6. [åº”ç”¨åœºæ™¯](#6-åº”ç”¨åœºæ™¯)
7. [åŠ¨æ‰‹å®è·µ](#7-åŠ¨æ‰‹å®è·µ)
8. [æŒ‘æˆ˜ä¸æœªæ¥](#8-æŒ‘æˆ˜ä¸æœªæ¥)
9. [å­¦ä¹ èµ„æº](#9-å­¦ä¹ èµ„æº)

---

## 1. ä»€ä¹ˆæ˜¯å¤šæ¨¡æ€

### 1.1 åŸºæœ¬æ¦‚å¿µ

**æ¨¡æ€ï¼ˆModalityï¼‰** æŒ‡çš„æ˜¯ä¿¡æ¯çš„ä¸åŒå½¢å¼æˆ–ç±»å‹ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å¸¸è§æ¨¡æ€ç±»å‹                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“ æ–‡æœ¬ (Text)      - æ–‡ç« ã€å¯¹è¯ã€ä»£ç                    â”‚
â”‚  ğŸ–¼ï¸ å›¾åƒ (Image)     - ç…§ç‰‡ã€å›¾è¡¨ã€æˆªå›¾                   â”‚
â”‚  ğŸµ éŸ³é¢‘ (Audio)     - è¯­éŸ³ã€éŸ³ä¹ã€ç¯å¢ƒéŸ³                  â”‚
â”‚  ğŸ¬ è§†é¢‘ (Video)     - å½±ç‰‡ã€åŠ¨ç”»ã€å®æ—¶æµ                  â”‚
â”‚  ğŸ“Š ç»“æ„åŒ–æ•°æ®       - è¡¨æ ¼ã€å›¾è°±ã€æ•°æ®åº“                  â”‚
â”‚  ğŸ® 3D/ç©ºé—´æ•°æ®      - ç‚¹äº‘ã€3Dæ¨¡å‹ã€æ·±åº¦å›¾                â”‚
â”‚  ğŸ¤š è§¦è§‰/ä¼ æ„Ÿå™¨      - æ¸©åº¦ã€å‹åŠ›ã€è¿åŠ¨æ•°æ®                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 å¤šæ¨¡æ€ vs å•æ¨¡æ€

```
å•æ¨¡æ€ LLM:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ–‡æœ¬   â”‚ â”€â”€â–º â”‚   LLM   â”‚ â”€â”€â–º â”‚  æ–‡æœ¬   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å¤šæ¨¡æ€ LLM:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ–‡æœ¬   â”‚â”€â”€â”
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å›¾åƒ   â”‚â”€â”€â”¼â”€â–º â”‚  MLLM   â”‚ â”€â”€â–º â”‚ æ–‡æœ¬/   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ å›¾åƒ... â”‚
â”‚  éŸ³é¢‘   â”‚â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 ä¸ºä»€ä¹ˆéœ€è¦å¤šæ¨¡æ€ï¼Ÿ

| ç»´åº¦           | å•æ¨¡æ€é™åˆ¶       | å¤šæ¨¡æ€ä¼˜åŠ¿               |
| -------------- | ---------------- | ------------------------ |
| **ä¿¡æ¯å®Œæ•´æ€§** | åªèƒ½å¤„ç†æ–‡å­—æè¿° | ç›´æ¥ç†è§£å›¾åƒã€è§†é¢‘å†…å®¹   |
| **äº¤äº’è‡ªç„¶æ€§** | åªèƒ½æ‰“å­—è¾“å…¥     | æ”¯æŒè¯­éŸ³ã€å›¾ç‰‡ç­‰è‡ªç„¶äº¤äº’ |
| **ä»»åŠ¡è¦†ç›–**   | å±€é™äºæ–‡æœ¬ä»»åŠ¡   | å›¾æ–‡é—®ç­”ã€è§†é¢‘ç†è§£ç­‰     |
| **çœŸå®ä¸–ç•Œ**   | ä¸ç‰©ç†ä¸–ç•Œè„±èŠ‚   | å¯è¿æ¥ä¼ æ„Ÿå™¨ã€æœºå™¨äºº     |

---

## 2. å¤šæ¨¡æ€LLMå‘å±•å†ç¨‹

### 2.1 å‘å±•æ—¶é—´çº¿

```
2020 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º 2025

   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2021.01      â”‚
â”‚ CLIP/DALL-E  â”‚  OpenAIå¼€åˆ›æ€§å·¥ä½œ
â”‚ å›¾æ–‡å¯¹é½     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 2022.04      â”‚
   â”‚ Flamingo     â”‚  DeepMind å°‘æ ·æœ¬å¤šæ¨¡æ€
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 2023.03      â”‚
        â”‚ GPT-4V       â”‚  å¼ºå¤§çš„è§†è§‰ç†è§£
        â”‚ LLaVA        â”‚  å¼€æºè§†è§‰è¯­è¨€æ¨¡å‹
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚ 2023.09      â”‚
             â”‚ Qwen-VL      â”‚  é˜¿é‡Œå¤šæ¨¡æ€ç³»åˆ—
             â”‚ InternVL     â”‚  å•†æ±¤ä¹¦ç”Ÿç³»åˆ—
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ 2024-2025    â”‚
                  â”‚ GPT-4o       â”‚  åŸç”Ÿå¤šæ¨¡æ€
                  â”‚ Gemini 2.0   â”‚  å…¨æ¨¡æ€ç†è§£ç”Ÿæˆ
                  â”‚ Claude 3.5   â”‚  å¼ºè§†è§‰ç†è§£
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æŠ€æœ¯æ¼”è¿›è·¯çº¿

```
ç¬¬ä¸€é˜¶æ®µï¼šå›¾æ–‡å¯¹é½ (Contrastive Learning)
â”œâ”€â”€ CLIP: å¯¹æ¯”å­¦ä¹ å¯¹é½å›¾æ–‡ç©ºé—´
â”œâ”€â”€ ALIGN: æ›´å¤§è§„æ¨¡æ•°æ®è®­ç»ƒ
â””â”€â”€ æ ¸å¿ƒï¼šå­¦ä¹ å›¾åƒå’Œæ–‡æœ¬çš„å…±äº«è¡¨ç¤º

ç¬¬äºŒé˜¶æ®µï¼šLLM + Vision Encoder (è¿æ¥å™¨æ–¹æ³•)
â”œâ”€â”€ Flamingo: é€šè¿‡Gated Cross-Attentionè¿æ¥
â”œâ”€â”€ BLIP-2: Q-Formerä½œä¸ºæ¡¥æ¢
â”œâ”€â”€ LLaVA: ç®€å•çº¿æ€§æŠ•å½±å±‚
â””â”€â”€ æ ¸å¿ƒï¼šåˆ©ç”¨é¢„è®­ç»ƒLLMçš„å¼ºå¤§èƒ½åŠ›

ç¬¬ä¸‰é˜¶æ®µï¼šåŸç”Ÿå¤šæ¨¡æ€ (Native Multimodal)
â”œâ”€â”€ GPT-4o: ç«¯åˆ°ç«¯å¤šæ¨¡æ€è®­ç»ƒ
â”œâ”€â”€ Gemini: ä»å¤´è®­ç»ƒçš„å¤šæ¨¡æ€æ¨¡å‹
â””â”€â”€ æ ¸å¿ƒï¼šç»Ÿä¸€æ¶æ„å¤„ç†æ‰€æœ‰æ¨¡æ€
```

---

## 3. æ ¸å¿ƒæŠ€æœ¯æ¶æ„

### 3.1 å…¸å‹æ¶æ„æ€»è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å¤šæ¨¡æ€LLMé€šç”¨æ¶æ„                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  è¾“å…¥    â”‚    â”‚ æ¨¡æ€ç¼–ç å™¨â”‚    â”‚  å¯¹é½/   â”‚    â”‚   LLM    â”‚  â”‚
â”‚  â”‚  æ¨¡æ€    â”‚â”€â”€â”€â–ºâ”‚ Encoders â”‚â”€â”€â”€â–ºâ”‚  èåˆå±‚  â”‚â”€â”€â”€â–ºâ”‚ Backbone â”‚  â”‚
â”‚  â”‚          â”‚    â”‚          â”‚    â”‚          â”‚    â”‚          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚                                                  â”‚      â”‚
â”‚       â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚      â”‚
â”‚       â”‚              â”‚      å¯é€‰ï¼šè§£ç å™¨         â”‚        â”‚      â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   (å›¾åƒ/éŸ³é¢‘ç”Ÿæˆ)         â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 è§†è§‰ç¼–ç å™¨ (Vision Encoder)

#### ä¸»æµé€‰æ‹©

| ç¼–ç å™¨       | æ¥æº   | ç‰¹ç‚¹                | å¸¸ç”¨äº     |
| ------------ | ------ | ------------------- | ---------- |
| **ViT**      | Google | æ ‡å‡†Transformeræ¶æ„ | é€šç”¨åœºæ™¯   |
| **CLIP-ViT** | OpenAI | å›¾æ–‡å¯¹é½é¢„è®­ç»ƒ      | LLaVAç³»åˆ—  |
| **EVA-CLIP** | BAAI   | æ›´å¤§è§„æ¨¡ã€æ›´å¼ºæ€§èƒ½  | InternVL   |
| **SigLIP**   | Google | SigmoidæŸå¤±æ”¹è¿›     | PaliGemma  |
| **DINOv2**   | Meta   | è‡ªç›‘ç£å¼ºç‰¹å¾        | ç»†ç²’åº¦ä»»åŠ¡ |

#### ViTå·¥ä½œåŸç†

```
è¾“å…¥å›¾åƒ (224Ã—224Ã—3)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Patch Embedding (åˆ‡åˆ†ä¸º16Ã—16å—)     â”‚
â”‚  224/16 = 14, å¾—åˆ° 14Ã—14=196 ä¸ªpatch â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  + Position Embedding               â”‚
â”‚  + [CLS] Token                      â”‚
â”‚  å¾—åˆ° 197 Ã— 768 çš„åºåˆ—              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transformer Encoder Ã— Nå±‚          â”‚
â”‚  (Multi-Head Attention + FFN)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
    è§†è§‰ç‰¹å¾ (197 Ã— 768) æˆ– ä½¿ç”¨[CLS]
```

### 3.3 æ¨¡æ€å¯¹é½æ–¹æ³•

#### æ–¹æ³•ä¸€ï¼šçº¿æ€§æŠ•å½± (LLaVAé£æ ¼)

```python
class LinearProjector(nn.Module):
    """æœ€ç®€å•çš„å¯¹é½æ–¹å¼"""
    def __init__(self, vision_dim=1024, llm_dim=4096):
        super().__init__()
        self.proj = nn.Linear(vision_dim, llm_dim)

    def forward(self, vision_features):
        # vision_features: [batch, num_patches, vision_dim]
        return self.proj(vision_features)  # [batch, num_patches, llm_dim]
```

#### æ–¹æ³•äºŒï¼šMLPæŠ•å½±å™¨ (LLaVA-1.5)

```python
class MLPProjector(nn.Module):
    """ä¸¤å±‚MLP + GELUæ¿€æ´»"""
    def __init__(self, vision_dim=1024, llm_dim=4096):
        super().__init__()
        self.proj = nn.Sequential(
            nn.Linear(vision_dim, llm_dim),
            nn.GELU(),
            nn.Linear(llm_dim, llm_dim)
        )

    def forward(self, vision_features):
        return self.proj(vision_features)
```

#### æ–¹æ³•ä¸‰ï¼šQ-Former (BLIP-2é£æ ¼)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Q-Former æ¶æ„                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   Learned Queries        Image Features (from ViT)         â”‚
â”‚   [32 Ã— 768]              [196 Ã— 1024]                     â”‚
â”‚        â”‚                       â”‚                            â”‚
â”‚        â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚        â”‚    â”‚   Cross-Attention Layer             â”‚         â”‚
â”‚        â””â”€â”€â”€â–ºâ”‚   Q=queries, K,V=image_features     â”‚         â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                â”‚                            â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚                    â”‚  Self-Attention Layer  â”‚                â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                â”‚                            â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚                    â”‚     Feed Forward       â”‚                â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                â”‚                            â”‚
â”‚                                â–¼                            â”‚
â”‚                   Compressed Visual Tokens                  â”‚
â”‚                        [32 Ã— 768]                          â”‚
â”‚                                                             â”‚
â”‚   ä¼˜ç‚¹ï¼šå°†196ä¸ªtokenå‹ç¼©åˆ°32ä¸ªï¼Œå‡å°‘LLMè®¡ç®—é‡               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### æ–¹æ³•å››ï¼šCross-Attention (Flamingoé£æ ¼)

```python
class GatedCrossAttention(nn.Module):
    """åœ¨LLMå±‚é—´æ’å…¥äº¤å‰æ³¨æ„åŠ›"""
    def __init__(self, dim):
        super().__init__()
        self.cross_attn = nn.MultiheadAttention(dim, num_heads=8)
        self.gate = nn.Parameter(torch.zeros(1))  # åˆå§‹ä¸º0ï¼Œæ¸è¿›è®­ç»ƒ

    def forward(self, text_hidden, image_features):
        # text_hidden: LLMçš„éšè—çŠ¶æ€
        # image_features: è§†è§‰ç¼–ç å™¨è¾“å‡º
        attn_output, _ = self.cross_attn(
            query=text_hidden,
            key=image_features,
            value=image_features
        )
        return text_hidden + self.gate.tanh() * attn_output
```

### 3.4 æ¶æ„å¯¹æ¯”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ä¸‰ç§ä¸»æµæ¶æ„å¯¹æ¯”                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   æ¶æ„ç±»å‹   â”‚   ä»£è¡¨æ¨¡å‹        â”‚      ä¼˜ç‚¹        â”‚      ç¼ºç‚¹       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Early      â”‚   CLIP           â”‚  è®­ç»ƒç®€å•        â”‚  èåˆä¸æ·±å…¥     â”‚
â”‚  Fusion     â”‚   ALBEF          â”‚  æ¨¡å—åŒ–          â”‚                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Connector  â”‚   LLaVA          â”‚  åˆ©ç”¨é¢„è®­ç»ƒLLM   â”‚  è§†è§‰tokenå¤š    â”‚
â”‚  Based      â”‚   BLIP-2         â”‚  è®­ç»ƒæˆæœ¬ä½      â”‚  å¯èƒ½ä¸¢å¤±ç»†èŠ‚   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Native     â”‚   GPT-4o         â”‚  æ·±åº¦èåˆ        â”‚  è®­ç»ƒæˆæœ¬æé«˜   â”‚
â”‚  Multimodal â”‚   Gemini         â”‚  æ€§èƒ½æœ€ä¼˜        â”‚  ä»å¤´è®­ç»ƒ       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. ä¸»æµå¤šæ¨¡æ€æ¨¡å‹

### 4.1 é—­æºæ¨¡å‹

#### GPT-4V / GPT-4o (OpenAI)

```yaml
GPT-4o ç‰¹ç‚¹:
  - åŸç”Ÿå¤šæ¨¡æ€ï¼šä»å¤´è®­ç»ƒç»Ÿä¸€å¤„ç†æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘
  - å®æ—¶å¯¹è¯ï¼šæ”¯æŒè¯­éŸ³å®æ—¶äº¤äº’
  - å›¾åƒç†è§£ï¼šOCRã€å›¾è¡¨åˆ†æã€è§†è§‰æ¨ç†
  - å›¾åƒç”Ÿæˆï¼šæ”¯æŒDALL-Eé£æ ¼ç”Ÿæˆ

èƒ½åŠ›è¾¹ç•Œ: âœ… å¤æ‚è§†è§‰æ¨ç†
  âœ… å¤šå›¾å¯¹æ¯”åˆ†æ
  âœ… é•¿æ–‡æ¡£ç†è§£
  âŒ è§†é¢‘ç†è§£ï¼ˆæœ‰é™ï¼‰
  âŒ é«˜åˆ†è¾¨ç‡ç»†èŠ‚ï¼ˆæœ‰æŸå‹ç¼©ï¼‰
```

#### Claude 3.5 Sonnet (Anthropic)

```yaml
ç‰¹ç‚¹:
  - å¼ºå¤§è§†è§‰ç†è§£ï¼šå°¤å…¶æ“…é•¿æ–‡æ¡£ã€å›¾è¡¨ã€UI
  - 200Kä¸Šä¸‹æ–‡ï¼šå¯å¤„ç†å¤§é‡å›¾ç‰‡
  - ä»£ç ç”Ÿæˆï¼šæ ¹æ®è®¾è®¡å›¾ç”Ÿæˆä»£ç 

æœ€ä½³åœºæ™¯:
  - æŠ€æœ¯æ–‡æ¡£ç†è§£
  - æ•°æ®å¯è§†åŒ–åˆ†æ
  - UI/UXè®¾è®¡è½¬ä»£ç 
```

#### Gemini ç³»åˆ— (Google)

```yaml
Gemini 2.0 ç‰¹ç‚¹:
  - å…¨æ¨¡æ€åŸç”Ÿï¼šæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘
  - é•¿ä¸Šä¸‹æ–‡ï¼š100ä¸‡+ tokens
  - è§†é¢‘ç†è§£ï¼šå¯åˆ†æé•¿è§†é¢‘
  - ä»£ç æ‰§è¡Œï¼šå†…ç½®Pythonè§£é‡Šå™¨

ç‰ˆæœ¬å¯¹æ¯”:
  Flash: å¿«é€Ÿæ¨ç†ï¼Œé€‚åˆå®æ—¶åœºæ™¯
  Pro: å¹³è¡¡æ€§èƒ½ä¸æˆæœ¬
  Ultra: æœ€å¼ºèƒ½åŠ›ï¼Œå¤æ‚æ¨ç†
```

### 4.2 å¼€æºæ¨¡å‹

#### LLaVA ç³»åˆ—

```
æ¼”è¿›è·¯çº¿:
LLaVA (2023.04)
    â”œâ”€â”€ æ¶æ„ï¼šCLIP-ViT + Linear + Vicuna
    â””â”€â”€ åˆ›æ–°ï¼šè§†è§‰æŒ‡ä»¤å¾®è°ƒ
         â”‚
         â–¼
LLaVA-1.5 (2023.10)
    â”œâ”€â”€ æ”¹è¿›ï¼šMLPæŠ•å½±å™¨ + æ›´é«˜åˆ†è¾¨ç‡(336px)
    â””â”€â”€ æ•ˆæœï¼šæ€§èƒ½å¤§å¹…æå‡
         â”‚
         â–¼
LLaVA-NeXT (2024)
    â”œâ”€â”€ æ”¹è¿›ï¼šåŠ¨æ€åˆ†è¾¨ç‡ + AnyResæŠ€æœ¯
    â””â”€â”€ æ•ˆæœï¼šæ”¯æŒä¸åŒå°ºå¯¸å›¾ç‰‡
         â”‚
         â–¼
LLaVA-OneVision (2024)
    â”œâ”€â”€ æ”¹è¿›ï¼šç»Ÿä¸€å›¾åƒã€è§†é¢‘ç†è§£
    â””â”€â”€ æ•ˆæœï¼šå•æ¨¡å‹å¤šä»»åŠ¡
```

#### Qwen-VL ç³»åˆ— (é˜¿é‡Œ)

```yaml
Qwen2-VL ç‰¹ç‚¹:
  - åŠ¨æ€åˆ†è¾¨ç‡ï¼šNaive Dynamic Resolution
  - M-RoPEï¼šå¤šæ¨¡æ€æ—‹è½¬ä½ç½®ç¼–ç 
  - è§†é¢‘ç†è§£ï¼šåŸç”Ÿæ”¯æŒé•¿è§†é¢‘
  - å¤šè¯­è¨€ï¼šä¸­è‹±æ–‡åŒè¯­å¼ºå¤§

å‚æ•°è§„æ¨¡:
  - Qwen2-VL-2B: è½»é‡éƒ¨ç½²
  - Qwen2-VL-7B: å¹³è¡¡ä¹‹é€‰
  - Qwen2-VL-72B: æœ€å¼ºæ€§èƒ½
```

#### InternVL ç³»åˆ— (ä¹¦ç”Ÿ)

```yaml
InternVL2 ç‰¹ç‚¹:
  - å¼ºå¤§è§†è§‰ç¼–ç å™¨ï¼šInternViT-6B
  - å¤šè§„æ¨¡ç‰ˆæœ¬ï¼š1Båˆ°108B
  - åŠ¨æ€åˆ†è¾¨ç‡ï¼šæ”¯æŒ4Ké«˜æ¸…
  - ä¸­æ–‡ä¼˜åŒ–ï¼šä¸­æ–‡åœºæ™¯è¡¨ç°ä¼˜ç§€
```

### 4.3 æ¨¡å‹æ€§èƒ½å¯¹æ¯”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ä¸»æµæ¨¡å‹èƒ½åŠ›å¯¹æ¯” (2024.12)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     æ¨¡å‹        â”‚ å›¾åƒQA â”‚ OCR    â”‚ å›¾è¡¨   â”‚ è§†é¢‘   â”‚ å¤šå›¾æ¨ç†   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ GPT-4o          â”‚ â˜…â˜…â˜…â˜…â˜… â”‚ â˜…â˜…â˜…â˜…â˜… â”‚ â˜…â˜…â˜…â˜…â˜… â”‚ â˜…â˜…â˜…â˜†  â”‚ â˜…â˜…â˜…â˜…â˜…     â”‚
â”‚ Claude 3.5      â”‚ â˜…â˜…â˜…â˜…â˜… â”‚ â˜…â˜…â˜…â˜…â˜… â”‚ â˜…â˜…â˜…â˜…â˜… â”‚ â˜…â˜…â˜†   â”‚ â˜…â˜…â˜…â˜…â˜…     â”‚
â”‚ Gemini 2.0      â”‚ â˜…â˜…â˜…â˜…â˜… â”‚ â˜…â˜…â˜…â˜…â˜† â”‚ â˜…â˜…â˜…â˜…â˜† â”‚ â˜…â˜…â˜…â˜…â˜… â”‚ â˜…â˜…â˜…â˜…â˜†     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Qwen2-VL-72B    â”‚ â˜…â˜…â˜…â˜…â˜† â”‚ â˜…â˜…â˜…â˜…â˜… â”‚ â˜…â˜…â˜…â˜…â˜† â”‚ â˜…â˜…â˜…â˜…â˜† â”‚ â˜…â˜…â˜…â˜…â˜†     â”‚
â”‚ InternVL2-76B   â”‚ â˜…â˜…â˜…â˜…â˜† â”‚ â˜…â˜…â˜…â˜…â˜† â”‚ â˜…â˜…â˜…â˜…â˜† â”‚ â˜…â˜…â˜…â˜†  â”‚ â˜…â˜…â˜…â˜…â˜†     â”‚
â”‚ LLaVA-OneVision â”‚ â˜…â˜…â˜…â˜…â˜† â”‚ â˜…â˜…â˜…â˜†  â”‚ â˜…â˜…â˜…â˜†  â”‚ â˜…â˜…â˜…â˜…â˜† â”‚ â˜…â˜…â˜…â˜†      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. æŠ€æœ¯å®ç°è¯¦è§£

### 5.1 è®­ç»ƒæµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      å¤šæ¨¡æ€LLMè®­ç»ƒä¸‰é˜¶æ®µ                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  é˜¶æ®µ1: é¢„è®­ç»ƒå¯¹é½ (Pretrain Alignment)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ç›®æ ‡ï¼šå­¦ä¹ è§†è§‰-æ–‡æœ¬æ˜ å°„                                      â”‚   â”‚
â”‚  â”‚  æ•°æ®ï¼šå¤§è§„æ¨¡å›¾æ–‡å¯¹ (CC3M, LAIONç­‰)                           â”‚   â”‚
â”‚  â”‚  è®­ç»ƒï¼šåªè®­ç»ƒæŠ•å½±å±‚ï¼Œå†»ç»“Vision Encoderå’ŒLLM                  â”‚   â”‚
â”‚  â”‚  Lossï¼šä¸‹ä¸€ä¸ªtokené¢„æµ‹                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                      â”‚
â”‚                              â–¼                                      â”‚
â”‚  é˜¶æ®µ2: æŒ‡ä»¤å¾®è°ƒ (Instruction Tuning)                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ç›®æ ‡ï¼šå­¦ä¹ éµå¾ªå¤šæ¨¡æ€æŒ‡ä»¤                                     â”‚   â”‚
â”‚  â”‚  æ•°æ®ï¼šè§†è§‰æŒ‡ä»¤æ•°æ®é›† (LLaVA-Instruct, ShareGPT4Vç­‰)          â”‚   â”‚
â”‚  â”‚  è®­ç»ƒï¼šè®­ç»ƒæŠ•å½±å±‚ + LLM (å¯é€‰LoRA)                            â”‚   â”‚
â”‚  â”‚  Lossï¼šä¸‹ä¸€ä¸ªtokené¢„æµ‹                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                      â”‚
â”‚                              â–¼                                      â”‚
â”‚  é˜¶æ®µ3: åå¥½ä¼˜åŒ– (å¯é€‰)                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ç›®æ ‡ï¼šå¯¹é½äººç±»åå¥½ï¼Œå‡å°‘å¹»è§‰                                  â”‚   â”‚
â”‚  â”‚  æ–¹æ³•ï¼šRLHF / DPO / RLAIF                                     â”‚   â”‚
â”‚  â”‚  æ•°æ®ï¼šåå¥½å¯¹æ¯”æ•°æ®                                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 æ•°æ®æ ¼å¼

#### å¯¹è¯æ ¼å¼ç¤ºä¾‹

```json
{
  "id": "000001",
  "image": "images/example.jpg",
  "conversations": [
    {
      "from": "human",
      "value": "<image>\nè¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆï¼Ÿ"
    },
    {
      "from": "gpt",
      "value": "è¿™å¼ å›¾ç‰‡å±•ç¤ºäº†ä¸€åªæ©˜è‰²çš„çŒ«æ­£åœ¨é˜³å…‰ä¸‹çš„çª—å°ä¸Šæ‰“ç›¹..."
    },
    {
      "from": "human",
      "value": "çŒ«çœ‹èµ·æ¥æ˜¯ä»€ä¹ˆå“ç§ï¼Ÿ"
    },
    {
      "from": "gpt",
      "value": "ä»å›¾ç‰‡æ¥çœ‹ï¼Œè¿™å¯èƒ½æ˜¯ä¸€åªè‹±å›½çŸ­æ¯›çŒ«..."
    }
  ]
}
```

#### å¤šå›¾å¯¹è¯

```json
{
  "id": "000002",
  "images": ["img1.jpg", "img2.jpg"],
  "conversations": [
    {
      "from": "human",
      "value": "<image> <image>\nè¯·æ¯”è¾ƒè¿™ä¸¤å¼ å›¾ç‰‡çš„åŒºåˆ«"
    },
    {
      "from": "gpt",
      "value": "è¿™ä¸¤å¼ å›¾ç‰‡çš„ä¸»è¦åŒºåˆ«åœ¨äº..."
    }
  ]
}
```

### 5.3 æ¨ç†æµç¨‹

```python
# ç®€åŒ–çš„æ¨ç†æµç¨‹ä¼ªä»£ç 

class MultimodalLLM:
    def __init__(self):
        self.vision_encoder = load_vision_encoder()  # å¦‚ CLIP-ViT
        self.projector = load_projector()            # å¦‚ MLP
        self.llm = load_llm()                        # å¦‚ Qwen2
        self.tokenizer = load_tokenizer()

    def encode_image(self, image):
        """å›¾åƒç¼–ç """
        # 1. é¢„å¤„ç†å›¾åƒ
        pixel_values = preprocess(image)  # resize, normalize

        # 2. é€šè¿‡è§†è§‰ç¼–ç å™¨
        vision_features = self.vision_encoder(pixel_values)
        # shape: [1, num_patches, vision_dim] e.g., [1, 576, 1024]

        # 3. æŠ•å½±åˆ°LLMç©ºé—´
        image_embeds = self.projector(vision_features)
        # shape: [1, num_patches, llm_dim] e.g., [1, 576, 4096]

        return image_embeds

    def generate(self, image, prompt):
        """ç”Ÿæˆå›å¤"""
        # 1. ç¼–ç å›¾åƒ
        image_embeds = self.encode_image(image)

        # 2. å¤„ç†æ–‡æœ¬
        text_tokens = self.tokenizer(prompt)
        text_embeds = self.llm.embed_tokens(text_tokens)

        # 3. æ‹¼æ¥å›¾åƒå’Œæ–‡æœ¬åµŒå…¥
        # <image>å ä½ç¬¦ä½ç½®æ›¿æ¢ä¸ºimage_embeds
        input_embeds = merge_embeddings(image_embeds, text_embeds)

        # 4. LLMç”Ÿæˆ
        output = self.llm.generate(inputs_embeds=input_embeds)

        return self.tokenizer.decode(output)
```

### 5.4 åŠ¨æ€åˆ†è¾¨ç‡æŠ€æœ¯

```
ä¼ ç»Ÿæ–¹æ³•: å›ºå®šåˆ†è¾¨ç‡
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ä»»æ„å°ºå¯¸å›¾ç‰‡    â”‚ -> â”‚ å¼ºåˆ¶resizeåˆ°  â”‚ -> ä¿¡æ¯ä¸¢å¤±
â”‚  1920Ã—1080      â”‚    â”‚   336Ã—336     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

åŠ¨æ€åˆ†è¾¨ç‡ (AnyRes/NaiveDynamicRes):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1920Ã—1080      â”‚ -> â”‚ åˆ‡åˆ†ä¸ºå¤šä¸ª 336Ã—336 å°å—        â”‚
â”‚  åŸå§‹å›¾ç‰‡        â”‚    â”‚ + ä¸€ä¸ªå…¨å±€ç¼©ç•¥å›¾               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
                       â”‚ å—1 â”‚ å—2 â”‚ å—3 â”‚ å—4 â”‚  å±€éƒ¨ç»†èŠ‚
                       â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
                       â”‚ å—5 â”‚ å—6 â”‚ å—7 â”‚ å—8 â”‚
                       â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
                              +
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚     å…¨å±€ç¼©ç•¥å›¾        â”‚  æ•´ä½“è¯­ä¹‰
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. åº”ç”¨åœºæ™¯

### 6.1 åº”ç”¨å…¨æ™¯å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      å¤šæ¨¡æ€LLMåº”ç”¨åœºæ™¯                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  ğŸ“„ æ–‡æ¡£æ™ºèƒ½  â”‚  â”‚  ğŸ›’ ç”µå•†åœºæ™¯  â”‚  â”‚  ğŸ¥ åŒ»ç–—å¥åº·  â”‚              â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”‚
â”‚  â”‚ â€¢ æ–‡æ¡£é—®ç­”    â”‚  â”‚ â€¢ å•†å“ç†è§£    â”‚  â”‚ â€¢ åŒ»å­¦å½±åƒ    â”‚              â”‚
â”‚  â”‚ â€¢ è¡¨æ ¼æŠ½å–    â”‚  â”‚ â€¢ ä»¥å›¾æœå›¾    â”‚  â”‚ â€¢ ç—…å†åˆ†æ    â”‚              â”‚
â”‚  â”‚ â€¢ åˆåŒåˆ†æ    â”‚  â”‚ â€¢ ç©¿æ­æ¨è    â”‚  â”‚ â€¢ è¾…åŠ©è¯Šæ–­    â”‚              â”‚
â”‚  â”‚ â€¢ å‘ç¥¨è¯†åˆ«    â”‚  â”‚ â€¢ è¯„è®ºåˆ†æ    â”‚  â”‚ â€¢ è¯å“è¯†åˆ«    â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  ğŸš— è‡ªåŠ¨é©¾é©¶  â”‚  â”‚  ğŸ¨ åˆ›æ„è®¾è®¡  â”‚  â”‚  ğŸ“š æ•™è‚²åŸ¹è®­  â”‚              â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”‚
â”‚  â”‚ â€¢ åœºæ™¯ç†è§£    â”‚  â”‚ â€¢ è®¾è®¡ç”Ÿæˆ    â”‚  â”‚ â€¢ é¢˜ç›®è§£ç­”    â”‚              â”‚
â”‚  â”‚ â€¢ äº¤é€šæ ‡è¯†    â”‚  â”‚ â€¢ å›¾ç‰‡ç¼–è¾‘    â”‚  â”‚ â€¢ ä½œä¸šæ‰¹æ”¹    â”‚              â”‚
â”‚  â”‚ â€¢ è¡Œäººæ£€æµ‹    â”‚  â”‚ â€¢ é£æ ¼è¿ç§»    â”‚  â”‚ â€¢ å®éªŒæŒ‡å¯¼    â”‚              â”‚
â”‚  â”‚ â€¢ å†³ç­–è¾…åŠ©    â”‚  â”‚ â€¢ ç´ æåˆ›ä½œ    â”‚  â”‚ â€¢ çŸ¥è¯†é—®ç­”    â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  ğŸ¤– æœºå™¨äºº    â”‚  â”‚  ğŸ”’ å®‰é˜²ç›‘æ§  â”‚  â”‚  ğŸ® æ¸¸æˆå¨±ä¹  â”‚              â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”‚
â”‚  â”‚ â€¢ è§†è§‰å¯¼èˆª    â”‚  â”‚ â€¢ å¼‚å¸¸æ£€æµ‹    â”‚  â”‚ â€¢ NPCå¯¹è¯     â”‚              â”‚
â”‚  â”‚ â€¢ ç‰©ä½“æ“ä½œ    â”‚  â”‚ â€¢ äººè„¸è¯†åˆ«    â”‚  â”‚ â€¢ åœºæ™¯ç”Ÿæˆ    â”‚              â”‚
â”‚  â”‚ â€¢ äººæœºäº¤äº’    â”‚  â”‚ â€¢ è¡Œä¸ºåˆ†æ    â”‚  â”‚ â€¢ å‰§æƒ…åˆ›ä½œ    â”‚              â”‚
â”‚  â”‚ â€¢ ä»»åŠ¡ç†è§£    â”‚  â”‚ â€¢ äº‹ä»¶é¢„è­¦    â”‚  â”‚ â€¢ è§’è‰²äº’åŠ¨    â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 å…¸å‹åº”ç”¨æ¡ˆä¾‹

#### æ¡ˆä¾‹1ï¼šæ™ºèƒ½æ–‡æ¡£å¤„ç†

```python
# åœºæ™¯ï¼šä¿é™©ç†èµ”å•æ®è‡ªåŠ¨å¤„ç†

prompt = """
è¯·åˆ†æè¿™å¼ ä¿é™©ç†èµ”å•æ®ï¼Œæå–ä»¥ä¸‹ä¿¡æ¯ï¼š
1. è¢«ä¿é™©äººå§“å
2. ä¿å•å·
3. äº‹æ•…æ—¥æœŸ
4. ç†èµ”é‡‘é¢
5. äº‹æ•…æè¿°

ä»¥JSONæ ¼å¼è¾“å‡ºã€‚
"""

response = model.generate(image=claim_form_image, prompt=prompt)

# è¾“å‡ºç¤ºä¾‹:
{
  "è¢«ä¿é™©äºº": "å¼ ä¸‰",
  "ä¿å•å·": "PO2024001234",
  "äº‹æ•…æ—¥æœŸ": "2024-01-15",
  "ç†èµ”é‡‘é¢": "15000.00å…ƒ",
  "äº‹æ•…æè¿°": "è½¦è¾†è¿½å°¾äº‹æ•…ï¼Œå‰ä¿é™©æ æŸå"
}
```

#### æ¡ˆä¾‹2ï¼šç”µå•†å•†å“ç†è§£

```python
# åœºæ™¯ï¼šæ ¹æ®å•†å“å›¾ç‰‡è‡ªåŠ¨ç”Ÿæˆæè¿°å’Œæ ‡ç­¾

prompt = """
åˆ†æè¿™å¼ å•†å“å›¾ç‰‡ï¼Œç”Ÿæˆï¼š
1. å•†å“æ ‡é¢˜ï¼ˆ20å­—ä»¥å†…ï¼‰
2. å–ç‚¹æè¿°ï¼ˆ3æ¡ï¼‰
3. å•†å“ç±»ç›®
4. å±æ€§æ ‡ç­¾
"""

# è‡ªåŠ¨ç”Ÿæˆå•†å“è¯¦æƒ…é¡µå†…å®¹
```

#### æ¡ˆä¾‹3ï¼šæ•™è‚²åœºæ™¯

```python
# åœºæ™¯ï¼šæ•°å­¦é¢˜ç›®æ™ºèƒ½è§£ç­”

prompt = """
è¯·çœ‹è¿™é“æ•°å­¦é¢˜çš„å›¾ç‰‡ï¼Œ
1. è¯†åˆ«é¢˜ç›®å†…å®¹
2. åˆ†æè§£é¢˜æ€è·¯
3. ç»™å‡ºè¯¦ç»†è§£ç­”æ­¥éª¤
4. æ€»ç»“æ¶‰åŠçš„çŸ¥è¯†ç‚¹
"""

# è‡ªåŠ¨ç”Ÿæˆè§£é¢˜è¿‡ç¨‹
```

---

## 7. åŠ¨æ‰‹å®è·µ

### 7.1 ä½¿ç”¨ Transformers åº“

```python
# å®‰è£…ä¾èµ–
# pip install transformers torch pillow

from transformers import Qwen2VLForConditionalGeneration, AutoProcessor
from PIL import Image
import torch

# åŠ è½½æ¨¡å‹
model_name = "Qwen/Qwen2-VL-7B-Instruct"
model = Qwen2VLForConditionalGeneration.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,
    device_map="auto"
)
processor = AutoProcessor.from_pretrained(model_name)

# å‡†å¤‡è¾“å…¥
image = Image.open("example.jpg")
messages = [
    {
        "role": "user",
        "content": [
            {"type": "image", "image": image},
            {"type": "text", "text": "æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹"}
        ]
    }
]

# å¤„ç†è¾“å…¥
text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
inputs = processor(
    text=[text],
    images=[image],
    return_tensors="pt"
).to(model.device)

# ç”Ÿæˆè¾“å‡º
generated_ids = model.generate(**inputs, max_new_tokens=512)
output = processor.batch_decode(
    generated_ids[:, inputs.input_ids.shape[1]:],
    skip_special_tokens=True
)[0]

print(output)
```

### 7.2 ä½¿ç”¨ vLLM é«˜æ€§èƒ½æ¨ç†

```python
# pip install vllm

from vllm import LLM, SamplingParams
from vllm.multimodal import MultiModalData

# åˆå§‹åŒ–æ¨¡å‹
llm = LLM(
    model="Qwen/Qwen2-VL-7B-Instruct",
    dtype="bfloat16",
    gpu_memory_utilization=0.8
)

# é‡‡æ ·å‚æ•°
sampling_params = SamplingParams(
    temperature=0.7,
    max_tokens=512
)

# å‡†å¤‡å¤šæ¨¡æ€è¾“å…¥
prompt = "<|im_start|>user\n<image>\nè¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆï¼Ÿ<|im_end|>\n<|im_start|>assistant\n"
image_data = load_image("example.jpg")  # éœ€è¦å®ç°å›¾ç‰‡åŠ è½½

# ç”Ÿæˆ
outputs = llm.generate(
    prompts=[prompt],
    sampling_params=sampling_params,
    multi_modal_data={"image": image_data}
)

print(outputs[0].outputs[0].text)
```

### 7.3 ä½¿ç”¨ OpenAI API (GPT-4V)

```python
from openai import OpenAI
import base64

client = OpenAI()

# è¯»å–å›¾ç‰‡å¹¶ç¼–ç 
def encode_image(image_path):
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode('utf-8')

image_base64 = encode_image("example.jpg")

# è°ƒç”¨API
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "è¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆï¼Ÿè¯·è¯¦ç»†æè¿°"
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{image_base64}"
                    }
                }
            ]
        }
    ],
    max_tokens=1000
)

print(response.choices[0].message.content)
```

### 7.4 ä½¿ç”¨ LLaVA

```python
# pip install llava

from llava.model.builder import load_pretrained_model
from llava.mm_utils import get_model_name_from_path, process_images, tokenizer_image_token
from llava.constants import IMAGE_TOKEN_INDEX
from PIL import Image
import torch

# åŠ è½½æ¨¡å‹
model_path = "liuhaotian/llava-v1.6-vicuna-7b"
tokenizer, model, image_processor, context_len = load_pretrained_model(
    model_path=model_path,
    model_base=None,
    model_name=get_model_name_from_path(model_path)
)

# å¤„ç†å›¾ç‰‡
image = Image.open("example.jpg")
image_tensor = process_images([image], image_processor, model.config)
image_tensor = image_tensor.to(model.device, dtype=torch.float16)

# å‡†å¤‡prompt
prompt = "USER: <image>\næè¿°è¿™å¼ å›¾ç‰‡\nASSISTANT:"
input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt')
input_ids = input_ids.unsqueeze(0).to(model.device)

# ç”Ÿæˆ
with torch.inference_mode():
    output_ids = model.generate(
        input_ids,
        images=image_tensor,
        max_new_tokens=512,
        do_sample=True,
        temperature=0.2
    )

output = tokenizer.decode(output_ids[0], skip_special_tokens=True)
print(output.split("ASSISTANT:")[-1].strip())
```

### 7.5 å¾®è°ƒç¤ºä¾‹

```python
# ä½¿ç”¨ LLaMA-Factory è¿›è¡Œå¤šæ¨¡æ€å¾®è°ƒ
# https://github.com/hiyouga/LLaMA-Factory

# 1. å‡†å¤‡æ•°æ®é›† (data/my_multimodal_data.json)
"""
[
  {
    "messages": [
      {"role": "user", "content": "<image>è¿™æ˜¯ä»€ä¹ˆï¼Ÿ"},
      {"role": "assistant", "content": "è¿™æ˜¯ä¸€åªå¯çˆ±çš„çŒ«å’ª"}
    ],
    "images": ["images/cat.jpg"]
  }
]
"""

# 2. é…ç½®æ–‡ä»¶ (examples/train_lora/qwen2_vl_lora.yaml)
"""
model_name_or_path: Qwen/Qwen2-VL-7B-Instruct
stage: sft
do_train: true
finetuning_type: lora
lora_target: all
dataset: my_multimodal_data
template: qwen2_vl
output_dir: saves/qwen2-vl-lora
per_device_train_batch_size: 1
gradient_accumulation_steps: 8
lr_scheduler_type: cosine
logging_steps: 10
warmup_ratio: 0.1
save_steps: 1000
learning_rate: 1.0e-4
num_train_epochs: 3.0
"""

# 3. å¯åŠ¨è®­ç»ƒ
# llamafactory-cli train examples/train_lora/qwen2_vl_lora.yaml
```

---

## 8. æŒ‘æˆ˜ä¸æœªæ¥

### 8.1 å½“å‰æŒ‘æˆ˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ä¸»è¦æŠ€æœ¯æŒ‘æˆ˜                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  ğŸ”´ å¹»è§‰é—®é¢˜ (Hallucination)                                        â”‚
â”‚  â”œâ”€â”€ æè¿°ä¸å­˜åœ¨çš„ç‰©ä½“                                                â”‚
â”‚  â”œâ”€â”€ é”™è¯¯è§£è¯»å›¾åƒå†…å®¹                                                â”‚
â”‚  â””â”€â”€ è‡†é€ ç»†èŠ‚ä¿¡æ¯                                                    â”‚
â”‚                                                                     â”‚
â”‚  ğŸŸ  è®¡ç®—æ•ˆç‡                                                         â”‚
â”‚  â”œâ”€â”€ é«˜åˆ†è¾¨ç‡å›¾åƒtokenè¿‡å¤š                                           â”‚
â”‚  â”œâ”€â”€ è§†é¢‘ç†è§£è®¡ç®—é‡å·¨å¤§                                              â”‚
â”‚  â””â”€â”€ è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²å›°éš¾                                                â”‚
â”‚                                                                     â”‚
â”‚  ğŸŸ¡ ç»†ç²’åº¦ç†è§£                                                       â”‚
â”‚  â”œâ”€â”€ å°ç‰©ä½“æ£€æµ‹èƒ½åŠ›å¼±                                                â”‚
â”‚  â”œâ”€â”€ å¯†é›†æ–‡å­—OCRä¸å¤Ÿç²¾å‡†                                             â”‚
â”‚  â””â”€â”€ ç©ºé—´å…³ç³»æ¨ç†ä¸è¶³                                                â”‚
â”‚                                                                     â”‚
â”‚  ğŸŸ¢ æ•°æ®é—®é¢˜                                                         â”‚
â”‚  â”œâ”€â”€ é«˜è´¨é‡å¤šæ¨¡æ€æ•°æ®ç¨€ç¼º                                            â”‚
â”‚  â”œâ”€â”€ æ•°æ®æ ‡æ³¨æˆæœ¬é«˜                                                  â”‚
â”‚  â””â”€â”€ é¢†åŸŸæ•°æ®ä¸å¹³è¡¡                                                  â”‚
â”‚                                                                     â”‚
â”‚  ğŸ”µ è¯„æµ‹æ ‡å‡†                                                         â”‚
â”‚  â”œâ”€â”€ ç¼ºä¹ç»Ÿä¸€è¯„æµ‹åŸºå‡†                                                â”‚
â”‚  â”œâ”€â”€ äººå·¥è¯„æµ‹æˆæœ¬é«˜                                                  â”‚
â”‚  â””â”€â”€ å¼€æ”¾ä»»åŠ¡éš¾ä»¥é‡åŒ–                                                â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.2 æœªæ¥å‘å±•è¶‹åŠ¿

```
2024 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º æœªæ¥

   åŸç”Ÿå¤šæ¨¡æ€
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  â€¢ ä»å¤´è®­ç»ƒç»Ÿä¸€æ¶æ„                                         â”‚
   â”‚  â€¢ æ‰“ç ´æ¨¡æ€è¾¹ç•Œ                                             â”‚
   â”‚  â€¢ æ›´æ·±åº¦çš„è·¨æ¨¡æ€ç†è§£                                       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
   å…¨æ¨¡æ€ç”Ÿæˆ
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  â€¢ Any-to-Any: ä»»æ„æ¨¡æ€è¾“å…¥è¾“å‡º                             â”‚
   â”‚  â€¢ ç»Ÿä¸€ç”Ÿæˆæ¡†æ¶                                             â”‚
   â”‚  â€¢ å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘ã€3Dç”Ÿæˆ                                  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
   å…·èº«æ™ºèƒ½
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  â€¢ è¿æ¥ç‰©ç†ä¸–ç•Œ                                             â”‚
   â”‚  â€¢ æœºå™¨äººæ§åˆ¶                                               â”‚
   â”‚  â€¢ ç©ºé—´ç†è§£ä¸å¯¼èˆª                                           â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
   ä¸–ç•Œæ¨¡å‹
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  â€¢ ç‰©ç†è§„å¾‹ç†è§£                                             â”‚
   â”‚  â€¢ å› æœæ¨ç†                                                 â”‚
   â”‚  â€¢ é¢„æµ‹ä¸è§„åˆ’                                               â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.3 æŠ€æœ¯å±•æœ›

| æ–¹å‘         | å½“å‰çŠ¶æ€      | æœªæ¥ç›®æ ‡     |
| ------------ | ------------- | ------------ |
| **åˆ†è¾¨ç‡**   | 336-768pxä¸ºä¸» | 4K+åŸç”Ÿæ”¯æŒ  |
| **è§†é¢‘é•¿åº¦** | å‡ åˆ†é’Ÿ        | å°æ—¶çº§é•¿è§†é¢‘ |
| **å®æ—¶æ€§**   | å»¶è¿Ÿæ˜æ˜¾      | å®æ—¶æµå¤„ç†   |
| **æ¨¡æ€æ•°é‡** | 2-3ç§         | 10+ç§æ¨¡æ€    |
| **æ¨¡å‹å¤§å°** | 7B-72Bå‚æ•°    | æ›´é«˜æ•ˆå°æ¨¡å‹ |
| **å¹»è§‰ç‡**   | è¾ƒé«˜          | æ¥è¿‘é›¶å¹»è§‰   |

---

## 9. å­¦ä¹ èµ„æº

### 9.1 è®ºæ–‡æ¨è

#### åŸºç¡€è®ºæ–‡

| è®ºæ–‡                                         | å¹´ä»½ | æ ¸å¿ƒè´¡çŒ®           |
| -------------------------------------------- | ---- | ------------------ |
| [CLIP](https://arxiv.org/abs/2103.00020)     | 2021 | å¯¹æ¯”å­¦ä¹ å›¾æ–‡å¯¹é½   |
| [ViT](https://arxiv.org/abs/2010.11929)      | 2020 | Vision Transformer |
| [Flamingo](https://arxiv.org/abs/2204.14198) | 2022 | å°‘æ ·æœ¬å¤šæ¨¡æ€å­¦ä¹    |
| [BLIP-2](https://arxiv.org/abs/2301.12597)   | 2023 | Q-Formeræ¶æ„       |
| [LLaVA](https://arxiv.org/abs/2304.08485)    | 2023 | è§†è§‰æŒ‡ä»¤å¾®è°ƒ       |

#### è¿›é˜¶è®ºæ–‡

| è®ºæ–‡                                                                 | å¹´ä»½ | æ ¸å¿ƒè´¡çŒ®         |
| -------------------------------------------------------------------- | ---- | ---------------- |
| [LLaVA-NeXT](https://llava-vl.github.io/blog/2024-01-30-llava-next/) | 2024 | åŠ¨æ€åˆ†è¾¨ç‡       |
| [Qwen-VL](https://arxiv.org/abs/2308.12966)                          | 2023 | å¤šè¯­è¨€å¤šæ¨¡æ€     |
| [InternVL](https://arxiv.org/abs/2312.14238)                         | 2024 | å¤§è§„æ¨¡è§†è§‰ç¼–ç å™¨ |
| [GPT-4VæŠ€æœ¯æŠ¥å‘Š](https://openai.com/research/gpt-4v-system-card)     | 2023 | å•†ä¸šçº§å¤šæ¨¡æ€     |

### 9.2 å¼€æºé¡¹ç›®

```
æ ¸å¿ƒé¡¹ç›®:
â”œâ”€â”€ LLaVA: https://github.com/haotian-liu/LLaVA
â”œâ”€â”€ Qwen-VL: https://github.com/QwenLM/Qwen-VL
â”œâ”€â”€ InternVL: https://github.com/OpenGVLab/InternVL
â”œâ”€â”€ BLIP: https://github.com/salesforce/BLIP
â””â”€â”€ OpenCLIP: https://github.com/mlfoundations/open_clip

è®­ç»ƒæ¡†æ¶:
â”œâ”€â”€ LLaMA-Factory: https://github.com/hiyouga/LLaMA-Factory
â”œâ”€â”€ Swift: https://github.com/modelscope/swift
â””â”€â”€ XTuner: https://github.com/InternLM/xtuner

æ¨ç†éƒ¨ç½²:
â”œâ”€â”€ vLLM: https://github.com/vllm-project/vllm
â”œâ”€â”€ SGLang: https://github.com/sgl-project/sglang
â””â”€â”€ Ollama: https://github.com/ollama/ollama
```

### 9.3 è¯„æµ‹åŸºå‡†

| åŸºå‡†           | ä»»åŠ¡ç±»å‹      | è¯´æ˜                    |
| -------------- | ------------- | ----------------------- |
| **MMBench**    | ç»¼åˆè¯„æµ‹      | æ¶µç›–æ„ŸçŸ¥ã€æ¨ç†ç­‰20+èƒ½åŠ› |
| **SEED-Bench** | å›¾åƒ/è§†é¢‘ç†è§£ | å¤§è§„æ¨¡å¤šç»´åº¦è¯„æµ‹        |
| **MME**        | æ„ŸçŸ¥+è®¤çŸ¥     | åŒºåˆ†yes/noé—®ç­”          |
| **TextVQA**    | OCRé—®ç­”       | å›¾ä¸­æ–‡å­—ç†è§£            |
| **ChartQA**    | å›¾è¡¨ç†è§£      | æ•°æ®å¯è§†åŒ–åˆ†æ          |
| **DocVQA**     | æ–‡æ¡£é—®ç­”      | æ–‡æ¡£ç†è§£èƒ½åŠ›            |
| **Video-MME**  | è§†é¢‘ç†è§£      | é•¿è§†é¢‘å¤šé€‰é—®ç­”          |

### 9.4 å­¦ä¹ è·¯å¾„

```
å…¥é—¨é˜¶æ®µ (1-2å‘¨)
â”œâ”€â”€ 1. äº†è§£TransformeråŸºç¡€
â”œâ”€â”€ 2. å­¦ä¹ ViTè§†è§‰Transformer
â”œâ”€â”€ 3. ç†è§£CLIPå›¾æ–‡å¯¹é½
â””â”€â”€ 4. é˜…è¯»LLaVAè®ºæ–‡

è¿›é˜¶é˜¶æ®µ (2-4å‘¨)
â”œâ”€â”€ 1. åŠ¨æ‰‹è¿è¡ŒLLaVAæ¨ç†
â”œâ”€â”€ 2. å­¦ä¹ ä¸åŒå¯¹é½æ¶æ„
â”œâ”€â”€ 3. å°è¯•Qwen-VL/InternVL
â””â”€â”€ 4. ç†è§£è®­ç»ƒæµç¨‹

å®æˆ˜é˜¶æ®µ (4-8å‘¨)
â”œâ”€â”€ 1. å‡†å¤‡å¤šæ¨¡æ€æ•°æ®é›†
â”œâ”€â”€ 2. ä½¿ç”¨LLaMA-Factoryå¾®è°ƒ
â”œâ”€â”€ 3. è¯„æµ‹æ¨¡å‹æ€§èƒ½
â””â”€â”€ 4. éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ

æ·±å…¥é˜¶æ®µ (æŒç»­)
â”œâ”€â”€ 1. è·Ÿè¸ªæœ€æ–°è®ºæ–‡
â”œâ”€â”€ 2. å‚ä¸å¼€æºè´¡çŒ®
â”œâ”€â”€ 3. æ¢ç´¢åˆ›æ–°åº”ç”¨
â””â”€â”€ 4. æ„å»ºç«¯åˆ°ç«¯ç³»ç»Ÿ
```

---

## é™„å½•ï¼šæœ¯è¯­è¡¨

| æœ¯è¯­       | è‹±æ–‡                 | è§£é‡Š                               |
| ---------- | -------------------- | ---------------------------------- |
| å¤šæ¨¡æ€     | Multimodal           | å¤„ç†å¤šç§ä¿¡æ¯å½¢å¼çš„èƒ½åŠ›             |
| è§†è§‰ç¼–ç å™¨ | Vision Encoder       | å°†å›¾åƒè½¬æ¢ä¸ºç‰¹å¾å‘é‡çš„æ¨¡å‹         |
| æŠ•å½±å™¨     | Projector            | å¯¹é½ä¸åŒæ¨¡æ€ç‰¹å¾ç»´åº¦çš„æ¨¡å—         |
| è§†è§‰Token  | Visual Tokens        | å›¾åƒç»ç¼–ç åçš„tokenåºåˆ—            |
| æŒ‡ä»¤å¾®è°ƒ   | Instruction Tuning   | è®©æ¨¡å‹å­¦ä¼šéµå¾ªæŒ‡ä»¤çš„è®­ç»ƒæ–¹æ³•       |
| å¹»è§‰       | Hallucination        | æ¨¡å‹ç”Ÿæˆä¸å­˜åœ¨/é”™è¯¯çš„ä¿¡æ¯          |
| å¯¹æ¯”å­¦ä¹    | Contrastive Learning | é€šè¿‡æ­£è´Ÿæ ·æœ¬å¯¹æ¯”å­¦ä¹ è¡¨ç¤º           |
| äº¤å‰æ³¨æ„åŠ› | Cross-Attention      | ä¸€ä¸ªåºåˆ—å…³æ³¨å¦ä¸€ä¸ªåºåˆ—çš„æ³¨æ„åŠ›æœºåˆ¶ |
| åŠ¨æ€åˆ†è¾¨ç‡ | Dynamic Resolution   | æ ¹æ®å›¾åƒå°ºå¯¸è‡ªé€‚åº”å¤„ç†çš„æŠ€æœ¯       |

---

## æ€»ç»“

å¤šæ¨¡æ€LLMæ˜¯AIå‘å±•çš„é‡è¦æ–¹å‘ï¼Œå®ƒè®©AIèƒ½å¤Ÿåƒäººç±»ä¸€æ ·ç†è§£å’Œå¤„ç†å¤šç§æ„Ÿå®˜ä¿¡æ¯ã€‚æœ¬æ–‡ä»åŸºç¡€æ¦‚å¿µåˆ°æŠ€æœ¯å®ç°ï¼Œä»ä¸»æµæ¨¡å‹åˆ°å®è·µåº”ç”¨ï¼Œå…¨é¢ä»‹ç»äº†è¿™ä¸€é¢†åŸŸã€‚

**æ ¸å¿ƒè¦ç‚¹å›é¡¾ï¼š**

1. **æ¶æ„æ¼”è¿›**ï¼šä»ç®€å•çš„å›¾æ–‡å¯¹é½ï¼Œåˆ°è¿æ¥å™¨æ–¹æ³•ï¼Œå†åˆ°åŸç”Ÿå¤šæ¨¡æ€
2. **å…³é”®æŠ€æœ¯**ï¼šè§†è§‰ç¼–ç å™¨ + å¯¹é½æ¨¡å— + LLMä¸»å¹²
3. **è®­ç»ƒæµç¨‹**ï¼šé¢„è®­ç»ƒå¯¹é½ â†’ æŒ‡ä»¤å¾®è°ƒ â†’ åå¥½ä¼˜åŒ–
4. **åº”ç”¨å¹¿æ³›**ï¼šæ–‡æ¡£ç†è§£ã€ç”µå•†ã€åŒ»ç–—ã€æ•™è‚²ç­‰åœºæ™¯
5. **æœªæ¥è¶‹åŠ¿**ï¼šå…¨æ¨¡æ€ç”Ÿæˆã€å…·èº«æ™ºèƒ½ã€ä¸–ç•Œæ¨¡å‹

---

_æ–‡æ¡£ç‰ˆæœ¬ï¼šv1.0 | æ›´æ–°æ—¶é—´ï¼š2024å¹´12æœˆ_
