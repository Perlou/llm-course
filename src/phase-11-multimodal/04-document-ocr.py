"""
æ–‡æ¡£ OCR å¤„ç†
============

å­¦ä¹ ç›®æ ‡ï¼š
    1. ä½¿ç”¨å¤šæ¨¡æ€ LLM è¿›è¡Œæ–‡æ¡£ OCR
    2. å¤„ç†ä¸åŒç±»å‹çš„æ–‡æ¡£ï¼ˆå‘ç¥¨ã€åˆåŒã€è¡¨æ ¼ç­‰ï¼‰
    3. ç»“æ„åŒ–æå–æ–‡æ¡£ä¿¡æ¯

æ ¸å¿ƒæ¦‚å¿µï¼š
    - OCR (Optical Character Recognition)
    - æ–‡æ¡£ç»“æ„ç†è§£
    - ä¿¡æ¯æŠ½å–

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install openai pillow pdf2image

ğŸ“Œ Gemini è¿ç§»è¯´æ˜ï¼š
    æœ¬æ–‡ä»¶å±•ç¤ºæ–‡æ¡£OCRçš„æ ¸å¿ƒæ¦‚å¿µã€‚
    ç¤ºä¾‹ä»£ç ä½¿ç”¨OpenAI APIæ¼”ç¤ºï¼ŒGeminiç­‰ä»·å®ç°å‚è€ƒ02-gpt4-vision.pyé¡¶éƒ¨è¯´æ˜ã€‚ge
"""

import os
from typing import Dict, List
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šOCR æ¦‚è¿° ====================


def introduction():
    """OCR æ¦‚è¿°"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šæ–‡æ¡£ OCR æ¦‚è¿°")
    print("=" * 60)

    print("""
    ğŸ“Œ ä¼ ç»Ÿ OCR vs å¤šæ¨¡æ€ LLM OCRï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              â”‚    ä¼ ç»Ÿ OCR      â”‚  å¤šæ¨¡æ€ LLM      â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ æ–‡å­—è¯†åˆ«     â”‚ âœ… å‡†ç¡®          â”‚ âœ… å‡†ç¡®          â”‚
    â”‚ ç‰ˆé¢ç†è§£     â”‚ âŒ æœ‰é™          â”‚ âœ… ç†è§£ç»“æ„      â”‚
    â”‚ è¯­ä¹‰ç†è§£     â”‚ âŒ ä¸æ”¯æŒ        â”‚ âœ… ç†è§£å«ä¹‰      â”‚
    â”‚ ä¿¡æ¯æŠ½å–     â”‚ âŒ éœ€è§„åˆ™        â”‚ âœ… è‡ªåŠ¨æŠ½å–      â”‚
    â”‚ å¤šè¯­è¨€       â”‚ éœ€è¦ä¸“é—¨æ¨¡å‹     â”‚ âœ… åŸç”Ÿæ”¯æŒ      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    ğŸ“Œ é€‚ç”¨åœºæ™¯ï¼š
    - å‘ç¥¨/æ”¶æ®è¯†åˆ«
    - åˆåŒä¿¡æ¯æå–
    - è¡¨æ ¼æ•°æ®æŠ½å–
    - è¯ä»¶ä¿¡æ¯è¯†åˆ«
    - æ–‡æ¡£é—®ç­”
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€ OCR ====================


def basic_ocr():
    """åŸºç¡€ OCR"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€æ–‡å­—è¯†åˆ«")
    print("=" * 60)

    code = '''
from openai import OpenAI
import base64

client = OpenAI()

def encode_image(path: str) -> str:
    with open(path, "rb") as f:
        return base64.b64encode(f.read()).decode('utf-8')

def extract_text(image_path: str) -> str:
    """ä»å›¾ç‰‡ä¸­æå–æ‰€æœ‰æ–‡å­—"""
    image_base64 = encode_image(image_path)

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": """è¯·è¯†åˆ«å¹¶æå–å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—ã€‚
è¦æ±‚ï¼š
1. ä¿æŒåŸæœ‰çš„æ’ç‰ˆæ ¼å¼
2. åŒºåˆ†æ ‡é¢˜ã€æ­£æ–‡ã€æ³¨é‡Šç­‰
3. è¡¨æ ¼å†…å®¹ç”¨è¡¨æ ¼æ ¼å¼è¡¨ç¤º
4. å¦‚æœ‰æ‰‹å†™æ–‡å­—ï¼Œå°½é‡è¯†åˆ«"""
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_base64}",
                            "detail": "high"  # é«˜åˆ†è¾¨ç‡æ¨¡å¼
                        }
                    }
                ]
            }
        ],
        max_tokens=2000
    )

    return response.choices[0].message.content
'''
    print(code)


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šå‘ç¥¨è¯†åˆ« ====================


def invoice_recognition():
    """å‘ç¥¨è¯†åˆ«"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šå‘ç¥¨è¯†åˆ«")
    print("=" * 60)

    code = '''
def extract_invoice_info(image_path: str) -> dict:
    """æå–å‘ç¥¨ä¿¡æ¯"""
    image_base64 = encode_image(image_path)

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": """è¯·è¯†åˆ«è¿™å¼ å‘ç¥¨ï¼Œæå–ä»¥ä¸‹ä¿¡æ¯å¹¶è¿”å› JSONï¼š
{
    "invoice_code": "å‘ç¥¨ä»£ç ",
    "invoice_number": "å‘ç¥¨å·ç ",
    "invoice_date": "å¼€ç¥¨æ—¥æœŸ",
    "seller": {
        "name": "é”€å”®æ–¹åç§°",
        "tax_id": "çº³ç¨äººè¯†åˆ«å·"
    },
    "buyer": {
        "name": "è´­ä¹°æ–¹åç§°",
        "tax_id": "çº³ç¨äººè¯†åˆ«å·"
    },
    "items": [
        {"name": "å•†å“åç§°", "quantity": æ•°é‡, "unit_price": å•ä»·, "amount": é‡‘é¢}
    ],
    "total_amount": "åˆè®¡é‡‘é¢",
    "tax_amount": "ç¨é¢",
    "total_with_tax": "ä»·ç¨åˆè®¡"
}

å¦‚æœæŸé¡¹ä¿¡æ¯æ— æ³•è¯†åˆ«ï¼Œå¡«å†™ nullã€‚"""
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_base64}",
                            "detail": "high"
                        }
                    }
                ]
            }
        ],
        max_tokens=1500
    )

    import json
    return json.loads(response.choices[0].message.content)
'''
    print(code)


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šè¡¨æ ¼æå– ====================


def table_extraction():
    """è¡¨æ ¼æå–"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šè¡¨æ ¼æ•°æ®æå–")
    print("=" * 60)

    code = '''
def extract_table(image_path: str, output_format: str = "markdown") -> str:
    """ä»å›¾ç‰‡ä¸­æå–è¡¨æ ¼"""
    image_base64 = encode_image(image_path)

    format_prompts = {
        "markdown": "è¯·ç”¨ Markdown è¡¨æ ¼æ ¼å¼è¾“å‡º",
        "csv": "è¯·ç”¨ CSV æ ¼å¼è¾“å‡ºï¼Œç”¨é€—å·åˆ†éš”",
        "json": "è¯·ç”¨ JSON æ•°ç»„æ ¼å¼è¾“å‡ºï¼Œæ¯è¡Œæ˜¯ä¸€ä¸ªå¯¹è±¡"
    }

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": f"""è¯†åˆ«å›¾ç‰‡ä¸­çš„è¡¨æ ¼æ•°æ®ã€‚
{format_prompts.get(output_format, format_prompts['markdown'])}

è¦æ±‚ï¼š
1. å‡†ç¡®è¯†åˆ«æ¯ä¸ªå•å…ƒæ ¼çš„å†…å®¹
2. ä¿æŒè¡¨æ ¼çš„è¡Œåˆ—ç»“æ„
3. åˆå¹¶å•å…ƒæ ¼éœ€è¦æ­£ç¡®å¤„ç†"""
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_base64}",
                            "detail": "high"
                        }
                    }
                ]
            }
        ],
        max_tokens=3000
    )

    return response.choices[0].message.content

# ä½¿ç”¨ç¤ºä¾‹
# table_md = extract_table("spreadsheet.png", "markdown")
# table_csv = extract_table("spreadsheet.png", "csv")
'''
    print(code)


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šåˆåŒåˆ†æ ====================


def contract_analysis():
    """åˆåŒåˆ†æ"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šåˆåŒæ–‡æ¡£åˆ†æ")
    print("=" * 60)

    code = '''
def analyze_contract(image_paths: list) -> dict:
    """åˆ†æåˆåŒæ–‡æ¡£ï¼ˆæ”¯æŒå¤šé¡µï¼‰"""
    content = [{
        "type": "text",
        "text": """åˆ†æè¿™ä»½åˆåŒæ–‡æ¡£ï¼Œæå–ä»¥ä¸‹å…³é”®ä¿¡æ¯ï¼š

{
    "contract_type": "åˆåŒç±»å‹",
    "parties": [
        {"role": "ç”²æ–¹/ä¹™æ–¹", "name": "åç§°", "address": "åœ°å€"}
    ],
    "subject": "åˆåŒæ ‡çš„",
    "amount": "åˆåŒé‡‘é¢",
    "duration": {
        "start": "å¼€å§‹æ—¥æœŸ",
        "end": "ç»“æŸæ—¥æœŸ"
    },
    "key_terms": ["å…³é”®æ¡æ¬¾åˆ—è¡¨"],
    "payment_terms": "ä»˜æ¬¾æ¡æ¬¾",
    "liability": "è¿çº¦è´£ä»»",
    "risks": ["æ½œåœ¨é£é™©ç‚¹"]
}"""
    }]

    for path in image_paths:
        image_base64 = encode_image(path)
        content.append({
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{image_base64}",
                "detail": "high"
            }
        })

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": content}],
        max_tokens=3000
    )

    import json
    return json.loads(response.choices[0].message.content)
'''
    print(code)


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šç»ƒä¹  ====================


def exercises():
    """ç»ƒä¹ """
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šå®ç°èº«ä»½è¯/åç‰‡ä¿¡æ¯æå–å‡½æ•°

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        import google.generativeai as genai
        from PIL import Image
        from typing import Dict
        
        class IDCardExtractor:
            '''èº«ä»½è¯/åç‰‡ä¿¡æ¯æå–å™¨'''
            
            def __init__(self, api_key: str):
                genai.configure(api_key=api_key)
                self.model = genai.GenerativeModel('gemini-1.5-flash')
            
            def extract_id_card(self, image_path: str) -> Dict:
                '''æå–èº«ä»½è¯ä¿¡æ¯'''
                img = Image.open(image_path)
                
                prompt = '''è¯†åˆ«è¿™å¼ èº«ä»½è¯ï¼Œæå–ä¿¡æ¯å¹¶è¿”å› JSONï¼š
{
    "name": "å§“å",
    "gender": "æ€§åˆ«",
    "ethnicity": "æ°‘æ—",
    "birth_date": "å‡ºç”Ÿæ—¥æœŸ (YYYY-MM-DD)",
    "address": "ä½å€",
    "id_number": "èº«ä»½è¯å·",
    "issuing_authority": "ç­¾å‘æœºå…³ï¼ˆå¦‚æœ‰ï¼‰",
    "valid_period": "æœ‰æ•ˆæœŸé™ï¼ˆå¦‚æœ‰ï¼‰",
    "side": "æ­£é¢/èƒŒé¢"
}
æ³¨æ„ï¼šä¿æŠ¤éšç§ï¼Œéƒ¨åˆ†ä¿¡æ¯å¯ç”¨ * é®æŒ¡ã€‚'''
                
                response = self.model.generate_content([prompt, img])
                
                import json
                return json.loads(response.text)
            
            def extract_business_card(self, image_path: str) -> Dict:
                '''æå–åç‰‡ä¿¡æ¯'''
                img = Image.open(image_path)
                
                prompt = '''è¯†åˆ«è¿™å¼ åç‰‡ï¼Œæå–ä¿¡æ¯å¹¶è¿”å› JSONï¼š
{
    "name": "å§“å",
    "title": "èŒä½",
    "company": "å…¬å¸åç§°",
    "department": "éƒ¨é—¨",
    "phone": ["ç”µè¯å·ç åˆ—è¡¨"],
    "email": "é‚®ç®±",
    "address": "åœ°å€",
    "website": "ç½‘ç«™",
    "social_media": {"å¾®ä¿¡": "...", "å…¶ä»–": "..."}
}'''
                
                response = self.model.generate_content([prompt, img])
                
                import json
                return json.loads(response.text)
        
        # ä½¿ç”¨ç¤ºä¾‹
        # extractor = IDCardExtractor(os.getenv("GOOGLE_API_KEY"))
        # id_info = extractor.extract_id_card("id_card.jpg")
        # card_info = extractor.extract_business_card("business_card.jpg")
        ```
    
    ç»ƒä¹  2ï¼šå®ç°å¤šé¡µ PDF çš„æ‰¹é‡ OCR å¤„ç†

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        from pdf2image import convert_from_path
        import tempfile
        import os
        
        class PDFBatchOCR:
            '''PDF æ‰¹é‡ OCR å¤„ç†å™¨'''
            
            def __init__(self, api_key: str):
                genai.configure(api_key=api_key)
                self.model = genai.GenerativeModel('gemini-1.5-flash')
            
            def pdf_to_images(
                self, 
                pdf_path: str, 
                dpi: int = 200
            ) -> list:
                '''å°† PDF è½¬æ¢ä¸ºå›¾ç‰‡'''
                images = convert_from_path(pdf_path, dpi=dpi)
                return images
            
            def ocr_page(self, image) -> str:
                '''OCR å•é¡µ'''
                prompt = '''è¯·è¯†åˆ«è¿™é¡µæ–‡æ¡£ä¸­çš„æ‰€æœ‰æ–‡å­—ã€‚
ä¿æŒåŸæœ‰æ ¼å¼ï¼ŒåŒºåˆ†æ ‡é¢˜ã€æ­£æ–‡ã€è¡¨æ ¼ç­‰ã€‚'''
                
                response = self.model.generate_content([prompt, image])
                return response.text
            
            def ocr_pdf(
                self, 
                pdf_path: str,
                output_format: str = "text"
            ) -> Dict:
                '''OCR æ•´ä¸ª PDF'''
                images = self.pdf_to_images(pdf_path)
                
                results = []
                full_text = []
                
                for i, img in enumerate(images):
                    text = self.ocr_page(img)
                    results.append({
                        'page': i + 1,
                        'text': text
                    })
                    full_text.append(f"=== ç¬¬ {i+1} é¡µ ===\\n{text}")
                
                return {
                    'total_pages': len(images),
                    'pages': results,
                    'full_text': "\\n\\n".join(full_text)
                }
            
            def extract_structure(self, pdf_path: str) -> Dict:
                '''æå–æ–‡æ¡£ç»“æ„'''
                images = self.pdf_to_images(pdf_path)
                
                # åªåˆ†æç¬¬ä¸€é¡µè·å–ç›®å½•ç»“æ„
                prompt = '''åˆ†æè¿™ä¸ªæ–‡æ¡£çš„ç»“æ„ï¼Œè¿”å› JSONï¼š
{
    "title": "æ–‡æ¡£æ ‡é¢˜",
    "type": "æ–‡æ¡£ç±»å‹ï¼ˆåˆåŒ/æŠ¥å‘Š/è®ºæ–‡ç­‰ï¼‰",
    "sections": ["ç« èŠ‚åˆ—è¡¨"],
    "summary": "å†…å®¹æ¦‚è¦"
}'''
                
                response = self.model.generate_content([prompt, images[0]])
                
                import json
                return json.loads(response.text)
        
        # ä½¿ç”¨ç¤ºä¾‹
        # ocr = PDFBatchOCR(os.getenv("GOOGLE_API_KEY"))
        # result = ocr.ocr_pdf("document.pdf")
        # print(f"å…± {result['total_pages']} é¡µ")
        # print(result['full_text'])
        ```

    æ€è€ƒé¢˜ï¼šå¤šæ¨¡æ€ LLM OCR çš„ä¼˜åŠ¿å’Œå±€é™æ˜¯ä»€ä¹ˆï¼Ÿ

        âœ… ç­”ï¼š
        ä¼˜åŠ¿ï¼š
        1. è¯­ä¹‰ç†è§£ - ä¸ä»…è¯†åˆ«æ–‡å­—ï¼Œè¿˜ç†è§£å«ä¹‰
        2. ä¿¡æ¯æŠ½å– - è‡ªåŠ¨æå–å…³é”®å­—æ®µ
        3. å¤æ‚ç‰ˆé¢ - å¤„ç†è¡¨æ ¼ã€å¤šæ ã€æ··åˆå¸ƒå±€
        4. å¤šè¯­è¨€ - åŸç”Ÿæ”¯æŒå¤šç§è¯­è¨€æ··æ’
        5. é—®ç­”èƒ½åŠ› - å¯ä»¥å°±æ–‡æ¡£å†…å®¹æé—®
        
        å±€é™ï¼š
        1. æˆæœ¬è¾ƒé«˜ - æŒ‰ token è®¡è´¹ï¼Œå¤§é‡æ–‡æ¡£æˆæœ¬é«˜
        2. é€Ÿåº¦è¾ƒæ…¢ - æ¯”ä¼ ç»Ÿ OCR å»¶è¿Ÿæ›´é«˜
        3. é•¿æ–‡æ¡£é™åˆ¶ - éœ€è¦åˆ†é¡µå¤„ç†
        4. æ‰‹å†™è¯†åˆ« - å¤æ‚æ‰‹å†™å‡†ç¡®ç‡æœ‰é™
        5. éšç§é£é™© - æ•°æ®å‘é€åˆ°äº‘ç«¯å¤„ç†
    """)


def main():
    introduction()
    basic_ocr()
    invoice_recognition()
    table_extraction()
    contract_analysis()
    exercises()
    print("\nè¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š05-chart-analysis.py")


if __name__ == "__main__":
    main()
