"""
è§†é¢‘ç†è§£
========

å­¦ä¹ ç›®æ ‡ï¼š
    1. äº†è§£è§†é¢‘ç†è§£çš„æ–¹æ³•å’ŒæŒ‘æˆ˜
    2. ä½¿ç”¨å¤šæ¨¡æ€ LLM åˆ†æè§†é¢‘å†…å®¹
    3. å®ç°è§†é¢‘æ‘˜è¦å’Œé—®ç­”

æ ¸å¿ƒæ¦‚å¿µï¼š
    - å¸§é‡‡æ ·ï¼šä»è§†é¢‘ä¸­æå–å…³é”®å¸§
    - æ—¶åºç†è§£ï¼šç†è§£è§†é¢‘çš„æ—¶é—´é¡ºåº
    - è§†é¢‘é—®ç­”ï¼šåŸºäºè§†é¢‘å†…å®¹å›ç­”é—®é¢˜

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install google-generativeai pillow opencv-python

ğŸ“Œ Gemini è¿ç§»è¯´æ˜ï¼š
    æœ¬æ–‡ä»¶å±•ç¤ºè§†é¢‘ç†è§£çš„æ ¸å¿ƒæ¦‚å¿µï¼ˆé€šè¿‡å¸§æå–+å›¾åƒåˆ†æï¼‰ã€‚
    ç¤ºä¾‹ä»£ç ä½¿ç”¨OpenAI APIæ¼”ç¤ºï¼ŒGeminiç­‰ä»·å®ç°å‚è€ƒ02-gpt4-vision.pyé¡¶éƒ¨è¯´æ˜ã€‚
"""

import os
from typing import List, Dict
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šè§†é¢‘ç†è§£æ¦‚è¿° ====================


def introduction():
    """è§†é¢‘ç†è§£æ¦‚è¿°"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šè§†é¢‘ç†è§£æ¦‚è¿°")
    print("=" * 60)

    print("""
    ğŸ“Œ è§†é¢‘ç†è§£çš„æŒ‘æˆ˜ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 1. æ•°æ®é‡å¤§ï¼š1åˆ†é’Ÿè§†é¢‘ = 1800å¸§ (30fps)               â”‚
    â”‚ 2. æ—¶åºä¾èµ–ï¼šéœ€è¦ç†è§£å¸§ä¹‹é—´çš„å…³ç³»                      â”‚
    â”‚ 3. è®¡ç®—æˆæœ¬ï¼šå¤„ç†å¤§é‡å¸§æ¶ˆè€—èµ„æº                        â”‚
    â”‚ 4. ä¸Šä¸‹æ–‡é•¿åº¦ï¼šToken é™åˆ¶                              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    ğŸ“Œ å¸¸ç”¨æ–¹æ³•ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ å…³é”®å¸§é‡‡æ ·      â”‚ å‡åŒ€æˆ–æ™ºèƒ½é€‰å–ä»£è¡¨æ€§å¸§              â”‚
    â”‚ åœºæ™¯åˆ†å‰²       â”‚ æŒ‰åœºæ™¯å˜åŒ–åˆ†æ®µå¤„ç†                   â”‚
    â”‚ è§†é¢‘æ‘˜è¦       â”‚ ç”Ÿæˆè§†é¢‘å†…å®¹æ¦‚è¿°                     â”‚
    â”‚ è§†é¢‘é—®ç­”       â”‚ åŸºäºè§†é¢‘å›ç­”é—®é¢˜                     â”‚
    â”‚ åŸç”Ÿè§†é¢‘æ¨¡å‹   â”‚ Gemini 2.0 ç­‰æ”¯æŒç›´æ¥è¾“å…¥è§†é¢‘       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    ğŸ“Œ æ”¯æŒè§†é¢‘çš„æ¨¡å‹ï¼š
    - Gemini 2.0ï¼šåŸç”Ÿè§†é¢‘ç†è§£
    - Qwen2-VLï¼šæ”¯æŒè§†é¢‘è¾“å…¥
    - GPT-4oï¼šé€šè¿‡å¸§é‡‡æ ·åˆ†æ
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šå¸§é‡‡æ · ====================


def frame_sampling():
    """å¸§é‡‡æ ·"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šè§†é¢‘å¸§é‡‡æ ·")
    print("=" * 60)

    code = '''
import cv2
import base64
from PIL import Image
import io

def extract_frames(video_path: str, num_frames: int = 10) -> list:
    """ä»è§†é¢‘ä¸­å‡åŒ€é‡‡æ ·å¸§"""
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    duration = total_frames / fps

    print(f"è§†é¢‘ä¿¡æ¯: {total_frames}å¸§, {fps}fps, {duration:.1f}ç§’")

    # å‡åŒ€é‡‡æ ·
    frame_indices = [int(i * total_frames / num_frames) for i in range(num_frames)]

    frames = []
    for idx in frame_indices:
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if ret:
            # BGR to RGB
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frames.append({
                "frame_idx": idx,
                "timestamp": idx / fps,
                "image": Image.fromarray(frame_rgb)
            })

    cap.release()
    return frames

def frames_to_base64(frames: list) -> list:
    """å°†å¸§è½¬æ¢ä¸º base64"""
    base64_frames = []
    for frame in frames:
        buffer = io.BytesIO()
        frame["image"].save(buffer, format="JPEG", quality=85)
        b64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
        base64_frames.append({
            "timestamp": frame["timestamp"],
            "base64": b64
        })
    return base64_frames
'''
    print(code)


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šè§†é¢‘åˆ†æ ====================


def video_analysis():
    """è§†é¢‘åˆ†æ"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šè§†é¢‘å†…å®¹åˆ†æ")
    print("=" * 60)

    code = '''
from openai import OpenAI

client = OpenAI()

def analyze_video(video_path: str, num_frames: int = 8) -> str:
    """åˆ†æè§†é¢‘å†…å®¹"""
    # æå–å¸§
    frames = extract_frames(video_path, num_frames)
    base64_frames = frames_to_base64(frames)

    # æ„å»ºè¯·æ±‚
    content = [{
        "type": "text",
        "text": """è¿™æ˜¯ä¸€ä¸ªè§†é¢‘çš„å…³é”®å¸§åºåˆ—ï¼Œè¯·åˆ†æè§†é¢‘å†…å®¹ï¼š

1. è§†é¢‘ä¸»é¢˜ï¼šè¿™ä¸ªè§†é¢‘åœ¨è®²ä»€ä¹ˆï¼Ÿ
2. åœºæ™¯æè¿°ï¼šä¸»è¦åœºæ™¯å’Œç¯å¢ƒ
3. å…³é”®äº‹ä»¶ï¼šæŒ‰æ—¶é—´é¡ºåºåˆ—å‡ºå‘ç”Ÿçš„äº‹æƒ…
4. äººç‰©/ç‰©ä½“ï¼šä¸»è¦å‡ºç°çš„äººç‰©æˆ–ç‰©ä½“
5. æ•´ä½“æ‘˜è¦ï¼šç”¨2-3å¥è¯æ€»ç»“è§†é¢‘

å¸§åºåˆ—ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼‰ï¼š"""
    }]

    for i, frame in enumerate(base64_frames):
        content.append({"type": "text", "text": f"\\nå¸§ {i+1} (æ—¶é—´: {frame['timestamp']:.1f}ç§’):"})
        content.append({
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{frame['base64']}"
            }
        })

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": content}],
        max_tokens=1500
    )

    return response.choices[0].message.content
'''
    print(code)


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šè§†é¢‘é—®ç­” ====================


def video_qa():
    """è§†é¢‘é—®ç­”"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šè§†é¢‘é—®ç­”")
    print("=" * 60)

    code = '''
def video_question_answer(
    video_path: str,
    question: str,
    num_frames: int = 8
) -> str:
    """åŸºäºè§†é¢‘å›ç­”é—®é¢˜"""
    frames = extract_frames(video_path, num_frames)
    base64_frames = frames_to_base64(frames)

    content = [{
        "type": "text",
        "text": f"""è¿™æ˜¯ä¸€ä¸ªè§†é¢‘çš„å…³é”®å¸§åºåˆ—ã€‚è¯·æ ¹æ®è§†é¢‘å†…å®¹å›ç­”é—®é¢˜ã€‚

é—®é¢˜ï¼š{question}

å¸§åºåˆ—ï¼š"""
    }]

    for i, frame in enumerate(base64_frames):
        content.append({
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{frame['base64']}"
            }
        })

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": content}],
        max_tokens=800
    )

    return response.choices[0].message.content

# ä½¿ç”¨ç¤ºä¾‹
# answer = video_question_answer("demo.mp4", "è§†é¢‘ä¸­æœ‰å¤šå°‘äººï¼Ÿ")
'''
    print(code)


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šä½¿ç”¨ Gemini ====================


def gemini_video():
    """ä½¿ç”¨ Gemini åŸç”Ÿè§†é¢‘ç†è§£"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šGemini åŸç”Ÿè§†é¢‘ç†è§£")
    print("=" * 60)

    code = '''
import google.generativeai as genai
import time

# é…ç½® API
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

def analyze_video_gemini(video_path: str, prompt: str) -> str:
    """ä½¿ç”¨ Gemini åˆ†æè§†é¢‘ï¼ˆåŸç”Ÿæ”¯æŒï¼‰"""
    # ä¸Šä¼ è§†é¢‘æ–‡ä»¶
    video_file = genai.upload_file(path=video_path)

    # ç­‰å¾…å¤„ç†å®Œæˆ
    while video_file.state.name == "PROCESSING":
        print("å¤„ç†ä¸­...")
        time.sleep(5)
        video_file = genai.get_file(video_file.name)

    if video_file.state.name == "FAILED":
        raise ValueError("è§†é¢‘å¤„ç†å¤±è´¥")

    # è°ƒç”¨æ¨¡å‹
    model = genai.GenerativeModel("gemini-2.0-flash")
    response = model.generate_content(
        [video_file, prompt],
        generation_config={"max_output_tokens": 2000}
    )

    return response.text

# ä½¿ç”¨ç¤ºä¾‹
# result = analyze_video_gemini("video.mp4", "æ€»ç»“è¿™ä¸ªè§†é¢‘çš„å†…å®¹")
'''
    print(code)


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šç»ƒä¹  ====================


def exercises():
    """ç»ƒä¹ """
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šå®ç°æ™ºèƒ½å¸§é‡‡æ ·ï¼ˆåŸºäºåœºæ™¯å˜åŒ–ï¼‰
    ç»ƒä¹  2ï¼šæ„å»ºè§†é¢‘å†…å®¹å®¡æ ¸ç³»ç»Ÿ

    æ€è€ƒé¢˜ï¼šå¸§é‡‡æ ·æ•°é‡å¦‚ä½•é€‰æ‹©ï¼Ÿ
    ç­”æ¡ˆï¼š
    - çŸ­è§†é¢‘ï¼ˆ<1åˆ†é’Ÿï¼‰ï¼š6-10å¸§
    - ä¸­ç­‰è§†é¢‘ï¼ˆ1-5åˆ†é’Ÿï¼‰ï¼š10-16å¸§
    - é•¿è§†é¢‘ï¼šæŒ‰åœºæ™¯åˆ†æ®µï¼Œæ¯æ®µé‡‡æ ·
    - å¿«é€Ÿå˜åŒ–åœºæ™¯ï¼šå¢åŠ é‡‡æ ·å¯†åº¦
    - é™æ€åœºæ™¯ï¼šå¯å‡å°‘é‡‡æ ·
    """)


def main():
    introduction()
    frame_sampling()
    video_analysis()
    video_qa()
    gemini_video()
    exercises()
    print("\nè¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š07-speech-to-text.py")


if __name__ == "__main__":
    main()
