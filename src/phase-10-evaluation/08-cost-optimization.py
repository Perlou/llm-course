"""
æˆæœ¬ä¼˜åŒ–
========

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£ LLM åº”ç”¨çš„æˆæœ¬æ„æˆ
    2. æŒæ¡ Token ä¼˜åŒ–æŠ€å·§
    3. å®ç°æˆæœ¬ç›‘æ§å’Œæ§åˆ¶

æ ¸å¿ƒæ¦‚å¿µï¼š
    - Token æˆæœ¬ï¼šè¾“å…¥/è¾“å‡º token å®šä»·
    - Cachingï¼šç¼“å­˜å¤ç”¨
    - æ¨¡å‹é€‰æ‹©ï¼šåœ¨è´¨é‡å’Œæˆæœ¬é—´å¹³è¡¡

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install tiktoken openai
"""

import os
from typing import List, Dict
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šæˆæœ¬æ„æˆåˆ†æ ====================


def introduction():
    """æˆæœ¬æ„æˆåˆ†æ"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šLLM æˆæœ¬æ„æˆ")
    print("=" * 60)

    print("""
    ğŸ“Œ LLM åº”ç”¨æˆæœ¬æ„æˆï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  1. API è°ƒç”¨æˆæœ¬ (æœ€å¤§)                                 â”‚
    â”‚     - è¾“å…¥ Token è´¹ç”¨                                   â”‚
    â”‚     - è¾“å‡º Token è´¹ç”¨ï¼ˆé€šå¸¸æ›´è´µï¼‰                       â”‚
    â”‚                                                         â”‚
    â”‚  2. åŸºç¡€è®¾æ–½æˆæœ¬                                        â”‚
    â”‚     - æœåŠ¡å™¨/GPU è´¹ç”¨                                   â”‚
    â”‚     - å‘é‡æ•°æ®åº“                                        â”‚
    â”‚                                                         â”‚
    â”‚  3. å­˜å‚¨æˆæœ¬                                            â”‚
    â”‚     - å‘é‡ç´¢å¼•å­˜å‚¨                                      â”‚
    â”‚     - ç¼“å­˜å­˜å‚¨                                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    ğŸ“Œ ä¸»æµæ¨¡å‹å®šä»·å¯¹æ¯” ($/1M tokens)ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     æ¨¡å‹       â”‚  è¾“å…¥    â”‚   è¾“å‡º   â”‚   æ€§èƒ½/æˆæœ¬  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ GPT-4o         â”‚  $2.5    â”‚  $10     â”‚   ä¸­         â”‚
    â”‚ GPT-4o-mini    â”‚  $0.15   â”‚  $0.6    â”‚   é«˜         â”‚
    â”‚ Claude 3.5     â”‚  $3      â”‚  $15     â”‚   ä¸­         â”‚
    â”‚ Claude 3 Haiku â”‚  $0.25   â”‚  $1.25   â”‚   é«˜         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šToken ä¼˜åŒ– ====================


def token_optimization():
    """Token ä¼˜åŒ–"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šToken ä¼˜åŒ–")
    print("=" * 60)

    code = '''
import tiktoken

def count_tokens(text: str, model: str = "gpt-4") -> int:
    """è®¡ç®—æ–‡æœ¬çš„ token æ•°é‡"""
    encoding = tiktoken.encoding_for_model(model)
    return len(encoding.encode(text))

def estimate_cost(
    input_text: str,
    output_tokens: int,
    model: str = "gpt-4o"
) -> float:
    """ä¼°ç®— API è°ƒç”¨æˆæœ¬"""
    prices = {
        "gpt-4o": {"input": 2.5/1e6, "output": 10/1e6},
        "gpt-4o-mini": {"input": 0.15/1e6, "output": 0.6/1e6},
    }

    input_tokens = count_tokens(input_text, model)
    price = prices[model]

    cost = input_tokens * price["input"] + output_tokens * price["output"]
    return cost

# ä¼˜åŒ–ç¤ºä¾‹ï¼šç²¾ç®€æç¤ºè¯
verbose_prompt = """
æˆ‘æƒ³è¯·ä½ å¸®æˆ‘å®Œæˆä¸€ä¸ªä»»åŠ¡ã€‚è¿™ä¸ªä»»åŠ¡éå¸¸é‡è¦ã€‚
è¯·ä½ ä»”ç»†é˜…è¯»ä»¥ä¸‹å†…å®¹ï¼Œç„¶åç»™å‡ºä½ çš„å›ç­”ã€‚
åœ¨å›ç­”æ—¶ï¼Œè¯·ç¡®ä¿......ï¼ˆå†—é•¿çš„è¯´æ˜ï¼‰
"""

concise_prompt = """
ä»»åŠ¡ï¼š{task}
è¦æ±‚ï¼šç®€æ´å›ç­”ï¼Œ2å¥è¯ä»¥å†…
"""

print(f"å†—é•¿ç‰ˆ tokens: {count_tokens(verbose_prompt)}")
print(f"ç²¾ç®€ç‰ˆ tokens: {count_tokens(concise_prompt)}")
'''
    print(code)


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šç¼“å­˜ç­–ç•¥ ====================


def caching_strategy():
    """ç¼“å­˜ç­–ç•¥"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šç¼“å­˜ç­–ç•¥")
    print("=" * 60)

    code = '''
import hashlib
import json
from functools import lru_cache

class LLMCache:
    """LLM å“åº”ç¼“å­˜"""

    def __init__(self, redis_client=None):
        self.redis = redis_client
        self.local_cache = {}

    def _get_cache_key(self, prompt: str, model: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = f"{model}:{prompt}"
        return hashlib.md5(content.encode()).hexdigest()

    def get(self, prompt: str, model: str) -> str | None:
        """è·å–ç¼“å­˜"""
        key = self._get_cache_key(prompt, model)

        # å…ˆæŸ¥æœ¬åœ°ç¼“å­˜
        if key in self.local_cache:
            return self.local_cache[key]

        # å†æŸ¥ Redis
        if self.redis:
            cached = self.redis.get(key)
            if cached:
                return cached.decode()

        return None

    def set(self, prompt: str, model: str, response: str, ttl: int = 3600):
        """è®¾ç½®ç¼“å­˜"""
        key = self._get_cache_key(prompt, model)
        self.local_cache[key] = response

        if self.redis:
            self.redis.setex(key, ttl, response)

# ä½¿ç”¨ç¤ºä¾‹
cache = LLMCache()

def generate_with_cache(prompt: str, model: str = "gpt-4o"):
    # æ£€æŸ¥ç¼“å­˜
    cached = cache.get(prompt, model)
    if cached:
        print("å‘½ä¸­ç¼“å­˜ï¼ŒèŠ‚çœ API è°ƒç”¨")
        return cached

    # è°ƒç”¨ API
    response = client.chat.completions.create(...)

    # å­˜å…¥ç¼“å­˜
    cache.set(prompt, model, response.choices[0].message.content)
    return response.choices[0].message.content
'''
    print(code)


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šæ¨¡å‹è·¯ç”± ====================


def model_routing():
    """æ¨¡å‹è·¯ç”±ç­–ç•¥"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šæ¨¡å‹è·¯ç”±ç­–ç•¥")
    print("=" * 60)

    code = '''
class SmartRouter:
    """æ™ºèƒ½æ¨¡å‹è·¯ç”±å™¨"""

    def __init__(self):
        self.models = {
            "simple": "gpt-4o-mini",    # ç®€å•ä»»åŠ¡
            "complex": "gpt-4o",         # å¤æ‚ä»»åŠ¡
            "creative": "gpt-4o",        # åˆ›æ„ä»»åŠ¡
        }

    def classify_task(self, prompt: str) -> str:
        """åˆ†ç±»ä»»åŠ¡å¤æ‚åº¦"""
        # ç®€å•è§„åˆ™åˆ¤æ–­
        if len(prompt) < 100 and "ç®€å•" in prompt:
            return "simple"
        elif any(w in prompt for w in ["ä»£ç ", "åˆ†æ", "æ¨ç†", "å¤æ‚"]):
            return "complex"
        else:
            return "simple"

    def route(self, prompt: str) -> str:
        """è·¯ç”±åˆ°åˆé€‚çš„æ¨¡å‹"""
        task_type = self.classify_task(prompt)
        return self.models[task_type]

# ä½¿ç”¨
router = SmartRouter()

def smart_generate(prompt: str):
    model = router.route(prompt)
    print(f"ä½¿ç”¨æ¨¡å‹: {model}")
    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}]
    )
    return response
'''
    print(code)


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šæˆæœ¬ç›‘æ§ ====================


def cost_monitoring():
    """æˆæœ¬ç›‘æ§"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šæˆæœ¬ç›‘æ§")
    print("=" * 60)

    code = '''
class CostTracker:
    """æˆæœ¬è¿½è¸ªå™¨"""

    def __init__(self):
        self.usage_log = []
        self.total_cost = 0

    def log_usage(
        self,
        model: str,
        input_tokens: int,
        output_tokens: int,
        user_id: str = None
    ):
        """è®°å½•ä½¿ç”¨é‡"""
        cost = self._calculate_cost(model, input_tokens, output_tokens)

        self.usage_log.append({
            "timestamp": datetime.now().isoformat(),
            "model": model,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "cost": cost,
            "user_id": user_id
        })

        self.total_cost += cost
        return cost

    def get_daily_report(self) -> dict:
        """è·å–æ—¥æŠ¥"""
        today = datetime.now().date()
        today_logs = [
            log for log in self.usage_log
            if log["timestamp"].startswith(str(today))
        ]

        return {
            "date": str(today),
            "total_requests": len(today_logs),
            "total_tokens": sum(l["input_tokens"] + l["output_tokens"] for l in today_logs),
            "total_cost": sum(l["cost"] for l in today_logs),
            "by_model": self._group_by_model(today_logs)
        }

    def check_budget(self, budget: float) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¶…é¢„ç®—"""
        if self.total_cost >= budget:
            print(f"âš ï¸ å·²è¾¾åˆ°é¢„ç®—ä¸Šé™: ${budget}")
            return False
        return True
'''
    print(code)


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šç»ƒä¹  ====================


def exercises():
    """ç»ƒä¹ """
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šå®ç°ä¸€ä¸ªå¸¦ç¼“å­˜çš„ LLM è°ƒç”¨å‡½æ•°
    ç»ƒä¹  2ï¼šè®¾è®¡ä¸€ä¸ªåŸºäºä»»åŠ¡å¤æ‚åº¦çš„æ¨¡å‹è·¯ç”±ç­–ç•¥

    æ€è€ƒé¢˜ï¼šå¦‚ä½•åœ¨è´¨é‡å’Œæˆæœ¬ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ï¼Ÿ
    ç­”æ¡ˆï¼š1. æ ¹æ®ä»»åŠ¡é‡è¦æ€§é€‰æ‹©æ¨¡å‹
          2. åˆ©ç”¨ç¼“å­˜å‡å°‘é‡å¤è°ƒç”¨
          3. ä¼˜åŒ–æç¤ºè¯å‡å°‘ token
          4. ç›‘æ§æˆæœ¬è®¾ç½®é¢„ç®—å‘Šè­¦
    """)


def main():
    introduction()
    token_optimization()
    caching_strategy()
    model_routing()
    cost_monitoring()
    exercises()
    print("\n" + "=" * 60)
    print("ğŸ‰ Phase 10 è¯¾ç¨‹å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()
