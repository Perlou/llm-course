"""
评估方法概述
==========

学习目标：
    1. 理解 LLM 评估的重要性和挑战
    2. 掌握评估的三个层次（任务层、能力层、应用层）
    3. 了解主要评估维度和方法分类

核心概念：
    - 评估维度：知识、推理、语言、安全、效率
    - 评估层次：任务层、能力层、应用层
    - 评估方法：自动评估、人工评估、LLM-as-Judge

环境要求：
    - pip install transformers torch
"""


# ==================== 第一部分：为什么需要评估 ====================


def introduction():
    """为什么需要评估"""
    print("=" * 60)
    print("第一部分：为什么需要评估")
    print("=" * 60)

    print("""
    📌 LLM 评估的核心挑战：
    ┌─────────────────────────────────────────────────────────┐
    │  ❓ 如何量化模型能力？    →  评估指标 & 基准测试       │
    │  ❓ 如何发现模型缺陷？    →  多维度评估框架            │
    │  ❓ 如何提升模型表现？    →  微调 & 对齐优化           │
    │  ❓ 如何降低部署成本？    →  量化 & 蒸馏技术           │
    │  ❓ 如何保证安全性？      →  安全评估 & 对齐           │
    └─────────────────────────────────────────────────────────┘

    📌 评估与优化的关系：
    ┌─────────┐      ┌─────────┐      ┌─────────┐
    │  评估   │ ───► │  分析   │ ───► │  优化   │
    └─────────┘      └─────────┘      └─────────┘
         ▲                                  │
         └──────────────────────────────────┘
                     反馈验证
    """)


# ==================== 第二部分：评估维度 ====================


def evaluation_dimensions():
    """评估维度"""
    print("\n" + "=" * 60)
    print("第二部分：评估维度")
    print("=" * 60)

    print("""
                          LLM 评估维度
                               │
        ┌──────────┬──────────┼──────────┬──────────┐
        ▼          ▼          ▼          ▼          ▼
   ┌─────────┐┌─────────┐┌─────────┐┌─────────┐┌─────────┐
   │ 知识能力 ││ 推理能力 ││ 语言能力 ││ 安全性  ││ 效率    │
   └─────────┘└─────────┘└─────────┘└─────────┘└─────────┘
        │          │          │          │          │
   • 事实准确  • 逻辑推理  • 文本生成  • 有害内容  • 推理速度
   • 知识广度  • 数学计算  • 语言理解  • 偏见公平  • 内存占用
   • 专业深度  • 代码生成  • 多语言    • 隐私保护  • 吞吐量

    📌 评估的三个层次：
    ┌─────────┬──────────────────┬───────────────────┐
    │  层次   │      描述        │      评估方法      │
    ├─────────┼──────────────────┼───────────────────┤
    │ 任务层  │ 特定任务完成质量 │ 基准测试、准确率  │
    │ 能力层  │ 底层能力表现     │ 能力探测、消融    │
    │ 应用层  │ 实际场景效果     │ A/B测试、用户反馈 │
    └─────────┴──────────────────┴───────────────────┘
    """)


# ==================== 第三部分：评估方法分类 ====================


def evaluation_methods():
    """评估方法分类"""
    print("\n" + "=" * 60)
    print("第三部分：评估方法分类")
    print("=" * 60)

    print("""
                     LLM 评估方法
                          │
         ┌────────────────┼────────────────┐
         ▼                ▼                ▼
    ┌─────────┐     ┌──────────┐    ┌───────────┐
    │ 自动评估 │     │ 人工评估  │    │LLM-as-Judge│
    └─────────┘     └──────────┘    └───────────┘
         │                │                │
    ┌────┴────┐     ┌─────┴─────┐   ┌─────┴─────┐
    │         │     │           │   │           │
 基准测试  指标计算  众包评估  专家评估  单模型  多模型

    📌 方法对比：
    ┌────────────┬──────────────┬────────────┬────────────┐
    │   方法     │    成本      │   一致性   │   灵活性   │
    ├────────────┼──────────────┼────────────┼────────────┤
    │ 自动评估   │ 低           │ 高         │ 低         │
    │ 人工评估   │ 高           │ 中         │ 高         │
    │ LLM-Judge  │ 中           │ 中-高      │ 高         │
    └────────────┴──────────────┴────────────┴────────────┘
    """)


# ==================== 第四部分：常见评估指标 ====================


def evaluation_metrics():
    """常见评估指标"""
    print("\n" + "=" * 60)
    print("第四部分：常见评估指标")
    print("=" * 60)

    print("""
    📌 传统 NLP 指标：
    ┌─────────────┬──────────────────┬──────────────────┐
    │   指标      │     适用场景     │       特点       │
    ├─────────────┼──────────────────┼──────────────────┤
    │ Perplexity  │ 语言建模         │ 无需参考答案     │
    │ BLEU        │ 翻译、生成       │ 快速、可复现     │
    │ ROUGE       │ 摘要生成         │ 召回率导向       │
    │ BERTScore   │ 文本生成         │ 语义相似度       │
    │ Accuracy    │ 分类、QA         │ 直观易懂         │
    │ F1 Score    │ 实体识别         │ 平衡精确召回     │
    └─────────────┴──────────────────┴──────────────────┘

    📌 LLM 特有指标：
    - 事实性 (Factuality): 生成内容的事实准确性
    - 连贯性 (Coherence): 文本的逻辑连贯性
    - 指令遵循率: 是否按指令完成任务
    - 幻觉率 (Hallucination): 虚假信息比例
    """)


# ==================== 第五部分：主流评估基准 ====================


def evaluation_benchmarks():
    """主流评估基准"""
    print("\n" + "=" * 60)
    print("第五部分：主流评估基准")
    print("=" * 60)

    print("""
    📌 常用基准测试：
    ┌──────────┬──────────┬──────────┬────────────┐
    │  基准    │ 任务类型 │ 数据规模 │  评估指标  │
    ├──────────┼──────────┼──────────┼────────────┤
    │ MMLU     │ 知识问答 │ 14k      │ Accuracy   │
    │ GSM8K    │ 数学推理 │ 8.5k     │ Accuracy   │
    │ HumanEval│ 代码生成 │ 164      │ pass@k     │
    │ MT-Bench │ 对话能力 │ 80       │ Score(1-10)│
    │ TruthfulQA│ 真实性  │ 817      │ Accuracy   │
    │ C-Eval   │ 中文知识 │ 13k      │ Accuracy   │
    └──────────┴──────────┴──────────┴────────────┘

    知识类: MMLU, ARC, TriviaQA
    推理类: GSM8K, MATH, BBH
    代码类: HumanEval, MBPP, SWE-bench
    综合类: MT-Bench, AlpacaEval, HELM
    """)


# ==================== 第六部分：练习 ====================


def exercises():
    """练习"""
    print("\n" + "=" * 60)
    print("练习与思考")
    print("=" * 60)

    print("""
    练习 1：列出你的 LLM 应用需要评估的维度

        ✅ 参考答案（以 RAG 问答系统为例）：
        
        ```python
        # RAG 问答系统评估维度
        evaluation_dimensions = {
            # 1. 检索质量
            "retrieval": {
                "metrics": ["Context Precision", "Context Recall", "MRR", "NDCG"],
                "weight": 0.3,
                "description": "检索文档的相关性和完整性"
            },
            
            # 2. 生成质量
            "generation": {
                "metrics": ["Faithfulness", "Answer Relevancy", "Coherence"],
                "weight": 0.35,
                "description": "回答的准确性、相关性和连贯性"
            },
            
            # 3. 安全性
            "safety": {
                "metrics": ["Toxicity", "Bias", "PII Leakage"],
                "weight": 0.2,
                "description": "回答的安全性和合规性"
            },
            
            # 4. 效率
            "efficiency": {
                "metrics": ["Latency", "Throughput", "Cost per Query"],
                "weight": 0.15,
                "description": "响应速度和资源消耗"
            }
        }
        
        # 根据应用场景调整权重
        # - 医疗领域：提高 safety 权重到 0.35
        # - 客服场景：提高 efficiency 权重
        # - 知识库：提高 retrieval 权重
        ```
    
    练习 2：选择适合你应用场景的评估基准

        ✅ 参考答案：
        
        ```
        ┌────────────────┬────────────────────┬─────────────────────┐
        │   应用场景     │    推荐基准        │     评估指标        │
        ├────────────────┼────────────────────┼─────────────────────┤
        │ 通用问答       │ TriviaQA, NQ       │ EM, F1              │
        │ 代码助手       │ HumanEval, MBPP    │ pass@k              │
        │ 中文应用       │ C-Eval, CMMLU      │ Accuracy            │
        │ 数学推理       │ GSM8K, MATH        │ Accuracy + CoT      │
        │ RAG 系统       │ Ragas, RGB         │ 忠实度、相关性      │
        │ 对话系统       │ MT-Bench           │ 1-10 分评分         │
        └────────────────┴────────────────────┴─────────────────────┘
        ```
        
        选择原则：
        1. 任务对齐 - 基准测试与实际任务相匹配
        2. 难度适中 - 既能区分模型差异又不至于全对/全错
        3. 数据新鲜 - 避免被训练数据污染
        4. 可复现 - 有明确的评估协议

    思考题：为什么单一指标不足以评估 LLM？

        ✅ 答：
        1. 能力多维度 - LLM 涉及知识、推理、语言、安全等多个维度
        2. 指标冲突 - 准确率高不代表无幻觉，流畅度高不代表事实正确
        3. 任务差异 - 不同任务需要不同能力，如代码看逻辑、写作看创意
        4. 目标多元 - 用户关注准确性，产品关注成本，领导关注体验
        5. 取舍权衡 - 过度优化单一指标可能损害其他方面
    """)


def main():
    introduction()
    evaluation_dimensions()
    evaluation_methods()
    evaluation_metrics()
    evaluation_benchmarks()
    exercises()
    print("\n课程完成！下一步：02-automatic-evaluation.py")


if __name__ == "__main__":
    main()
