"""
ä¸Šä¸‹æ–‡ç›¸å…³æ€§è¯„ä¼°
===============

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£ä¸Šä¸‹æ–‡ç›¸å…³æ€§çš„é‡è¦æ€§
    2. å®ç°ä¸Šä¸‹æ–‡ç²¾ç¡®ç‡å’Œå¬å›ç‡è®¡ç®—
    3. ä¼˜åŒ–æ£€ç´¢ç»“æœçš„ç›¸å…³æ€§

æ ¸å¿ƒæ¦‚å¿µï¼š
    - Context Precisionï¼šæ£€ç´¢ç²¾ç¡®ç‡
    - Context Recallï¼šæ£€ç´¢å¬å›ç‡
    - Semantic Similarityï¼šè¯­ä¹‰ç›¸ä¼¼åº¦

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install sentence-transformers numpy
"""

import numpy as np
from typing import List


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸Šä¸‹æ–‡ç›¸å…³æ€§æ¦‚å¿µ ====================


def introduction():
    """ä¸Šä¸‹æ–‡ç›¸å…³æ€§æ¦‚å¿µ"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸Šä¸‹æ–‡ç›¸å…³æ€§æ¦‚å¿µ")
    print("=" * 60)

    print("""
    ğŸ“Œ ä¸ºä»€ä¹ˆå…³æ³¨ä¸Šä¸‹æ–‡ç›¸å…³æ€§ï¼Ÿ
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  RAG ç³»ç»Ÿçš„æ•ˆæœå¾ˆå¤§ç¨‹åº¦å–å†³äºæ£€ç´¢è´¨é‡                   â”‚
    â”‚  â€¢ æ£€ç´¢åˆ°ä¸ç›¸å…³å†…å®¹ â†’ å™ªå£°å¹²æ‰°ï¼Œé™ä½å›ç­”è´¨é‡            â”‚
    â”‚  â€¢ æ£€ç´¢ä¸åˆ°ç›¸å…³å†…å®¹ â†’ ä¿¡æ¯ç¼ºå¤±ï¼Œæ— æ³•æ­£ç¡®å›ç­”            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    ğŸ“Œ æ ¸å¿ƒæŒ‡æ ‡ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Context Precisionâ”‚ æ£€ç´¢ç»“æœä¸­ç›¸å…³å†…å®¹çš„æ¯”ä¾‹           â”‚
    â”‚                  â”‚ = ç›¸å…³æ–‡æ¡£æ•° / æ£€ç´¢æ–‡æ¡£æ€»æ•°         â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Context Recall   â”‚ ç›¸å…³å†…å®¹è¢«æ£€ç´¢åˆ°çš„ç¨‹åº¦             â”‚
    â”‚                  â”‚ = æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯ / æ‰€éœ€æ€»ä¿¡æ¯    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    ğŸ“Œ è¯„ä¼°æµç¨‹ï¼š
    é—®é¢˜ â†’ æ£€ç´¢æ–‡æ¡£ â†’ è®¡ç®—ç›¸å…³æ€§ â†’ ç²¾ç¡®ç‡/å¬å›ç‡
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šè¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®— ====================


def semantic_similarity():
    """è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šè¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—")
    print("=" * 60)

    code = '''
from sentence_transformers import SentenceTransformer
import numpy as np

# åŠ è½½åµŒå…¥æ¨¡å‹
model = SentenceTransformer('all-MiniLM-L6-v2')

def compute_similarity(text1: str, text2: str) -> float:
    """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„è¯­ä¹‰ç›¸ä¼¼åº¦"""
    embeddings = model.encode([text1, text2])
    similarity = np.dot(embeddings[0], embeddings[1]) / (
        np.linalg.norm(embeddings[0]) * np.linalg.norm(embeddings[1])
    )
    return float(similarity)

def compute_relevance_scores(question: str, contexts: list) -> list:
    """è®¡ç®—é—®é¢˜ä¸æ¯ä¸ªä¸Šä¸‹æ–‡çš„ç›¸å…³æ€§åˆ†æ•°"""
    question_embedding = model.encode([question])[0]
    context_embeddings = model.encode(contexts)

    scores = []
    for ctx_emb in context_embeddings:
        similarity = np.dot(question_embedding, ctx_emb) / (
            np.linalg.norm(question_embedding) * np.linalg.norm(ctx_emb)
        )
        scores.append(float(similarity))

    return scores

# ä½¿ç”¨ç¤ºä¾‹
question = "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
contexts = [
    "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ ã€‚",
    "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆæ•£æ­¥ã€‚",
    "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ç§æ–¹æ³•ã€‚"
]
scores = compute_relevance_scores(question, contexts)
# [0.72, 0.15, 0.68] - ç¬¬1å’Œç¬¬3ä¸ªæ–‡æ¡£ç›¸å…³
'''
    print(code)


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šä¸Šä¸‹æ–‡ç²¾ç¡®ç‡ ====================


def context_precision():
    """ä¸Šä¸‹æ–‡ç²¾ç¡®ç‡"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šä¸Šä¸‹æ–‡ç²¾ç¡®ç‡ (Context Precision)")
    print("=" * 60)

    code = '''
def calculate_context_precision(
    question: str,
    contexts: list,
    threshold: float = 0.5
) -> dict:
    """
    è®¡ç®—ä¸Šä¸‹æ–‡ç²¾ç¡®ç‡
    - æ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸­æœ‰å¤šå°‘æ˜¯çœŸæ­£ç›¸å…³çš„
    """
    scores = compute_relevance_scores(question, contexts)
    relevant_count = sum(1 for s in scores if s >= threshold)
    total_count = len(contexts)

    precision = relevant_count / total_count if total_count > 0 else 0

    return {
        "precision": precision,
        "relevant_count": relevant_count,
        "total_count": total_count,
        "scores": scores
    }

# ä½¿ç”¨ç¤ºä¾‹
result = calculate_context_precision(
    question="ä»€ä¹ˆæ˜¯ RAGï¼Ÿ",
    contexts=[
        "RAG æ˜¯æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯...",  # ç›¸å…³
        "ä»Šå¤©è‚¡å¸‚ä¸Šæ¶¨...",           # ä¸ç›¸å…³
        "æ£€ç´¢æ˜¯ RAG çš„æ ¸å¿ƒç»„ä»¶..."    # ç›¸å…³
    ]
)
# precision = 2/3 = 0.67
'''
    print(code)


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šä¸Šä¸‹æ–‡å¬å›ç‡ ====================


def context_recall():
    """ä¸Šä¸‹æ–‡å¬å›ç‡"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šä¸Šä¸‹æ–‡å¬å›ç‡ (Context Recall)")
    print("=" * 60)

    code = '''
def calculate_context_recall(
    answer: str,
    contexts: list,
    ground_truth: str
) -> dict:
    """
    è®¡ç®—ä¸Šä¸‹æ–‡å¬å›ç‡
    - æ­£ç¡®ç­”æ¡ˆä¸­çš„ä¿¡æ¯æœ‰å¤šå°‘è¢«æ£€ç´¢ä¸Šä¸‹æ–‡è¦†ç›–

    éœ€è¦: æ ‡å‡†ç­”æ¡ˆ (ground_truth)
    """
    # å°†æ ‡å‡†ç­”æ¡ˆåˆ†è§£ä¸ºå…³é”®ä¿¡æ¯ç‚¹
    truth_sentences = ground_truth.split('ã€‚')
    truth_sentences = [s.strip() for s in truth_sentences if s.strip()]

    # è®¡ç®—æ¯ä¸ªä¿¡æ¯ç‚¹æ˜¯å¦è¢«ä¸Šä¸‹æ–‡è¦†ç›–
    covered = 0
    context_text = ' '.join(contexts)

    for sentence in truth_sentences:
        # ä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦åˆ¤æ–­æ˜¯å¦è¦†ç›–
        similarity = compute_similarity(sentence, context_text)
        if similarity >= 0.6:  # é˜ˆå€¼
            covered += 1

    recall = covered / len(truth_sentences) if truth_sentences else 0

    return {
        "recall": recall,
        "covered": covered,
        "total_points": len(truth_sentences)
    }
'''
    print(code)


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šä¼˜åŒ–ç­–ç•¥ ====================


def optimization():
    """ä¼˜åŒ–ç­–ç•¥"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šä¼˜åŒ–ä¸Šä¸‹æ–‡ç›¸å…³æ€§")
    print("=" * 60)

    print("""
    ğŸ“Œ æé«˜ Precision çš„æ–¹æ³•ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 1. ä½¿ç”¨ Reranker é‡æ’åº                                â”‚
    â”‚ 2. å‡å°‘ top_kï¼Œåªä¿ç•™æœ€ç›¸å…³çš„                          â”‚
    â”‚ 3. è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤                                  â”‚
    â”‚ 4. ä½¿ç”¨æ›´å¥½çš„åµŒå…¥æ¨¡å‹                                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    ğŸ“Œ æé«˜ Recall çš„æ–¹æ³•ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 1. å¢åŠ  top_k å¬å›æ•°é‡                                 â”‚
    â”‚ 2. ä½¿ç”¨æ··åˆæ£€ç´¢ï¼ˆå…³é”®è¯ + å‘é‡ï¼‰                       â”‚
    â”‚ 3. æŸ¥è¯¢æ‰©å±•/æ”¹å†™                                       â”‚
    â”‚ 4. ä¼˜åŒ–æ–‡æ¡£åˆ‡åˆ†ç­–ç•¥                                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    ğŸ“Œ Precision vs Recall æƒè¡¡ï¼š
    - é«˜ Precisionï¼Œä½ Recall â†’ ä¿¡æ¯ä¸å…¨
    - ä½ Precisionï¼Œé«˜ Recall â†’ å™ªå£°è¿‡å¤š
    - ç›®æ ‡ï¼šä¸¤è€…å¹³è¡¡ (F1 Score)
    """)


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šç»ƒä¹  ====================


def exercises():
    """ç»ƒä¹ """
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šå®ç°ä¸Šä¸‹æ–‡ç›¸å…³æ€§è¯„ä¼°å‡½æ•°
    ç»ƒä¹  2ï¼šå¯¹æ¯”ä¸åŒ top_k è®¾ç½®å¯¹ Precision/Recall çš„å½±å“

    æ€è€ƒé¢˜ï¼šå¦‚ä½•åœ¨ Precision å’Œ Recall ä¹‹é—´å–å¾—å¹³è¡¡ï¼Ÿ
    ç­”æ¡ˆï¼šä½¿ç”¨ Reranker åœ¨å¤§é‡å¬å›çš„åŸºç¡€ä¸Šç²¾é€‰ï¼Œ
          å…ˆä¿è¯ Recallï¼Œå†é€šè¿‡é‡æ’åºæé«˜ Precisionã€‚
    """)


def main():
    introduction()
    semantic_similarity()
    context_precision()
    context_recall()
    optimization()
    exercises()
    print("\nè¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š06-faithfulness.py")


if __name__ == "__main__":
    main()
