"""
Chain åŸºç¡€
==========

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£ Chain çš„æ¦‚å¿µå’Œä½œç”¨
    2. æŒæ¡ LCEL ç®¡é“ç¬¦è¯­æ³•
    3. å­¦ä¼šç»„åˆå¤šä¸ªç»„ä»¶æ„å»ºé“¾

æ ¸å¿ƒæ¦‚å¿µï¼š
    - Chainï¼šå°†å¤šä¸ªç»„ä»¶ä¸²è”æ‰§è¡Œçš„å¤„ç†æµç¨‹
    - LCELï¼šä½¿ç”¨ | ç®¡é“ç¬¦æ„å»ºé“¾
    - Runnableï¼šæ‰€æœ‰å¯æ‰§è¡Œç»„ä»¶çš„åŸºç±»

å‰ç½®çŸ¥è¯†ï¼š
    - 03-prompt-templates.py

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install langchain langchain-google-genai python-dotenv
"""

import os
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šChain æ¦‚å¿µ ====================


def chain_concept():
    """Chain æ¦‚å¿µä»‹ç»"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šChain æ¦‚å¿µ")
    print("=" * 60)

    print("""
    ä»€ä¹ˆæ˜¯ Chainï¼Ÿ
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Chain æ˜¯å°†å¤šä¸ªç»„ä»¶ä¸²è”èµ·æ¥çš„æ‰§è¡Œæµç¨‹ï¼š
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Prompt  â”‚ â”€â–¶ â”‚   LLM    â”‚ â”€â–¶ â”‚  Parser  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    LCEL è¯­æ³•ï¼šchain = prompt | llm | parser
    
    æ ¸å¿ƒæ–¹æ³•ï¼š
    - invoke()  : åŒæ­¥æ‰§è¡Œ
    - stream()  : æµå¼æ‰§è¡Œ
    - batch()   : æ‰¹é‡æ‰§è¡Œ
    - ainvoke() : å¼‚æ­¥æ‰§è¡Œ
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šæ„å»ºåŸºç¡€é“¾ ====================


def basic_chain():
    """æ„å»ºåŸºç¡€é“¾"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šæ„å»ºåŸºç¡€é“¾")
    print("=" * 60)

    try:
        from langchain_google_genai import ChatGoogleGenerativeAI
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser

        # åˆ›å»ºç»„ä»¶
        prompt = ChatPromptTemplate.from_template("ç”¨ä¸€å¥è¯è§£é‡Š{concept}")
        llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")
        parser = StrOutputParser()

        # ä½¿ç”¨ | æ„å»ºé“¾
        chain = prompt | llm | parser

        print("ğŸ“Œ é“¾å·²æ„å»º: prompt | llm | parser")

        # æ‰§è¡Œé“¾
        result = chain.invoke({"concept": "å¾®æœåŠ¡æ¶æ„"})
        print(f"\nç»“æœ: {result}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šé“¾çš„æ ¸å¿ƒæ–¹æ³• ====================


def chain_methods():
    """é“¾çš„æ ¸å¿ƒæ–¹æ³•"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šé“¾çš„æ ¸å¿ƒæ–¹æ³•")
    print("=" * 60)

    try:
        from langchain_google_genai import ChatGoogleGenerativeAI
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser

        prompt = ChatPromptTemplate.from_template("ç”¨ä¸€å¥è¯æè¿°{topic}")
        llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")
        chain = prompt | llm | StrOutputParser()

        # 1. invoke - åŒæ­¥è°ƒç”¨
        print("\nğŸ“Œ 1. invoke() - åŒæ­¥è°ƒç”¨")
        result = chain.invoke({"topic": "Python"})
        print(f"ç»“æœ: {result}")

        # 2. stream - æµå¼è°ƒç”¨
        print("\nğŸ“Œ 2. stream() - æµå¼è°ƒç”¨")
        print("ç»“æœ: ", end="")
        for chunk in chain.stream({"topic": "JavaScript"}):
            print(chunk, end="", flush=True)
        print()

        # 3. batch - æ‰¹é‡è°ƒç”¨
        print("\nğŸ“Œ 3. batch() - æ‰¹é‡è°ƒç”¨")
        topics = [{"topic": "Java"}, {"topic": "Rust"}]
        results = chain.batch(topics)
        for topic, result in zip(topics, results):
            print(f"  {topic['topic']}: {result}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šRunnablePassthrough ====================


def runnable_passthrough():
    """RunnablePassthrough ä½¿ç”¨"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šRunnablePassthrough")
    print("=" * 60)

    print("""
    RunnablePassthrough ç”¨äºï¼š
    - ä¼ é€’è¾“å…¥åˆ°ä¸‹ä¸€æ­¥
    - åœ¨é“¾ä¸­ä¿ç•™åŸå§‹è¾“å…¥
    """)

    try:
        from langchain_google_genai import ChatGoogleGenerativeAI
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser
        from langchain_core.runnables import RunnablePassthrough

        # ç¤ºä¾‹: ä¿ç•™åŸå§‹é—®é¢˜
        prompt = ChatPromptTemplate.from_template("é—®é¢˜: {question}\n\nè¯·ç®€æ´å›ç­”ã€‚")
        llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")

        chain = {"question": RunnablePassthrough()} | prompt | llm | StrOutputParser()

        result = chain.invoke("ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ")
        print(f"ç»“æœ: {result}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šRunnableLambda ====================


def runnable_lambda():
    """RunnableLambda ä½¿ç”¨"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šRunnableLambda")
    print("=" * 60)

    try:
        from langchain_google_genai import ChatGoogleGenerativeAI
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser
        from langchain_core.runnables import RunnableLambda

        # è‡ªå®šä¹‰å¤„ç†å‡½æ•°
        def preprocess(text: str) -> str:
            return text.strip().upper()

        def postprocess(text: str) -> str:
            return f"ã€æ€»ç»“ã€‘{text}"

        prompt = ChatPromptTemplate.from_template("è§£é‡Š: {input}")
        llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")

        chain = (
            RunnableLambda(preprocess)
            | {"input": RunnableLambda(lambda x: x)}
            | prompt
            | llm
            | StrOutputParser()
            | RunnableLambda(postprocess)
        )

        result = chain.invoke("  machine learning  ")
        print(f"ç»“æœ: {result}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šæ„å»ºç¿»è¯‘é“¾
        åˆ›å»ºä¸€ä¸ªä¸­è‹±äº’è¯‘çš„é“¾ã€‚

    ç»ƒä¹  2ï¼šå¸¦é¢„å¤„ç†çš„é“¾
        ä½¿ç”¨ RunnableLambda æ¸…ç†è¾“å…¥åå†å¤„ç†ã€‚

    ç»ƒä¹  3ï¼šæ‰¹é‡å¤„ç†
        ä½¿ç”¨ batch() åŒæ—¶ç¿»è¯‘å¤šæ®µæ–‡æœ¬ã€‚

    æ€è€ƒé¢˜ï¼š
        1. LCEL ç›¸æ¯”ä¼ ç»Ÿé“¾æœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ
        2. ä½•æ—¶ä½¿ç”¨ stream() è€Œä¸æ˜¯ invoke()ï¼Ÿ
    """)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Chain åŸºç¡€")
    print("=" * 60)

    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯ï¼šæœªè®¾ç½® GOOGLE_API_KEY")
        return

    try:
        chain_concept()
        basic_chain()
        chain_methods()
        runnable_passthrough()
        runnable_lambda()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        return

    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š05-lcel-expressions.py")
    print("=" * 60)


if __name__ == "__main__":
    main()
