"""
LCEL è¡¨è¾¾å¼
===========

å­¦ä¹ ç›®æ ‡ï¼š
    1. æ·±å…¥ç†è§£ LCEL è¯­æ³•
    2. æŒæ¡ RunnableParallel å¹¶è¡Œæ‰§è¡Œ
    3. å­¦ä¼šä½¿ç”¨ RunnableBranch æ¡ä»¶åˆ†æ”¯

æ ¸å¿ƒæ¦‚å¿µï¼š
    - RunnableParallelï¼šå¹¶è¡Œæ‰§è¡Œå¤šä¸ªé“¾
    - RunnableBranchï¼šæ¡ä»¶åˆ†æ”¯é€‰æ‹©
    - bind()ï¼šç»‘å®šå‚æ•°

å‰ç½®çŸ¥è¯†ï¼š
    - 04-chains-basics.py

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install langchain langchain-google-genai python-dotenv
"""

import os
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šLCEL æ ¸å¿ƒè¯­æ³• ====================


def lcel_syntax():
    """LCEL æ ¸å¿ƒè¯­æ³•"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šLCEL æ ¸å¿ƒè¯­æ³•")
    print("=" * 60)

    print("""
    LCEL æ ¸å¿ƒæ“ä½œç¬¦ï¼š
    
    | æ“ä½œç¬¦ | ç±»å‹   | è¯´æ˜                    |
    |-------|-------|------------------------|
    |   |   | ç®¡é“ç¬¦ | ä¸²è”ç»„ä»¶ï¼Œå‰ä¸€ä¸ªè¾“å‡ºæ˜¯åä¸€ä¸ªè¾“å…¥ |
    |  {}   | å­—å…¸   | æ„é€ å­—å…¸ï¼Œå¯å¹¶è¡Œæ‰§è¡Œå¤šä¸ªåˆ†æ”¯   |
    
    æ ¸å¿ƒ Runnableï¼š
    - RunnablePassthrough: é€ä¼ è¾“å…¥
    - RunnableLambda: è‡ªå®šä¹‰å‡½æ•°
    - RunnableParallel: å¹¶è¡Œæ‰§è¡Œ
    - RunnableBranch: æ¡ä»¶åˆ†æ”¯
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šRunnableParallel å¹¶è¡Œæ‰§è¡Œ ====================


def runnable_parallel():
    """RunnableParallel å¹¶è¡Œæ‰§è¡Œ"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šRunnableParallel å¹¶è¡Œæ‰§è¡Œ")
    print("=" * 60)

    try:
        from langchain_google_genai import ChatGoogleGenerativeAI
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser
        from langchain_core.runnables import RunnableParallel

        llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")

        # åˆ›å»ºå¹¶è¡Œé“¾
        parallel_chain = RunnableParallel(
            summary=ChatPromptTemplate.from_template("ç”¨ä¸€å¥è¯æ€»ç»“{topic}")
            | llm
            | StrOutputParser(),
            keywords=ChatPromptTemplate.from_template("åˆ—å‡º{topic}çš„3ä¸ªå…³é”®è¯")
            | llm
            | StrOutputParser(),
            question=ChatPromptTemplate.from_template("é’ˆå¯¹{topic}æä¸€ä¸ªé—®é¢˜")
            | llm
            | StrOutputParser(),
        )

        print("ğŸ“Œ å¹¶è¡Œæ‰§è¡Œä¸‰ä¸ªä»»åŠ¡...")
        result = parallel_chain.invoke({"topic": "äººå·¥æ™ºèƒ½"})

        print(f"\næ€»ç»“: {result['summary']}")
        print(f"\nå…³é”®è¯: {result['keywords']}")
        print(f"\né—®é¢˜: {result['question']}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šRunnableBranch æ¡ä»¶åˆ†æ”¯ ====================


def runnable_branch():
    """RunnableBranch æ¡ä»¶åˆ†æ”¯"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šRunnableBranch æ¡ä»¶åˆ†æ”¯")
    print("=" * 60)

    try:
        from langchain_google_genai import ChatGoogleGenerativeAI
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser
        from langchain_core.runnables import RunnableBranch

        llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")

        # åˆ†ç±»å‡½æ•°
        def is_technical(x):
            keywords = ["ä»£ç ", "ç¼–ç¨‹", "æŠ€æœ¯", "API", "ç®—æ³•"]
            return any(k in x["input"] for k in keywords)

        # æ¡ä»¶åˆ†æ”¯é“¾
        branch_chain = RunnableBranch(
            (
                is_technical,
                ChatPromptTemplate.from_template("ä½œä¸ºæŠ€æœ¯ä¸“å®¶å›ç­”: {input}")
                | llm
                | StrOutputParser(),
            ),
            # é»˜è®¤åˆ†æ”¯
            ChatPromptTemplate.from_template("ä½œä¸ºé€šç”¨åŠ©æ‰‹å›ç­”: {input}")
            | llm
            | StrOutputParser(),
        )

        print("ğŸ“Œ æŠ€æœ¯é—®é¢˜è·¯ç”±åˆ°æŠ€æœ¯ä¸“å®¶")
        result1 = branch_chain.invoke({"input": "å¦‚ä½•ä¼˜åŒ–Pythonä»£ç æ€§èƒ½ï¼Ÿ"})
        print(f"ç»“æœ: {result1}")

        print("\nğŸ“Œ é€šç”¨é—®é¢˜è·¯ç”±åˆ°é€šç”¨åŠ©æ‰‹")
        result2 = branch_chain.invoke({"input": "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"})
        print(f"ç»“æœ: {result2}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šbind ç»‘å®šå‚æ•° ====================


def bind_parameters():
    """bind ç»‘å®šå‚æ•°"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šbind ç»‘å®šå‚æ•°")
    print("=" * 60)

    try:
        from langchain_google_genai import ChatGoogleGenerativeAI
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser

        llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")

        # ç»‘å®šåœæ­¢è¯
        llm_with_stop = llm.bind(stop=["\n\n"])

        prompt = ChatPromptTemplate.from_template("åˆ—å‡º{topic}çš„ä¼˜ç‚¹ï¼š")
        chain = prompt | llm_with_stop | StrOutputParser()

        print("ğŸ“Œ ä½¿ç”¨ bind ç»‘å®šåœæ­¢è¯")
        result = chain.invoke({"topic": "Python"})
        print(f"ç»“æœ: {result}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šwith_fallbacks å›é€€æœºåˆ¶ ====================


def fallbacks_demo():
    """with_fallbacks å›é€€æœºåˆ¶"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šwith_fallbacks å›é€€æœºåˆ¶")
    print("=" * 60)

    try:
        from langchain_google_genai import ChatGoogleGenerativeAI
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser

        # ä¸»æ¨¡å‹å’Œå›é€€æ¨¡å‹ï¼ˆéƒ½ä½¿ç”¨ Geminiï¼‰
        primary = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.7)
        fallback = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.3)

        # é…ç½®å›é€€
        llm_with_fallback = primary.with_fallbacks([fallback])

        prompt = ChatPromptTemplate.from_template("è§£é‡Š{concept}")
        chain = prompt | llm_with_fallback | StrOutputParser()

        print("ğŸ“Œ ä½¿ç”¨ with_fallbacks é…ç½®å›é€€")
        result = chain.invoke({"concept": "é‡å­è®¡ç®—"})
        print(f"ç»“æœ: {result}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šå¹¶è¡Œåˆ†æ
        ä½¿ç”¨ RunnableParallel åŒæ—¶åˆ†ææ–‡æœ¬çš„æƒ…æ„Ÿå’Œæ‘˜è¦ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        from langchain_google_genai import ChatGoogleGenerativeAI
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser
        from langchain_core.runnables import RunnableParallel

        llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")

        analysis_chain = RunnableParallel(
            sentiment=ChatPromptTemplate.from_template(
                "åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼ˆæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰ï¼š{text}"
            ) | llm | StrOutputParser(),
            summary=ChatPromptTemplate.from_template(
                "ç”¨ä¸€å¥è¯æ€»ç»“ä»¥ä¸‹æ–‡æœ¬ï¼š{text}"
            ) | llm | StrOutputParser(),
            keywords=ChatPromptTemplate.from_template(
                "æå–ä»¥ä¸‹æ–‡æœ¬çš„3ä¸ªå…³é”®è¯ï¼š{text}"
            ) | llm | StrOutputParser(),
        )

        result = analysis_chain.invoke({"text": "è¿™æ¬¾äº§å“è´¨é‡éå¸¸å¥½ï¼Œå€¼å¾—æ¨è"})
        print(f"æƒ…æ„Ÿ: {result['sentiment']}")
        print(f"æ‘˜è¦: {result['summary']}")
        print(f"å…³é”®è¯: {result['keywords']}")
        ```

    ç»ƒä¹  2ï¼šæ™ºèƒ½è·¯ç”±
        ä½¿ç”¨ RunnableBranch æ ¹æ®é—®é¢˜ç±»å‹é€‰æ‹©ä¸åŒå¤„ç†ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        from langchain_core.runnables import RunnableBranch

        def is_math_question(x):
            keywords = ["è®¡ç®—", "æ±‚", "ç­‰äº", "+", "-", "*", "/"]
            return any(k in x["input"] for k in keywords)

        def is_code_question(x):
            keywords = ["ä»£ç ", "ç¨‹åº", "å‡½æ•°", "bug", "é”™è¯¯"]
            return any(k in x["input"] for k in keywords)

        smart_router = RunnableBranch(
            (is_math_question,
             ChatPromptTemplate.from_template("ä½œä¸ºæ•°å­¦ä¸“å®¶è§£ç­”: {input}") | llm | StrOutputParser()),
            (is_code_question,
             ChatPromptTemplate.from_template("ä½œä¸ºç¼–ç¨‹ä¸“å®¶è§£ç­”: {input}") | llm | StrOutputParser()),
            # é»˜è®¤
            ChatPromptTemplate.from_template("å›ç­”: {input}") | llm | StrOutputParser()
        )
        ```

    ç»ƒä¹  3ï¼šå›é€€é“¾
        é…ç½®å¤šä¸ªå›é€€æ¨¡å‹ç¡®ä¿æœåŠ¡å¯ç”¨æ€§ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        # ä¸»æ¨¡å‹
        primary = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.7)
        
        # å›é€€æ¨¡å‹ï¼ˆå¯ä»¥ç”¨ä¸åŒé…ç½®æˆ–ä¸åŒæ¨¡å‹ï¼‰
        fallback1 = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.3)
        fallback2 = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.5)

        # é…ç½®å›é€€é“¾
        robust_llm = primary.with_fallbacks([fallback1, fallback2])

        # åœ¨é“¾ä¸­ä½¿ç”¨
        chain = prompt | robust_llm | StrOutputParser()
        ```

    æ€è€ƒé¢˜ï¼š
        1. å¹¶è¡Œæ‰§è¡Œæœ‰ä»€ä¹ˆæ€§èƒ½ä¼˜åŠ¿ï¼Ÿ
           
           âœ… ç­”æ¡ˆï¼š
           - å‡å°‘æ€»è€—æ—¶ï¼šå¤šä¸ª API è°ƒç”¨åŒæ—¶è¿›è¡Œ
           - æé«˜ååé‡ï¼šå……åˆ†åˆ©ç”¨ç½‘ç»œ I/O
           - é€‚åˆç‹¬ç«‹ä»»åŠ¡ï¼šå„åˆ†æ”¯äº’ä¸ä¾èµ–æ—¶æ•ˆæœæœ€ä½³
           - æ³¨æ„ï¼šå¹¶è¡Œä¼šæ¶ˆè€—æ›´å¤š token é…é¢

        2. æ¡ä»¶åˆ†æ”¯æœ‰ä»€ä¹ˆåº”ç”¨åœºæ™¯ï¼Ÿ
           
           âœ… ç­”æ¡ˆï¼š
           - æ™ºèƒ½é—®ç­”è·¯ç”±ï¼šæŠ€æœ¯/ç”Ÿæ´»/å­¦ä¹ é—®é¢˜åˆ†å‘
           - å¤šæ¨¡å‹é€‰æ‹©ï¼šæ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ¨¡å‹
           - è¯­è¨€æ£€æµ‹ï¼šè‡ªåŠ¨é€‰æ‹©å¯¹åº”è¯­è¨€å¤„ç†
           - æ•æ„Ÿå†…å®¹è¿‡æ»¤ï¼šæ•æ„Ÿé—®é¢˜ç‰¹æ®Šå¤„ç†
    """)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ LCEL è¡¨è¾¾å¼")
    print("=" * 60)

    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯ï¼šæœªè®¾ç½® GOOGLE_API_KEY")
        return

    try:
        lcel_syntax()
        runnable_parallel()
        runnable_branch()
        bind_parameters()
        fallbacks_demo()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        return

    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š06-sequential-chains.py")
    print("=" * 60)


if __name__ == "__main__":
    main()
