"""
LLM æ¨¡å‹å°è£… - Gemini ç‰ˆæœ¬
==========================

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£ LangChain ä¸­çš„æ¨¡å‹ç±»å‹
    2. æŒæ¡ ChatGoogleGenerativeAI çš„é…ç½®å’Œä½¿ç”¨
    3. äº†è§£ Embeddings æ¨¡å‹çš„ä½¿ç”¨

æ ¸å¿ƒæ¦‚å¿µï¼š
    - Chat Modelsï¼šåŸºäºæ¶ˆæ¯çš„å¯¹è¯æ¨¡å‹
    - Embeddingsï¼šæ–‡æœ¬å‘é‡åŒ–æ¨¡å‹

å‰ç½®çŸ¥è¯†ï¼š
    - 01-langchain-intro.py

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install langchain langchain-google-genai python-dotenv
"""

import os
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šæ¨¡å‹ç±»å‹æ¦‚è¿° ====================


def model_types_overview():
    """æ¨¡å‹ç±»å‹æ¦‚è¿°"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šæ¨¡å‹ç±»å‹æ¦‚è¿°")
    print("=" * 60)

    print("""
    LangChain ä¸­çš„æ¨¡å‹ç±»å‹ï¼š
    
    | ç±»å‹        | è¾“å…¥           | è¾“å‡º        | å…¸å‹æ¨¡å‹          |
    |------------|---------------|------------|------------------|
    | Chat Models| æ¶ˆæ¯åˆ—è¡¨       | AIæ¶ˆæ¯å¯¹è±¡   | gemini-2.0-flash |
    | Embeddings | æ–‡æœ¬           | å‘é‡        | gemini-embedding-001    |
    
    ğŸ’¡ Chat Models æœ€å¸¸ç”¨ï¼Œæ˜¯å¼€å‘çš„é¦–é€‰ã€‚
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šChat Models è¯¦è§£ ====================


def chat_models_demo():
    """Chat Models è¯¦è§£"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šChat Models è¯¦è§£")
    print("=" * 60)

    try:
        from langchain_google_genai import ChatGoogleGenerativeAI
        from langchain_core.messages import HumanMessage, SystemMessage

        # åˆ›å»ºæ¨¡å‹
        llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.7)
        print(f"\nâœ… æ¨¡å‹å·²åˆ›å»º: gemini-2.0-flash")

        # ç®€å•è°ƒç”¨
        print("\nğŸ“Œ ç®€å•è°ƒç”¨ï¼š")
        response = llm.invoke("ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯ LangChain")
        print(f"å›å¤: {response.content}")

        # ä½¿ç”¨æ¶ˆæ¯åˆ—è¡¨
        print("\nğŸ“Œ ä½¿ç”¨æ¶ˆæ¯åˆ—è¡¨ï¼š")
        messages = [
            SystemMessage(content="ä½ æ˜¯ Python ä¸“å®¶"),
            HumanMessage(content="åˆ—è¡¨æ¨å¯¼å¼æ˜¯ä»€ä¹ˆï¼Ÿ"),
        ]
        response = llm.invoke(messages)
        print(f"å›å¤: {response.content}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ¨¡å‹é…ç½® ====================


def model_configuration():
    """æ¨¡å‹é…ç½®"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ¨¡å‹é…ç½®")
    print("=" * 60)

    print("""
    å…³é”®å‚æ•°ï¼š
    - temperature (0-2): 0=ç¡®å®šæ€§, 1+=åˆ›é€ æ€§
    - max_output_tokens: æœ€å¤§è¾“å‡ºé•¿åº¦
    - timeout: è¶…æ—¶æ—¶é—´
    - max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    """)

    try:
        from langchain_google_genai import ChatGoogleGenerativeAI

        # å¯¹æ¯”ä¸åŒæ¸©åº¦
        print("\nğŸ“Œ æ¸©åº¦å¯¹æ¯”ï¼š")
        prompt = "ç”¨ä¸€å¥è¯æè¿°æœˆäº®"

        llm_low = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)
        llm_high = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=1.2)

        print(f"temperature=0: {llm_low.invoke(prompt).content}")
        print(f"temperature=1.2: {llm_high.invoke(prompt).content}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šEmbeddings æ¨¡å‹ ====================


def embeddings_demo():
    """Embeddings æ¨¡å‹æ¼”ç¤º"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šEmbeddings æ¨¡å‹")
    print("=" * 60)

    print("""
    Embeddings å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ï¼Œç”¨äºï¼š
    - è¯­ä¹‰æœç´¢
    - æ–‡æ¡£ç›¸ä¼¼åº¦
    - RAG åº”ç”¨
    """)

    try:
        from langchain_google_genai import GoogleGenerativeAIEmbeddings
        import numpy as np

        embeddings = GoogleGenerativeAIEmbeddings(model="models/gemini-embedding-001")

        # å•ä¸ªæ–‡æœ¬åµŒå…¥
        text = "LangChain æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ¡†æ¶"
        vector = embeddings.embed_query(text)
        print(f"\næ–‡æœ¬: {text}")
        print(f"å‘é‡ç»´åº¦: {len(vector)}")

        # ç›¸ä¼¼åº¦è®¡ç®—
        texts = ["Python ç¼–ç¨‹", "Java ç¼–ç¨‹", "çƒ¹é¥ªæŠ€å·§"]
        vectors = embeddings.embed_documents(texts)

        def cosine_sim(v1, v2):
            v1, v2 = np.array(v1), np.array(v2)
            return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

        print(
            f"\nç›¸ä¼¼åº¦: '{texts[0]}' vs '{texts[1]}': {cosine_sim(vectors[0], vectors[1]):.4f}"
        )
        print(
            f"ç›¸ä¼¼åº¦: '{texts[0]}' vs '{texts[2]}': {cosine_sim(vectors[0], vectors[2]):.4f}"
        )

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šåˆ›å»ºä»£ç ç”Ÿæˆæ¨¡å‹
        ä½¿ç”¨ä½æ¸©åº¦å’Œå¤§ max_output_tokens åˆ›å»ºé€‚åˆä»£ç ç”Ÿæˆçš„æ¨¡å‹ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        from langchain_google_genai import ChatGoogleGenerativeAI

        # ä»£ç ç”Ÿæˆæ¨¡å‹é…ç½®
        code_llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash",
            temperature=0.2,          # ä½æ¸©åº¦ä¿è¯ä¸€è‡´æ€§
            max_output_tokens=2048,   # è¶³å¤Ÿé•¿çš„ä»£ç è¾“å‡º
            timeout=60,               # è¾ƒé•¿è¶…æ—¶
        )

        # ä½¿ç”¨
        response = code_llm.invoke("å†™ä¸€ä¸ª Python å¿«é€Ÿæ’åºå‡½æ•°")
        print(response.content)
        ```

    ç»ƒä¹  2ï¼šå¤šè½®å¯¹è¯
        ä½¿ç”¨æ¶ˆæ¯åˆ—è¡¨å®ç°è¿ç»­çš„å¤šè½®å¯¹è¯ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        from langchain_google_genai import ChatGoogleGenerativeAI
        from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

        llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")

        # å¤šè½®å¯¹è¯æ¶ˆæ¯
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹"),
            HumanMessage(content="ä½ å¥½ï¼Œæˆ‘å«å°æ˜"),
            AIMessage(content="ä½ å¥½å°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼"),
            HumanMessage(content="æˆ‘ä¹‹å‰å‘Šè¯‰è¿‡ä½ æˆ‘çš„åå­—ï¼Œä½ è¿˜è®°å¾—å—ï¼Ÿ"),
        ]

        response = llm.invoke(messages)
        print(response.content)  # ä¼šå›ç­” "å°æ˜"
        ```

    ç»ƒä¹  3ï¼šæ–‡æœ¬ç›¸ä¼¼åº¦æœç´¢
        ä½¿ç”¨ Embeddings æ‰¾å‡ºæœ€ç›¸ä¼¼çš„æ–‡æ¡£ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        from langchain_google_genai import GoogleGenerativeAIEmbeddings
        import numpy as np

        embeddings = GoogleGenerativeAIEmbeddings(model="models/gemini-embedding-001")

        def cosine_similarity(v1, v2):
            v1, v2 = np.array(v1), np.array(v2)
            return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

        # æ–‡æ¡£åº“
        documents = [
            "Python æ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€",
            "æœºå™¨å­¦ä¹ éœ€è¦å¤§é‡æ•°æ®",
            "ä»Šå¤©å¤©æ°”æ™´æœ—",
            "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯"
        ]

        # æŸ¥è¯¢
        query = "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½"

        # å‘é‡åŒ–
        query_vec = embeddings.embed_query(query)
        doc_vecs = embeddings.embed_documents(documents)

        # æ‰¾æœ€ç›¸ä¼¼
        similarities = [cosine_similarity(query_vec, dv) for dv in doc_vecs]
        most_similar_idx = np.argmax(similarities)
        print(f"æœ€ç›¸ä¼¼æ–‡æ¡£: {documents[most_similar_idx]}")
        ```

    æ€è€ƒé¢˜ï¼š
        1. ä»€ä¹ˆæ—¶å€™ä½¿ç”¨ä½æ¸©åº¦ vs é«˜æ¸©åº¦ï¼Ÿ
           
           âœ… ç­”æ¡ˆï¼š
           - ä½æ¸©åº¦ (0-0.3)ï¼šä»£ç ç”Ÿæˆã€äº‹å®é—®ç­”ã€æ•°æ®æå–
           - ä¸­ç­‰æ¸©åº¦ (0.5-0.7)ï¼šé€šç”¨å¯¹è¯ã€æ–‡æ¡£æ€»ç»“
           - é«˜æ¸©åº¦ (0.8-1.2)ï¼šåˆ›æ„å†™ä½œã€å¤´è„‘é£æš´ã€æ•…äº‹ç”Ÿæˆ
           - å…³é”®åŸåˆ™ï¼šéœ€è¦ç¡®å®šæ€§ç”¨ä½æ¸©åº¦ï¼Œéœ€è¦åˆ›æ„ç”¨é«˜æ¸©åº¦

        2. Embeddings æœ‰ä»€ä¹ˆå®é™…åº”ç”¨ï¼Ÿ
           
           âœ… ç­”æ¡ˆï¼š
           - è¯­ä¹‰æœç´¢ï¼šæ‰¾åˆ°æ„æ€ç›¸è¿‘çš„æ–‡æ¡£
           - RAG åº”ç”¨ï¼šæ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡
           - æ–‡æ¡£èšç±»ï¼šå°†ç›¸ä¼¼æ–‡æ¡£åˆ†ç»„
           - æ¨èç³»ç»Ÿï¼šåŸºäºç›¸ä¼¼åº¦æ¨è
           - å¼‚å¸¸æ£€æµ‹ï¼šæ‰¾å‡ºä¸ä¼—ä¸åŒçš„æ–‡æœ¬
    """)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ LLM æ¨¡å‹å°è£… - Gemini ç‰ˆæœ¬")
    print("=" * 60)

    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯ï¼šæœªè®¾ç½® GOOGLE_API_KEY")
        return

    print(f"âœ… API Key å·²é…ç½®: {api_key[:8]}...{api_key[-4:]}")

    try:
        model_types_overview()
        chat_models_demo()
        model_configuration()
        embeddings_demo()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        return

    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š03-prompt-templates.py")
    print("=" * 60)


if __name__ == "__main__":
    main()
