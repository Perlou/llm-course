"""
LLM æ¨¡å‹å°è£…
============

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£ LangChain ä¸­çš„æ¨¡å‹ç±»å‹
    2. æŒæ¡ ChatOpenAI çš„é…ç½®å’Œä½¿ç”¨
    3. äº†è§£ Embeddings æ¨¡å‹çš„ä½¿ç”¨

æ ¸å¿ƒæ¦‚å¿µï¼š
    - Chat Modelsï¼šåŸºäºæ¶ˆæ¯çš„å¯¹è¯æ¨¡å‹
    - Embeddingsï¼šæ–‡æœ¬å‘é‡åŒ–æ¨¡å‹

å‰ç½®çŸ¥è¯†ï¼š
    - 01-langchain-intro.py

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install langchain langchain-openai python-dotenv
"""

import os
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šæ¨¡å‹ç±»å‹æ¦‚è¿° ====================


def model_types_overview():
    """æ¨¡å‹ç±»å‹æ¦‚è¿°"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šæ¨¡å‹ç±»å‹æ¦‚è¿°")
    print("=" * 60)

    print("""
    LangChain ä¸­çš„æ¨¡å‹ç±»å‹ï¼š
    
    | ç±»å‹        | è¾“å…¥           | è¾“å‡º        | å…¸å‹æ¨¡å‹          |
    |------------|---------------|------------|------------------|
    | Chat Models| æ¶ˆæ¯åˆ—è¡¨       | AIæ¶ˆæ¯å¯¹è±¡   | gpt-4, gpt-3.5   |
    | Embeddings | æ–‡æœ¬           | å‘é‡        | text-embedding-3 |
    
    ğŸ’¡ Chat Models æœ€å¸¸ç”¨ï¼Œæ˜¯å¼€å‘çš„é¦–é€‰ã€‚
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šChat Models è¯¦è§£ ====================


def chat_models_demo():
    """Chat Models è¯¦è§£"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šChat Models è¯¦è§£")
    print("=" * 60)

    try:
        from langchain_openai import ChatOpenAI
        from langchain_core.messages import HumanMessage, SystemMessage

        # åˆ›å»ºæ¨¡å‹
        llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
        print(f"\nâœ… æ¨¡å‹å·²åˆ›å»º: {llm.model_name}")

        # ç®€å•è°ƒç”¨
        print("\nğŸ“Œ ç®€å•è°ƒç”¨ï¼š")
        response = llm.invoke("ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯ LangChain")
        print(f"å›å¤: {response.content}")

        # ä½¿ç”¨æ¶ˆæ¯åˆ—è¡¨
        print("\nğŸ“Œ ä½¿ç”¨æ¶ˆæ¯åˆ—è¡¨ï¼š")
        messages = [
            SystemMessage(content="ä½ æ˜¯ Python ä¸“å®¶"),
            HumanMessage(content="åˆ—è¡¨æ¨å¯¼å¼æ˜¯ä»€ä¹ˆï¼Ÿ"),
        ]
        response = llm.invoke(messages)
        print(f"å›å¤: {response.content}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ¨¡å‹é…ç½® ====================


def model_configuration():
    """æ¨¡å‹é…ç½®"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ¨¡å‹é…ç½®")
    print("=" * 60)

    print("""
    å…³é”®å‚æ•°ï¼š
    - temperature (0-2): 0=ç¡®å®šæ€§, 1+=åˆ›é€ æ€§
    - max_tokens: æœ€å¤§è¾“å‡ºé•¿åº¦
    - timeout: è¶…æ—¶æ—¶é—´
    - max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    """)

    try:
        from langchain_openai import ChatOpenAI

        # å¯¹æ¯”ä¸åŒæ¸©åº¦
        print("\nğŸ“Œ æ¸©åº¦å¯¹æ¯”ï¼š")
        prompt = "ç”¨ä¸€å¥è¯æè¿°æœˆäº®"

        llm_low = ChatOpenAI(temperature=0)
        llm_high = ChatOpenAI(temperature=1.2)

        print(f"temperature=0: {llm_low.invoke(prompt).content}")
        print(f"temperature=1.2: {llm_high.invoke(prompt).content}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šEmbeddings æ¨¡å‹ ====================


def embeddings_demo():
    """Embeddings æ¨¡å‹æ¼”ç¤º"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šEmbeddings æ¨¡å‹")
    print("=" * 60)

    print("""
    Embeddings å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ï¼Œç”¨äºï¼š
    - è¯­ä¹‰æœç´¢
    - æ–‡æ¡£ç›¸ä¼¼åº¦
    - RAG åº”ç”¨
    """)

    try:
        from langchain_openai import OpenAIEmbeddings
        import numpy as np

        embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

        # å•ä¸ªæ–‡æœ¬åµŒå…¥
        text = "LangChain æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ¡†æ¶"
        vector = embeddings.embed_query(text)
        print(f"\næ–‡æœ¬: {text}")
        print(f"å‘é‡ç»´åº¦: {len(vector)}")

        # ç›¸ä¼¼åº¦è®¡ç®—
        texts = ["Python ç¼–ç¨‹", "Java ç¼–ç¨‹", "çƒ¹é¥ªæŠ€å·§"]
        vectors = embeddings.embed_documents(texts)

        def cosine_sim(v1, v2):
            v1, v2 = np.array(v1), np.array(v2)
            return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

        print(
            f"\nç›¸ä¼¼åº¦: '{texts[0]}' vs '{texts[1]}': {cosine_sim(vectors[0], vectors[1]):.4f}"
        )
        print(
            f"ç›¸ä¼¼åº¦: '{texts[0]}' vs '{texts[2]}': {cosine_sim(vectors[0], vectors[2]):.4f}"
        )

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šåˆ›å»ºä»£ç ç”Ÿæˆæ¨¡å‹
        ä½¿ç”¨ä½æ¸©åº¦å’Œå¤§ max_tokens åˆ›å»ºé€‚åˆä»£ç ç”Ÿæˆçš„æ¨¡å‹ã€‚

    ç»ƒä¹  2ï¼šå¤šè½®å¯¹è¯
        ä½¿ç”¨æ¶ˆæ¯åˆ—è¡¨å®ç°è¿ç»­çš„å¤šè½®å¯¹è¯ã€‚

    ç»ƒä¹  3ï¼šæ–‡æœ¬ç›¸ä¼¼åº¦æœç´¢
        ä½¿ç”¨ Embeddings æ‰¾å‡ºæœ€ç›¸ä¼¼çš„æ–‡æ¡£ã€‚

    æ€è€ƒé¢˜ï¼š
        1. ä»€ä¹ˆæ—¶å€™ä½¿ç”¨ä½æ¸©åº¦ vs é«˜æ¸©åº¦ï¼Ÿ
        2. Embeddings æœ‰ä»€ä¹ˆå®é™…åº”ç”¨ï¼Ÿ
    """)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ LLM æ¨¡å‹å°è£…")
    print("=" * 60)

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯ï¼šæœªè®¾ç½® OPENAI_API_KEY")
        return

    print(f"âœ… API Key å·²é…ç½®: {api_key[:8]}...{api_key[-4:]}")

    try:
        model_types_overview()
        chat_models_demo()
        model_configuration()
        embeddings_demo()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        return

    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š03-prompt-templates.py")
    print("=" * 60)


if __name__ == "__main__":
    main()
