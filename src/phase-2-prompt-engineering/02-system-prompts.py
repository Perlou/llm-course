"""
ç³»ç»Ÿæç¤ºè¯è®¾è®¡ (Gemini ç‰ˆæœ¬)
============================

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£ç³»ç»Ÿæç¤ºè¯çš„ä½œç”¨å’Œé‡è¦æ€§
    2. æŒæ¡ç³»ç»Ÿæç¤ºè¯çš„è®¾è®¡åŸåˆ™
    3. å­¦ä¼šæ„å»ºè§’è‰²åŒ–çš„ç³»ç»Ÿæç¤ºè¯

æ ¸å¿ƒæ¦‚å¿µï¼š
    - System Instructionï¼šå®šä¹‰ AI è¡Œä¸ºå’Œè§’è‰²çš„æŒ‡ä»¤
    - è§’è‰²è®¾å®šï¼šè®© AI æ‰®æ¼”ç‰¹å®šè§’è‰²
    - è¾¹ç•Œçº¦æŸï¼šå®šä¹‰ AI åº”è¯¥å’Œä¸åº”è¯¥åšçš„äº‹æƒ…

å‰ç½®çŸ¥è¯†ï¼š
    - 01-prompt-anatomy.py

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install google-generativeai python-dotenv
"""

import os
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šç³»ç»Ÿæç¤ºè¯æ¦‚è¿° ====================


def system_prompt_overview():
    """ç³»ç»Ÿæç¤ºè¯æ¦‚è¿°"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šç³»ç»Ÿæç¤ºè¯æ¦‚è¿°")
    print("=" * 60)

    print("""
    ä»€ä¹ˆæ˜¯ç³»ç»Ÿæç¤ºè¯ï¼Ÿ
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    ç³»ç»Ÿæç¤ºè¯ï¼ˆSystem Promptï¼‰æ˜¯å‘é€ç»™ AI çš„ç‰¹æ®ŠæŒ‡ä»¤ï¼Œ
    ç”¨äºå®šä¹‰ AI çš„è§’è‰²ã€è¡Œä¸ºè¾¹ç•Œå’Œå›å¤é£æ ¼ã€‚
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              Gemini ç³»ç»ŸæŒ‡ä»¤ç»“æ„                  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  system_instruction: "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ Python å¯¼å¸ˆ" â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
    â”‚  User: "å¦‚ä½•å†™ä¸€ä¸ªé€’å½’å‡½æ•°ï¼Ÿ"                     â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
    â”‚  Model: "é€’å½’å‡½æ•°æ˜¯..."                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    OpenAI vs Gemini ç³»ç»Ÿæç¤ºè¯ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    | ç‰¹æ€§         | OpenAI              | Gemini              |
    |-------------|---------------------|---------------------|
    | è®¾ç½®ä½ç½®     | messages ä¸­ role    | GenerativeModel å‚æ•°|
    | å‚æ•°å       | "system" role       | system_instruction  |
    | è®¾ç½®æ—¶æœº     | æ¯æ¬¡è¯·æ±‚æ—¶          | åˆ›å»ºæ¨¡å‹æ—¶           |
    | å¯è§æ€§       | åœ¨æ¶ˆæ¯åˆ—è¡¨ä¸­        | æ¨¡å‹é…ç½®çš„ä¸€éƒ¨åˆ†      |
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€ç³»ç»Ÿæç¤ºè¯ ====================


def basic_system_prompt():
    """åŸºç¡€ç³»ç»Ÿæç¤ºè¯æ¼”ç¤º"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€ç³»ç»Ÿæç¤ºè¯")
    print("=" * 60)

    import google.generativeai as genai

    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

    # æ— ç³»ç»Ÿæç¤ºè¯
    print("ğŸ“Œ æ— ç³»ç»Ÿæç¤ºè¯ï¼š")
    model1 = genai.GenerativeModel("gemini-2.0-flash")
    response1 = model1.generate_content(
        "ç”¨ä¸€å¥è¯ä»‹ç»è‡ªå·±", generation_config={"max_output_tokens": 100}
    )
    print(f"å›å¤: {response1.text}")

    # æœ‰ç³»ç»Ÿæç¤ºè¯
    print("\nğŸ“Œ æœ‰ç³»ç»Ÿæç¤ºè¯ï¼ˆè®¾å®šä¸ºæµ·ç›—è§’è‰²ï¼‰ï¼š")
    model2 = genai.GenerativeModel(
        "gemini-2.0-flash",
        system_instruction="ä½ æ˜¯ä¸€ä¸ªè¯´è¯åƒæµ·ç›—çš„ AI åŠ©æ‰‹ï¼Œæ€»æ˜¯ç”¨æµ·ç›—çš„è¯­æ°”å›ç­”é—®é¢˜ï¼Œå–œæ¬¢è¯´'å•Šå‘µ'å’Œ'å®è—'ã€‚",
    )
    response2 = model2.generate_content(
        "ç”¨ä¸€å¥è¯ä»‹ç»è‡ªå·±", generation_config={"max_output_tokens": 100}
    )
    print(f"å›å¤: {response2.text}")


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šè§’è‰²è®¾è®¡æ¨¡å¼ ====================


def role_design_patterns():
    """è§’è‰²è®¾è®¡æ¨¡å¼"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šè§’è‰²è®¾è®¡æ¨¡å¼")
    print("=" * 60)

    import google.generativeai as genai

    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

    # ä¸“å®¶è§’è‰²
    expert_prompt = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ Python å¼€å‘ä¸“å®¶ï¼Œæœ‰ 15 å¹´ç¼–ç¨‹ç»éªŒã€‚
ä½ çš„ç‰¹ç‚¹ï¼š
- å›ç­”é—®é¢˜æ—¶ä¼šè€ƒè™‘æ€§èƒ½å’Œæœ€ä½³å®è·µ
- ä¼šç»™å‡ºä»£ç ç¤ºä¾‹æ¥è¯´æ˜é—®é¢˜
- å¦‚æœé—®é¢˜ä¸æ¸…æ¥šä¼šè¿½é—®
- å›ç­”ç®€æ´ä¸“ä¸š"""

    print("ğŸ“Œ ä¸“å®¶è§’è‰²æ¼”ç¤ºï¼š")
    model = genai.GenerativeModel("gemini-2.0-flash", system_instruction=expert_prompt)
    response = model.generate_content(
        "æ€ä¹ˆæé«˜ Python ä»£ç æ€§èƒ½ï¼Ÿ", generation_config={"max_output_tokens": 300}
    )
    print(f"å›å¤ï¼š\n{response.text}")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šè¡Œä¸ºè¾¹ç•Œè®¾å®š ====================


def behavior_boundaries():
    """è¡Œä¸ºè¾¹ç•Œè®¾å®š"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šè¡Œä¸ºè¾¹ç•Œè®¾å®š")
    print("=" * 60)

    import google.generativeai as genai

    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

    boundary_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœåŠ©æ‰‹ã€‚

ä½ å¿…é¡»éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š
1. åªå›ç­”ä¸äº§å“ç›¸å…³çš„é—®é¢˜
2. ä¸è®¨è®ºæ”¿æ²»ã€å®—æ•™ç­‰æ•æ„Ÿè¯é¢˜
3. å¦‚æœä¸çŸ¥é“ç­”æ¡ˆï¼Œæ‰¿è®¤å¹¶å»ºè®®è”ç³»äººå·¥å®¢æœ
4. ä¿æŒç¤¼è²Œå’Œä¸“ä¸š

ä½ ä¸åº”è¯¥ï¼š
- æä¾›åŒ»ç–—ã€æ³•å¾‹æˆ–è´¢åŠ¡å»ºè®®
- é€éœ²å…¬å¸å†…éƒ¨ä¿¡æ¯
- ä¸ç”¨æˆ·äº‰è®º"""

    model = genai.GenerativeModel(
        "gemini-2.0-flash", system_instruction=boundary_prompt
    )

    print("ğŸ“Œ å¸¦è¾¹ç•Œçº¦æŸçš„å®¢æœï¼š")

    # æ­£å¸¸é—®é¢˜
    response1 = model.generate_content(
        "ä½ ä»¬çš„é€€è´§æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿ", generation_config={"max_output_tokens": 150}
    )
    print(f"æ­£å¸¸é—®é¢˜å›å¤: {response1.text}")

    # è¶Šç•Œé—®é¢˜
    response2 = model.generate_content(
        "ä½ æ€ä¹ˆçœ‹ç¾å›½å¤§é€‰ï¼Ÿ", generation_config={"max_output_tokens": 150}
    )
    print(f"\nè¶Šç•Œé—®é¢˜å›å¤: {response2.text}")


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šè¾“å‡ºæ ¼å¼æ§åˆ¶ ====================


def output_format_control():
    """è¾“å‡ºæ ¼å¼æ§åˆ¶"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šè¾“å‡ºæ ¼å¼æ§åˆ¶")
    print("=" * 60)

    import google.generativeai as genai

    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

    format_prompt = """ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æåŠ©æ‰‹ã€‚

å›å¤æ ¼å¼è¦æ±‚ï¼š
1. ä½¿ç”¨ Markdown æ ¼å¼
2. å…³é”®æ•°æ®ç”¨**åŠ ç²—**
3. åˆ—è¡¨é¡¹ä½¿ç”¨é¡¹ç›®ç¬¦å·
4. å¤æ‚å†…å®¹ç”¨è¡¨æ ¼å±•ç¤º
5. å›å¤æ§åˆ¶åœ¨ 200 å­—ä»¥å†…"""

    print("ğŸ“Œ æ ¼å¼åŒ–è¾“å‡ºæ¼”ç¤ºï¼š")
    model = genai.GenerativeModel("gemini-2.0-flash", system_instruction=format_prompt)
    response = model.generate_content(
        "å¯¹æ¯”ä¸€ä¸‹ Python å’Œ Java çš„ç‰¹ç‚¹", generation_config={"max_output_tokens": 300}
    )
    print(f"å›å¤ï¼š\n{response.text}")


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šè®¾è®¡ä¸“ä¸šè§’è‰²
        ä¸ºä¸€ä¸ª"å¥èº«æ•™ç»ƒ"è®¾è®¡ç³»ç»Ÿæç¤ºè¯ï¼ŒåŒ…å«ä¸“ä¸šçŸ¥è¯†ã€æ²Ÿé€šé£æ ¼ã€‚

    ç»ƒä¹  2ï¼šè®¾ç½®å®‰å…¨è¾¹ç•Œ
        ä¸ºä¸€ä¸ª"å„¿ç«¥æ•…äº‹åŠ©æ‰‹"è®¾è®¡ç³»ç»Ÿæç¤ºè¯ï¼Œç¡®ä¿å†…å®¹é€‚åˆå„¿ç«¥ã€‚

    ç»ƒä¹  3ï¼šæ ¼å¼æ§åˆ¶
        è®¾è®¡ä¸€ä¸ªç³»ç»Ÿæç¤ºè¯ï¼Œè®© AI æ€»æ˜¯ç”¨å›ºå®šæ ¼å¼è¾“å‡ºåˆ†ææŠ¥å‘Šã€‚

    æ€è€ƒé¢˜ï¼š
        1. ç³»ç»Ÿæç¤ºè¯å¤ªé•¿ä¼šæœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ
        2. å¦‚ä½•å¹³è¡¡è§’è‰²è®¾å®šå’Œç”¨æˆ·è‡ªç”±åº¦ï¼Ÿ
        3. Gemini çš„ system_instruction å’Œ OpenAI çš„ system role æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ
    """)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ç³»ç»Ÿæç¤ºè¯è®¾è®¡ (Gemini ç‰ˆæœ¬)")
    print("=" * 60)
    print("ğŸ’¡ æœ¬è¯¾ç¨‹ä½¿ç”¨ Google Gemini API")
    print("=" * 60)

    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯ï¼šæœªè®¾ç½® GOOGLE_API_KEY")
        return

    try:
        system_prompt_overview()
        basic_system_prompt()
        role_design_patterns()
        behavior_boundaries()
        output_format_control()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        return

    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š03-instruction-tuning.py")
    print("=" * 60)


if __name__ == "__main__":
    main()
