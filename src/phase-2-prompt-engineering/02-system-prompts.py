"""
ç³»ç»Ÿæç¤ºè¯è®¾è®¡
==============

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£ç³»ç»Ÿæç¤ºè¯çš„ä½œç”¨å’Œé‡è¦æ€§
    2. æŒæ¡ç³»ç»Ÿæç¤ºè¯çš„è®¾è®¡åŸåˆ™
    3. å­¦ä¼šæ„å»ºè§’è‰²åŒ–çš„ç³»ç»Ÿæç¤ºè¯

æ ¸å¿ƒæ¦‚å¿µï¼š
    - System Promptï¼šå®šä¹‰ AI è¡Œä¸ºå’Œè§’è‰²çš„æŒ‡ä»¤
    - è§’è‰²è®¾å®šï¼šè®© AI æ‰®æ¼”ç‰¹å®šè§’è‰²
    - è¾¹ç•Œçº¦æŸï¼šå®šä¹‰ AI åº”è¯¥å’Œä¸åº”è¯¥åšçš„äº‹æƒ…

å‰ç½®çŸ¥è¯†ï¼š
    - 01-prompt-anatomy.py

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install openai python-dotenv
"""

import os
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šç³»ç»Ÿæç¤ºè¯æ¦‚è¿° ====================


def system_prompt_overview():
    """ç³»ç»Ÿæç¤ºè¯æ¦‚è¿°"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šç³»ç»Ÿæç¤ºè¯æ¦‚è¿°")
    print("=" * 60)

    print("""
    ä»€ä¹ˆæ˜¯ç³»ç»Ÿæç¤ºè¯ï¼Ÿ
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    ç³»ç»Ÿæç¤ºè¯ï¼ˆSystem Promptï¼‰æ˜¯å‘é€ç»™ AI çš„ç‰¹æ®ŠæŒ‡ä»¤ï¼Œ
    ç”¨äºå®šä¹‰ AI çš„è§’è‰²ã€è¡Œä¸ºè¾¹ç•Œå’Œå›å¤é£æ ¼ã€‚
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   æ¶ˆæ¯ç»“æ„                        â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  System: "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ Python å¯¼å¸ˆ..."          â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
    â”‚  User: "å¦‚ä½•å†™ä¸€ä¸ªé€’å½’å‡½æ•°ï¼Ÿ"                     â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
    â”‚  Assistant: "é€’å½’å‡½æ•°æ˜¯..."                      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    ç³»ç»Ÿæç¤ºè¯ vs ç”¨æˆ·æç¤ºè¯ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    | ç‰¹æ€§     | System Prompt    | User Prompt     |
    |---------|------------------|-----------------|
    | å¯è§æ€§   | ç”¨æˆ·é€šå¸¸çœ‹ä¸åˆ°    | ç”¨æˆ·ç›´æ¥è¾“å…¥     |
    | ä½œç”¨èŒƒå›´ | æ•´ä¸ªå¯¹è¯         | å•æ¬¡è¯·æ±‚         |
    | ä¼˜å…ˆçº§   | è¾ƒé«˜             | è¾ƒä½            |
    | ç”¨é€”     | å®šä¹‰è§’è‰²å’Œè§„åˆ™    | å…·ä½“ä»»åŠ¡        |
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€ç³»ç»Ÿæç¤ºè¯ ====================


def basic_system_prompt():
    """åŸºç¡€ç³»ç»Ÿæç¤ºè¯æ¼”ç¤º"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€ç³»ç»Ÿæç¤ºè¯")
    print("=" * 60)

    client = OpenAI()

    # æ— ç³»ç»Ÿæç¤ºè¯
    print("ğŸ“Œ æ— ç³»ç»Ÿæç¤ºè¯ï¼š")
    response1 = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": "ç”¨ä¸€å¥è¯ä»‹ç»è‡ªå·±"}],
        max_tokens=100,
    )
    print(f"å›å¤: {response1.choices[0].message.content}")

    # æœ‰ç³»ç»Ÿæç¤ºè¯
    print("\nğŸ“Œ æœ‰ç³»ç»Ÿæç¤ºè¯ï¼ˆè®¾å®šä¸ºæµ·ç›—è§’è‰²ï¼‰ï¼š")
    response2 = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªè¯´è¯åƒæµ·ç›—çš„ AI åŠ©æ‰‹ï¼Œæ€»æ˜¯ç”¨æµ·ç›—çš„è¯­æ°”å›ç­”é—®é¢˜ï¼Œå–œæ¬¢è¯´'å•Šå‘µ'å’Œ'å®è—'ã€‚",
            },
            {"role": "user", "content": "ç”¨ä¸€å¥è¯ä»‹ç»è‡ªå·±"},
        ],
        max_tokens=100,
    )
    print(f"å›å¤: {response2.choices[0].message.content}")


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šè§’è‰²è®¾è®¡æ¨¡å¼ ====================


def role_design_patterns():
    """è§’è‰²è®¾è®¡æ¨¡å¼"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šè§’è‰²è®¾è®¡æ¨¡å¼")
    print("=" * 60)

    client = OpenAI()

    # ä¸“å®¶è§’è‰²
    expert_prompt = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ Python å¼€å‘ä¸“å®¶ï¼Œæœ‰ 15 å¹´ç¼–ç¨‹ç»éªŒã€‚
ä½ çš„ç‰¹ç‚¹ï¼š
- å›ç­”é—®é¢˜æ—¶ä¼šè€ƒè™‘æ€§èƒ½å’Œæœ€ä½³å®è·µ
- ä¼šç»™å‡ºä»£ç ç¤ºä¾‹æ¥è¯´æ˜é—®é¢˜
- å¦‚æœé—®é¢˜ä¸æ¸…æ¥šä¼šè¿½é—®
- å›ç­”ç®€æ´ä¸“ä¸š"""

    print("ğŸ“Œ ä¸“å®¶è§’è‰²æ¼”ç¤ºï¼š")
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": expert_prompt},
            {"role": "user", "content": "æ€ä¹ˆæé«˜ Python ä»£ç æ€§èƒ½ï¼Ÿ"},
        ],
        max_tokens=300,
    )
    print(f"å›å¤:\n{response.choices[0].message.content}")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šè¡Œä¸ºè¾¹ç•Œè®¾å®š ====================


def behavior_boundaries():
    """è¡Œä¸ºè¾¹ç•Œè®¾å®š"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šè¡Œä¸ºè¾¹ç•Œè®¾å®š")
    print("=" * 60)

    client = OpenAI()

    boundary_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœåŠ©æ‰‹ã€‚

ä½ å¿…é¡»éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š
1. åªå›ç­”ä¸äº§å“ç›¸å…³çš„é—®é¢˜
2. ä¸è®¨è®ºæ”¿æ²»ã€å®—æ•™ç­‰æ•æ„Ÿè¯é¢˜
3. å¦‚æœä¸çŸ¥é“ç­”æ¡ˆï¼Œæ‰¿è®¤å¹¶å»ºè®®è”ç³»äººå·¥å®¢æœ
4. ä¿æŒç¤¼è²Œå’Œä¸“ä¸š

ä½ ä¸åº”è¯¥ï¼š
- æä¾›åŒ»ç–—ã€æ³•å¾‹æˆ–è´¢åŠ¡å»ºè®®
- é€éœ²å…¬å¸å†…éƒ¨ä¿¡æ¯
- ä¸ç”¨æˆ·äº‰è®º"""

    print("ğŸ“Œ å¸¦è¾¹ç•Œçº¦æŸçš„å®¢æœï¼š")

    # æ­£å¸¸é—®é¢˜
    response1 = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": boundary_prompt},
            {"role": "user", "content": "ä½ ä»¬çš„é€€è´§æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿ"},
        ],
        max_tokens=150,
    )
    print(f"æ­£å¸¸é—®é¢˜å›å¤: {response1.choices[0].message.content}")

    # è¶Šç•Œé—®é¢˜
    response2 = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": boundary_prompt},
            {"role": "user", "content": "ä½ æ€ä¹ˆçœ‹ç¾å›½å¤§é€‰ï¼Ÿ"},
        ],
        max_tokens=150,
    )
    print(f"\nè¶Šç•Œé—®é¢˜å›å¤: {response2.choices[0].message.content}")


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šè¾“å‡ºæ ¼å¼æ§åˆ¶ ====================


def output_format_control():
    """è¾“å‡ºæ ¼å¼æ§åˆ¶"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šè¾“å‡ºæ ¼å¼æ§åˆ¶")
    print("=" * 60)

    client = OpenAI()

    format_prompt = """ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æåŠ©æ‰‹ã€‚

å›å¤æ ¼å¼è¦æ±‚ï¼š
1. ä½¿ç”¨ Markdown æ ¼å¼
2. å…³é”®æ•°æ®ç”¨**åŠ ç²—**
3. åˆ—è¡¨é¡¹ä½¿ç”¨é¡¹ç›®ç¬¦å·
4. å¤æ‚å†…å®¹ç”¨è¡¨æ ¼å±•ç¤º
5. å›å¤æ§åˆ¶åœ¨ 200 å­—ä»¥å†…"""

    print("ğŸ“Œ æ ¼å¼åŒ–è¾“å‡ºæ¼”ç¤ºï¼š")
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": format_prompt},
            {"role": "user", "content": "å¯¹æ¯”ä¸€ä¸‹ Python å’Œ Java çš„ç‰¹ç‚¹"},
        ],
        max_tokens=300,
    )
    print(f"å›å¤:\n{response.choices[0].message.content}")


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šè®¾è®¡ä¸“ä¸šè§’è‰²
        ä¸ºä¸€ä¸ª"å¥èº«æ•™ç»ƒ"è®¾è®¡ç³»ç»Ÿæç¤ºè¯ï¼ŒåŒ…å«ä¸“ä¸šçŸ¥è¯†ã€æ²Ÿé€šé£æ ¼ã€‚

    ç»ƒä¹  2ï¼šè®¾ç½®å®‰å…¨è¾¹ç•Œ
        ä¸ºä¸€ä¸ª"å„¿ç«¥æ•…äº‹åŠ©æ‰‹"è®¾è®¡ç³»ç»Ÿæç¤ºè¯ï¼Œç¡®ä¿å†…å®¹é€‚åˆå„¿ç«¥ã€‚

    ç»ƒä¹  3ï¼šæ ¼å¼æ§åˆ¶
        è®¾è®¡ä¸€ä¸ªç³»ç»Ÿæç¤ºè¯ï¼Œè®© AI æ€»æ˜¯ç”¨å›ºå®šæ ¼å¼è¾“å‡ºåˆ†ææŠ¥å‘Šã€‚

    æ€è€ƒé¢˜ï¼š
        1. ç³»ç»Ÿæç¤ºè¯å¤ªé•¿ä¼šæœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ
        2. å¦‚ä½•å¹³è¡¡è§’è‰²è®¾å®šå’Œç”¨æˆ·è‡ªç”±åº¦ï¼Ÿ
        3. ç³»ç»Ÿæç¤ºè¯èƒ½è¢«ç”¨æˆ·è¦†ç›–å—ï¼Ÿ
    """)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ç³»ç»Ÿæç¤ºè¯è®¾è®¡")
    print("=" * 60)
    print("âš ï¸ æ³¨æ„ï¼šæœ¬è¯¾ç¨‹å°†è°ƒç”¨ OpenAI API")
    print("=" * 60)

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯ï¼šæœªè®¾ç½® OPENAI_API_KEY")
        return

    try:
        system_prompt_overview()
        basic_system_prompt()
        role_design_patterns()
        behavior_boundaries()
        output_format_control()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        return

    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š03-instruction-tuning.py")
    print("=" * 60)


if __name__ == "__main__":
    main()
