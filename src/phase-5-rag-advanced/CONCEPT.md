# é«˜çº§RAGæŠ€æœ¯æ·±åº¦è§£æï¼šä»å…¥é—¨åˆ°ç²¾é€š

## ğŸ“š ç›®å½•

1. [RAGåŸºç¡€å›é¡¾](#1-ragåŸºç¡€å›é¡¾)
2. [é«˜çº§åˆ†å—ç­–ç•¥](#2-é«˜çº§åˆ†å—ç­–ç•¥)
3. [æŸ¥è¯¢ç†è§£ä¸ä¼˜åŒ–](#3-æŸ¥è¯¢ç†è§£ä¸ä¼˜åŒ–)
4. [é«˜çº§æ£€ç´¢æŠ€æœ¯](#4-é«˜çº§æ£€ç´¢æŠ€æœ¯)
5. [é‡æ’åºæŠ€æœ¯](#5-é‡æ’åºæŠ€æœ¯)
6. [ä¸Šä¸‹æ–‡å‹ç¼©ä¸ä¼˜åŒ–](#6-ä¸Šä¸‹æ–‡å‹ç¼©ä¸ä¼˜åŒ–)
7. [å¤šè·³æ¨ç†RAG](#7-å¤šè·³æ¨ç†rag)
8. [çŸ¥è¯†å›¾è°±å¢å¼ºRAG](#8-çŸ¥è¯†å›¾è°±å¢å¼ºrag)
9. [è‡ªé€‚åº”RAG](#9-è‡ªé€‚åº”rag)
10. [RAGè¯„ä¼°ä½“ç³»](#10-ragè¯„ä¼°ä½“ç³»)
11. [ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ](#11-ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ)

---

## 1. RAGåŸºç¡€å›é¡¾

### 1.1 ä»€ä¹ˆæ˜¯RAGï¼Ÿ

**RAGï¼ˆRetrieval-Augmented Generationï¼‰** æ˜¯ä¸€ç§å°†ä¿¡æ¯æ£€ç´¢ä¸å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆèƒ½åŠ›ç»“åˆçš„æŠ€æœ¯æ¶æ„ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      RAG åŸºç¡€æ¶æ„                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  ç”¨æˆ·æŸ¥è¯¢  â”‚â”€â”€â”€â–¶â”‚   æ£€ç´¢å™¨      â”‚â”€â”€â”€â–¶â”‚   å‘é‡æ•°æ®åº“         â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                â”‚                       â”‚              â”‚
â”‚         â”‚                â–¼                       â”‚              â”‚
â”‚         â”‚         ç›¸å…³æ–‡æ¡£å—                       â”‚              â”‚
â”‚         â”‚                â”‚                       â”‚              â”‚
â”‚         â–¼                â–¼                       â”‚              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚              â”‚
â”‚   â”‚          æç¤ºè¯æ„å»º            â”‚               â”‚              â”‚
â”‚   â”‚   Query + Retrieved Context  â”‚               â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚              â”‚
â”‚                    â”‚                             â”‚              â”‚
â”‚                    â–¼                             â”‚              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚              â”‚
â”‚   â”‚           LLM ç”Ÿæˆ            â”‚               â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚              â”‚
â”‚                    â”‚                             â”‚              â”‚
â”‚                    â–¼                             â”‚              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚              â”‚
â”‚   â”‚          æœ€ç»ˆå›ç­”             â”‚               â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Naive RAG vs Advanced RAG

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAG æ¼”è¿›è·¯çº¿å›¾                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  Naive RAG  â”‚â”€â”€â”€â”€â”€â–¶â”‚ Advanced RAGâ”‚â”€â”€â”€â”€â”€â–¶â”‚ Modular RAG â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚        â”‚                    â”‚                    â”‚                      â”‚
â”‚        â–¼                    â–¼                    â–¼                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ â€¢ ç®€å•åˆ†å—    â”‚    â”‚ â€¢ æŸ¥è¯¢ä¼˜åŒ–    â”‚    â”‚ â€¢ å¯æ’æ‹”æ¨¡å—  â”‚              â”‚
â”‚  â”‚ â€¢ ç›´æ¥æ£€ç´¢    â”‚    â”‚ â€¢ æ··åˆæ£€ç´¢    â”‚    â”‚ â€¢ è‡ªé€‚åº”è·¯ç”±  â”‚              â”‚
â”‚  â”‚ â€¢ æ— é‡æ’åº    â”‚    â”‚ â€¢ é‡æ’åº      â”‚    â”‚ â€¢ å¤šç­–ç•¥èåˆ  â”‚              â”‚
â”‚  â”‚ â€¢ åŸºç¡€ç”Ÿæˆ    â”‚    â”‚ â€¢ ä¸Šä¸‹æ–‡å‹ç¼©  â”‚    â”‚ â€¢ çŸ¥è¯†å›¾è°±    â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 åŸºç¡€å®ç°

```python
# åŸºç¡€ RAG å®ç°
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

class NaiveRAG:
    """åŸºç¡€RAGå®ç°"""

    def __init__(self):
        self.embeddings = OpenAIEmbeddings()
        self.llm = ChatOpenAI(model="gpt-4", temperature=0)
        self.vectorstore = None

    def index_documents(self, documents: list[str], chunk_size: int = 500):
        """ç´¢å¼•æ–‡æ¡£"""
        from langchain.text_splitter import RecursiveCharacterTextSplitter

        # ç®€å•åˆ†å—
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=50
        )
        chunks = splitter.create_documents(documents)

        # åˆ›å»ºå‘é‡å­˜å‚¨
        self.vectorstore = FAISS.from_documents(chunks, self.embeddings)

    def query(self, question: str, k: int = 4) -> str:
        """æŸ¥è¯¢"""
        qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            retriever=self.vectorstore.as_retriever(search_kwargs={"k": k})
        )
        return qa_chain.run(question)
```

---

## 2. é«˜çº§åˆ†å—ç­–ç•¥

### 2.1 åˆ†å—ç­–ç•¥å¯¹æ¯”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      åˆ†å—ç­–ç•¥å…¨æ™¯å›¾                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   å›ºå®šå¤§å°åˆ†å—    â”‚  â”‚   è¯­ä¹‰åˆ†å—       â”‚  â”‚   ç»“æ„åŒ–åˆ†å—     â”‚         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚
â”‚  â”‚ â€¢ æŒ‰å­—ç¬¦æ•°åˆ‡åˆ†   â”‚  â”‚ â€¢ åŸºäºåµŒå…¥ç›¸ä¼¼åº¦ â”‚  â”‚ â€¢ æŒ‰æ–‡æ¡£ç»“æ„    â”‚         â”‚
â”‚  â”‚ â€¢ ç®€å•é«˜æ•ˆ      â”‚  â”‚ â€¢ è¯­ä¹‰è¾¹ç•Œæ¸…æ™°   â”‚  â”‚ â€¢ ä¿ç•™å±‚æ¬¡å…³ç³»  â”‚         â”‚
â”‚  â”‚ â€¢ å¯èƒ½åˆ‡æ–­å¥å­  â”‚  â”‚ â€¢ è®¡ç®—æˆæœ¬è¾ƒé«˜   â”‚  â”‚ â€¢ éœ€è¦è§£æå™¨    â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   é€’å½’åˆ†å—       â”‚  â”‚   çˆ¶å­åˆ†å—       â”‚  â”‚   æ»‘åŠ¨çª—å£åˆ†å—   â”‚         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚
â”‚  â”‚ â€¢ å¤šçº§åˆ†éš”ç¬¦    â”‚  â”‚ â€¢ å°å—æ£€ç´¢      â”‚  â”‚ â€¢ é‡å ä¿ç•™ä¸Šä¸‹æ–‡â”‚         â”‚
â”‚  â”‚ â€¢ å°Šé‡æ–‡æ¡£ç»“æ„  â”‚  â”‚ â€¢ å¤§å—è¿”å›      â”‚  â”‚ â€¢ ä¿¡æ¯å†—ä½™      â”‚         â”‚
â”‚  â”‚ â€¢ æœ€å¸¸ç”¨æ–¹æ¡ˆ    â”‚  â”‚ â€¢ å…¼é¡¾ç²¾ç¡®å’Œä¸Šä¸‹æ–‡â”‚ â”‚ â€¢ å®ç°ç®€å•      â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 è¯­ä¹‰åˆ†å—å®ç°

````python
import numpy as np
from sentence_transformers import SentenceTransformer

class SemanticChunker:
    """åŸºäºè¯­ä¹‰çš„æ™ºèƒ½åˆ†å—å™¨"""

    def __init__(self,
                 model_name: str = "sentence-transformers/all-MiniLM-L6-v2",
                 breakpoint_threshold: float = 0.5):
        self.model = SentenceTransformer(model_name)
        self.breakpoint_threshold = breakpoint_threshold

    def chunk(self, text: str) -> list[str]:
        """
        åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„åˆ†å—
        åœ¨è¯­ä¹‰æ–­ç‚¹å¤„åˆ‡åˆ†æ–‡æ¡£
        """
        # 1. æŒ‰å¥å­åˆ†å‰²
        sentences = self._split_sentences(text)
        if len(sentences) <= 1:
            return [text]

        # 2. è®¡ç®—æ¯ä¸ªå¥å­çš„åµŒå…¥
        embeddings = self.model.encode(sentences)

        # 3. è®¡ç®—ç›¸é‚»å¥å­çš„ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = []
        for i in range(len(embeddings) - 1):
            sim = self._cosine_similarity(embeddings[i], embeddings[i+1])
            similarities.append(sim)

        # 4. æ‰¾åˆ°è¯­ä¹‰æ–­ç‚¹ï¼ˆç›¸ä¼¼åº¦ä½äºé˜ˆå€¼çš„ä½ç½®ï¼‰
        breakpoints = self._find_breakpoints(similarities)

        # 5. æ ¹æ®æ–­ç‚¹åˆ†å‰²
        chunks = self._split_by_breakpoints(sentences, breakpoints)

        return chunks

    def _split_sentences(self, text: str) -> list[str]:
        """åˆ†å‰²å¥å­"""
        import re
        sentences = re.split(r'(?<=[.!?])\s+', text)
        return [s.strip() for s in sentences if s.strip()]

    def _cosine_similarity(self, a: np.ndarray, b: np.ndarray) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

    def _find_breakpoints(self, similarities: list[float]) -> list[int]:
        """æ‰¾åˆ°è¯­ä¹‰æ–­ç‚¹"""
        breakpoints = []

        # æ–¹æ³•1: å›ºå®šé˜ˆå€¼
        for i, sim in enumerate(similarities):
            if sim < self.breakpoint_threshold:
                breakpoints.append(i + 1)

        # æ–¹æ³•2: åŸºäºç™¾åˆ†ä½æ•°ï¼ˆæ›´è‡ªé€‚åº”ï¼‰
        # threshold = np.percentile(similarities, 25)
        # breakpoints = [i+1 for i, sim in enumerate(similarities) if sim < threshold]

        return breakpoints

    def _split_by_breakpoints(self, sentences: list[str],
                               breakpoints: list[int]) -> list[str]:
        """æ ¹æ®æ–­ç‚¹åˆ†å‰²æ–‡æœ¬"""
        chunks = []
        start = 0

        for bp in breakpoints:
            chunk = ' '.join(sentences[start:bp])
            if chunk:
                chunks.append(chunk)
            start = bp

        # æœ€åä¸€ä¸ªå—
        if start < len(sentences):
            chunks.append(' '.join(sentences[start:]))

        return chunks


class AdaptiveChunker:
    """è‡ªé€‚åº”åˆ†å—å™¨ - æ ¹æ®å†…å®¹ç±»å‹é€‰æ‹©ç­–ç•¥"""

    def __init__(self):
        self.semantic_chunker = SemanticChunker()

    def chunk(self, text: str, content_type: str = "auto") -> list[str]:
        """æ ¹æ®å†…å®¹ç±»å‹é€‰æ‹©åˆ†å—ç­–ç•¥"""

        if content_type == "auto":
            content_type = self._detect_content_type(text)

        if content_type == "code":
            return self._chunk_code(text)
        elif content_type == "markdown":
            return self._chunk_markdown(text)
        elif content_type == "table":
            return self._chunk_table(text)
        else:
            return self.semantic_chunker.chunk(text)

    def _detect_content_type(self, text: str) -> str:
        """æ£€æµ‹å†…å®¹ç±»å‹"""
        # ç®€å•çš„è§„åˆ™æ£€æµ‹
        if "```" in text or "def " in text or "class " in text:
            return "code"
        elif text.startswith("#") or "##" in text:
            return "markdown"
        elif "|" in text and "-|-" in text:
            return "table"
        return "text"

    def _chunk_code(self, text: str) -> list[str]:
        """ä»£ç åˆ†å— - æŒ‰å‡½æ•°/ç±»åˆ†å‰²"""
        import re

        # åŒ¹é…å‡½æ•°å’Œç±»å®šä¹‰
        pattern = r'((?:def|class)\s+\w+[^:]*:(?:\n(?:[ \t]+[^\n]*|\n))*)'
        matches = re.findall(pattern, text)

        if matches:
            return matches
        return [text]

    def _chunk_markdown(self, text: str) -> list[str]:
        """Markdownåˆ†å— - æŒ‰æ ‡é¢˜åˆ†å‰²"""
        import re

        # æŒ‰ä¸€çº§å’ŒäºŒçº§æ ‡é¢˜åˆ†å‰²
        sections = re.split(r'\n(?=#{1,2}\s)', text)
        return [s.strip() for s in sections if s.strip()]

    def _chunk_table(self, text: str) -> list[str]:
        """è¡¨æ ¼åˆ†å— - ä¿æŒè¡¨æ ¼å®Œæ•´"""
        # è¡¨æ ¼é€šå¸¸åº”è¯¥ä¿æŒå®Œæ•´
        return [text]
````

### 2.3 çˆ¶å­åˆ†å—ï¼ˆParent-Child Chunkingï¼‰

```python
from dataclasses import dataclass
from typing import Optional
import uuid

@dataclass
class ChunkNode:
    """åˆ†å—èŠ‚ç‚¹"""
    id: str
    content: str
    parent_id: Optional[str]
    children_ids: list[str]
    level: int  # 0 = root, 1 = parent, 2 = child

class HierarchicalChunker:
    """
    å±‚æ¬¡åŒ–åˆ†å—å™¨
    å®ç°å°å—æ£€ç´¢ã€å¤§å—è¿”å›çš„ç­–ç•¥
    """

    def __init__(self,
                 parent_chunk_size: int = 2000,
                 child_chunk_size: int = 400,
                 child_overlap: int = 50):
        self.parent_chunk_size = parent_chunk_size
        self.child_chunk_size = child_chunk_size
        self.child_overlap = child_overlap
        self.nodes: dict[str, ChunkNode] = {}

    def chunk(self, document: str) -> tuple[list[ChunkNode], list[ChunkNode]]:
        """
        åˆ›å»ºå±‚æ¬¡åŒ–åˆ†å—
        è¿”å›: (çˆ¶å—åˆ—è¡¨, å­å—åˆ—è¡¨)
        """
        parent_chunks = []
        child_chunks = []

        # 1. åˆ›å»ºçˆ¶å—
        parent_texts = self._create_chunks(
            document,
            self.parent_chunk_size,
            overlap=100
        )

        for parent_text in parent_texts:
            parent_id = str(uuid.uuid4())

            # 2. ä¸ºæ¯ä¸ªçˆ¶å—åˆ›å»ºå­å—
            child_texts = self._create_chunks(
                parent_text,
                self.child_chunk_size,
                self.child_overlap
            )

            children_ids = []
            for child_text in child_texts:
                child_id = str(uuid.uuid4())
                child_node = ChunkNode(
                    id=child_id,
                    content=child_text,
                    parent_id=parent_id,
                    children_ids=[],
                    level=2
                )
                self.nodes[child_id] = child_node
                child_chunks.append(child_node)
                children_ids.append(child_id)

            parent_node = ChunkNode(
                id=parent_id,
                content=parent_text,
                parent_id=None,
                children_ids=children_ids,
                level=1
            )
            self.nodes[parent_id] = parent_node
            parent_chunks.append(parent_node)

        return parent_chunks, child_chunks

    def _create_chunks(self, text: str, chunk_size: int,
                       overlap: int = 0) -> list[str]:
        """åˆ›å»ºå›ºå®šå¤§å°çš„åˆ†å—"""
        chunks = []
        start = 0

        while start < len(text):
            end = start + chunk_size
            chunk = text[start:end]

            # å°è¯•åœ¨å¥å­è¾¹ç•Œå¤„åˆ‡åˆ†
            if end < len(text):
                last_period = chunk.rfind('.')
                if last_period > chunk_size * 0.5:
                    chunk = chunk[:last_period + 1]
                    end = start + last_period + 1

            chunks.append(chunk.strip())
            start = end - overlap

        return chunks

    def get_parent(self, child_id: str) -> Optional[ChunkNode]:
        """è·å–å­å—çš„çˆ¶å—"""
        child = self.nodes.get(child_id)
        if child and child.parent_id:
            return self.nodes.get(child.parent_id)
        return None


class ParentChildRetriever:
    """çˆ¶å­æ£€ç´¢å™¨ - å°å—æ£€ç´¢ï¼Œå¤§å—è¿”å›"""

    def __init__(self, chunker: HierarchicalChunker, vectorstore):
        self.chunker = chunker
        self.vectorstore = vectorstore

    def retrieve(self, query: str, k: int = 4) -> list[str]:
        """
        1. ç”¨å­å—è¿›è¡Œæ£€ç´¢ï¼ˆæ›´ç²¾ç¡®ï¼‰
        2. è¿”å›å¯¹åº”çš„çˆ¶å—ï¼ˆæ›´å®Œæ•´çš„ä¸Šä¸‹æ–‡ï¼‰
        """
        # æ£€ç´¢å­å—
        child_results = self.vectorstore.similarity_search(query, k=k)

        # è·å–å¯¹åº”çš„çˆ¶å—ï¼Œå»é‡
        parent_contents = []
        seen_parent_ids = set()

        for result in child_results:
            child_id = result.metadata.get("chunk_id")
            parent = self.chunker.get_parent(child_id)

            if parent and parent.id not in seen_parent_ids:
                parent_contents.append(parent.content)
                seen_parent_ids.add(parent.id)

        return parent_contents
```

---

## 3. æŸ¥è¯¢ç†è§£ä¸ä¼˜åŒ–

### 3.1 æŸ¥è¯¢ä¼˜åŒ–ç­–ç•¥æ¦‚è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       æŸ¥è¯¢ä¼˜åŒ–ç­–ç•¥                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚                        â”‚   åŸå§‹æŸ¥è¯¢    â”‚                                 â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â”‚                               â”‚                                         â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚              â”‚                â”‚                â”‚                        â”‚
â”‚              â–¼                â–¼                â–¼                        â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚     â”‚   æŸ¥è¯¢é‡å†™    â”‚ â”‚   æŸ¥è¯¢æ‰©å±•    â”‚ â”‚   æŸ¥è¯¢åˆ†è§£    â”‚                 â”‚
â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                 â”‚
â”‚     â”‚ HyDE         â”‚ â”‚ åŒä¹‰è¯æ‰©å±•   â”‚ â”‚ å­é—®é¢˜åˆ†è§£   â”‚                 â”‚
â”‚     â”‚ Step-back    â”‚ â”‚ LLMæ‰©å±•     â”‚ â”‚ å¤šè·³é—®é¢˜     â”‚                 â”‚
â”‚     â”‚ æ„å›¾æ˜ç¡®åŒ–    â”‚ â”‚ å¤šè¯­è¨€æ‰©å±•   â”‚ â”‚ æ ‘çŠ¶åˆ†è§£     â”‚                 â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚              â”‚                â”‚                â”‚                        â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                               â–¼                                         â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚                      â”‚  ä¼˜åŒ–åæŸ¥è¯¢   â”‚                                  â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 HyDEï¼ˆHypothetical Document Embeddingï¼‰

```python
from langchain.chat_models import ChatOpenAI
from langchain.embeddings import OpenAIEmbeddings

class HyDEQueryTransformer:
    """
    HyDE: å‡è®¾æ€§æ–‡æ¡£åµŒå…¥

    åŸç†: å…ˆè®©LLMç”Ÿæˆä¸€ä¸ªå‡è®¾æ€§ç­”æ¡ˆï¼Œ
    ç”¨è¿™ä¸ªç­”æ¡ˆï¼ˆè€ŒéåŸå§‹é—®é¢˜ï¼‰å»æ£€ç´¢
    """

    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4", temperature=0.7)
        self.embeddings = OpenAIEmbeddings()

    def transform(self, query: str) -> str:
        """ç”Ÿæˆå‡è®¾æ€§æ–‡æ¡£"""

        prompt = f"""è¯·é’ˆå¯¹ä»¥ä¸‹é—®é¢˜ï¼Œå†™ä¸€æ®µå¯èƒ½å‡ºç°åœ¨ç›¸å…³æ–‡æ¡£ä¸­çš„å›ç­”ã€‚
ä¸éœ€è¦å®Œå…¨å‡†ç¡®ï¼Œä½†è¦åŒ…å«å¯èƒ½çš„å…³é”®ä¿¡æ¯å’Œæœ¯è¯­ã€‚

é—®é¢˜: {query}

å‡è®¾æ€§æ–‡æ¡£å†…å®¹:"""

        response = self.llm.predict(prompt)
        return response

    def get_embedding(self, query: str) -> list[float]:
        """è·å–HyDEåµŒå…¥"""
        # ç”Ÿæˆå‡è®¾æ€§æ–‡æ¡£
        hypothetical_doc = self.transform(query)

        # ä½¿ç”¨å‡è®¾æ€§æ–‡æ¡£çš„åµŒå…¥
        return self.embeddings.embed_query(hypothetical_doc)

    def retrieve_with_hyde(self, query: str, vectorstore, k: int = 4):
        """ä½¿ç”¨HyDEè¿›è¡Œæ£€ç´¢"""
        hyde_embedding = self.get_embedding(query)

        # ä½¿ç”¨å‡è®¾æ€§æ–‡æ¡£åµŒå…¥è¿›è¡Œæ£€ç´¢
        results = vectorstore.similarity_search_by_vector(
            hyde_embedding,
            k=k
        )
        return results
```

### 3.3 Multi-Queryï¼ˆå¤šæŸ¥è¯¢ç­–ç•¥ï¼‰

```python
class MultiQueryRetriever:
    """
    å¤šæŸ¥è¯¢æ£€ç´¢å™¨

    ä»å¤šä¸ªè§’åº¦ç”ŸæˆæŸ¥è¯¢ï¼Œåˆå¹¶æ£€ç´¢ç»“æœ
    æé«˜å¬å›ç‡
    """

    def __init__(self, vectorstore):
        self.vectorstore = vectorstore
        self.llm = ChatOpenAI(model="gpt-4", temperature=0.7)

    def generate_queries(self, original_query: str, n: int = 3) -> list[str]:
        """ç”Ÿæˆå¤šä¸ªæŸ¥è¯¢å˜ä½“"""

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢ä¼˜åŒ–ä¸“å®¶ã€‚ç»™å®šä¸€ä¸ªç”¨æˆ·é—®é¢˜ï¼Œè¯·ç”Ÿæˆ{n}ä¸ªä¸åŒè§’åº¦çš„ç›¸å…³æŸ¥è¯¢ã€‚
è¿™äº›æŸ¥è¯¢åº”è¯¥å¸®åŠ©æ£€ç´¢åˆ°æ›´å…¨é¢çš„ç›¸å…³ä¿¡æ¯ã€‚

åŸå§‹é—®é¢˜: {original_query}

è¯·ç”Ÿæˆ{n}ä¸ªæŸ¥è¯¢ï¼Œæ¯è¡Œä¸€ä¸ª:"""

        response = self.llm.predict(prompt)
        queries = [q.strip() for q in response.strip().split('\n') if q.strip()]

        # åŒ…å«åŸå§‹æŸ¥è¯¢
        return [original_query] + queries[:n]

    def retrieve(self, query: str, k: int = 4) -> list:
        """å¤šæŸ¥è¯¢æ£€ç´¢"""
        # 1. ç”Ÿæˆå¤šä¸ªæŸ¥è¯¢
        queries = self.generate_queries(query)

        # 2. å¯¹æ¯ä¸ªæŸ¥è¯¢è¿›è¡Œæ£€ç´¢
        all_results = []
        seen_contents = set()

        for q in queries:
            results = self.vectorstore.similarity_search(q, k=k)
            for doc in results:
                # å»é‡
                if doc.page_content not in seen_contents:
                    all_results.append(doc)
                    seen_contents.add(doc.page_content)

        return all_results


class QueryDecomposer:
    """
    æŸ¥è¯¢åˆ†è§£å™¨

    å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºç®€å•å­é—®é¢˜
    åˆ†åˆ«æ£€ç´¢ååˆå¹¶
    """

    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4", temperature=0)

    def decompose(self, complex_query: str) -> list[str]:
        """åˆ†è§£å¤æ‚æŸ¥è¯¢"""

        prompt = f"""è¯·å°†ä»¥ä¸‹å¤æ‚é—®é¢˜åˆ†è§£ä¸ºæ›´ç®€å•çš„å­é—®é¢˜ã€‚
æ¯ä¸ªå­é—®é¢˜åº”è¯¥ç‹¬ç«‹å¯å›ç­”ï¼Œä¸”å›ç­”æ‰€æœ‰å­é—®é¢˜èƒ½å¸®åŠ©å›ç­”åŸå§‹é—®é¢˜ã€‚

åŸå§‹é—®é¢˜: {complex_query}

å­é—®é¢˜åˆ—è¡¨ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰:"""

        response = self.llm.predict(prompt)
        sub_queries = [q.strip().lstrip('0123456789.-) ')
                       for q in response.strip().split('\n')
                       if q.strip()]

        return sub_queries

    def retrieve_and_merge(self, query: str, vectorstore, k: int = 2):
        """åˆ†è§£æ£€ç´¢å¹¶åˆå¹¶"""
        sub_queries = self.decompose(query)

        all_results = []
        query_results = {}

        for sub_q in sub_queries:
            results = vectorstore.similarity_search(sub_q, k=k)
            query_results[sub_q] = results
            all_results.extend(results)

        return query_results, all_results
```

### 3.4 Step-Back Prompting

```python
class StepBackRetriever:
    """
    Step-Back Prompting

    å¯¹äºå…·ä½“é—®é¢˜ï¼Œå…ˆé€€ä¸€æ­¥é—®æ›´æŠ½è±¡çš„é—®é¢˜
    è·å–æ›´å¤šèƒŒæ™¯çŸ¥è¯†
    """

    def __init__(self, vectorstore):
        self.vectorstore = vectorstore
        self.llm = ChatOpenAI(model="gpt-4", temperature=0)

    def generate_stepback_query(self, query: str) -> str:
        """ç”Ÿæˆstep-backæŸ¥è¯¢"""

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªé—®é¢˜æŠ½è±¡ä¸“å®¶ã€‚ç»™å®šä¸€ä¸ªå…·ä½“é—®é¢˜ï¼Œ
è¯·ç”Ÿæˆä¸€ä¸ªæ›´æŠ½è±¡ã€æ›´åŸºç¡€çš„é—®é¢˜ï¼Œè¿™ä¸ªé—®é¢˜çš„ç­”æ¡ˆèƒ½æä¾›å›ç­”åŸå§‹é—®é¢˜æ‰€éœ€çš„èƒŒæ™¯çŸ¥è¯†ã€‚

åŸå§‹é—®é¢˜: {query}

æŠ½è±¡é—®é¢˜:"""

        return self.llm.predict(prompt).strip()

    def retrieve(self, query: str, k: int = 4):
        """Step-backæ£€ç´¢"""
        # 1. ç”ŸæˆæŠ½è±¡é—®é¢˜
        stepback_query = self.generate_stepback_query(query)

        # 2. æ£€ç´¢åŸå§‹é—®é¢˜ç›¸å…³æ–‡æ¡£
        original_results = self.vectorstore.similarity_search(query, k=k)

        # 3. æ£€ç´¢æŠ½è±¡é—®é¢˜ç›¸å…³æ–‡æ¡£ï¼ˆèƒŒæ™¯çŸ¥è¯†ï¼‰
        stepback_results = self.vectorstore.similarity_search(stepback_query, k=k//2)

        # 4. åˆå¹¶ç»“æœï¼ŒèƒŒæ™¯çŸ¥è¯†æ”¾å‰é¢
        return {
            'background': stepback_results,
            'specific': original_results,
            'stepback_query': stepback_query
        }
```

---

## 4. é«˜çº§æ£€ç´¢æŠ€æœ¯

### 4.1 æ··åˆæ£€ç´¢ï¼ˆHybrid Searchï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        æ··åˆæ£€ç´¢æ¶æ„                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚                         â”‚    Query     â”‚                               â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                                â”‚                                        â”‚
â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                 â”‚                             â”‚                         â”‚
â”‚                 â–¼                             â–¼                         â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚        â”‚  ç¨€ç–æ£€ç´¢     â”‚              â”‚   ç¨ å¯†æ£€ç´¢    â”‚                  â”‚
â”‚        â”‚  (BM25)      â”‚              â”‚  (Embedding) â”‚                  â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚               â”‚                             â”‚                          â”‚
â”‚               â”‚  å…³é”®è¯åŒ¹é…                   â”‚  è¯­ä¹‰ç›¸ä¼¼                â”‚
â”‚               â”‚  ç²¾ç¡®åŒ¹é…å¼º                   â”‚  æ¨¡ç³ŠåŒ¹é…å¼º              â”‚
â”‚               â”‚                             â”‚                          â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                              â”‚                                         â”‚
â”‚                              â–¼                                         â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚                     â”‚   åˆ†æ•°èåˆ    â”‚                                   â”‚
â”‚                     â”‚  (RRF/åŠ æƒ)  â”‚                                   â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚                            â”‚                                           â”‚
â”‚                            â–¼                                           â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚                     â”‚   æœ€ç»ˆç»“æœ    â”‚                                   â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```python
from rank_bm25 import BM25Okapi
import numpy as np
from typing import List, Tuple

class HybridRetriever:
    """
    æ··åˆæ£€ç´¢å™¨
    ç»“åˆBM25ï¼ˆç¨€ç–ï¼‰å’Œå‘é‡ï¼ˆç¨ å¯†ï¼‰æ£€ç´¢
    """

    def __init__(self,
                 documents: list[str],
                 embeddings_model,
                 vectorstore,
                 alpha: float = 0.5):
        """
        alpha: ç¨ å¯†æ£€ç´¢çš„æƒé‡ (0-1)
               0 = çº¯BM25, 1 = çº¯å‘é‡
        """
        self.documents = documents
        self.embeddings_model = embeddings_model
        self.vectorstore = vectorstore
        self.alpha = alpha

        # åˆå§‹åŒ–BM25
        tokenized_docs = [doc.lower().split() for doc in documents]
        self.bm25 = BM25Okapi(tokenized_docs)

    def search(self, query: str, k: int = 10) -> list[Tuple[str, float]]:
        """æ··åˆæ£€ç´¢"""
        # 1. BM25 æ£€ç´¢
        bm25_scores = self._bm25_search(query)

        # 2. å‘é‡æ£€ç´¢
        vector_scores = self._vector_search(query)

        # 3. åˆ†æ•°èåˆ
        final_scores = self._fuse_scores(bm25_scores, vector_scores)

        # 4. æ’åºè¿”å›
        sorted_results = sorted(final_scores.items(),
                               key=lambda x: x[1],
                               reverse=True)

        return [(self.documents[idx], score)
                for idx, score in sorted_results[:k]]

    def _bm25_search(self, query: str) -> dict[int, float]:
        """BM25æ£€ç´¢"""
        tokenized_query = query.lower().split()
        scores = self.bm25.get_scores(tokenized_query)

        # å½’ä¸€åŒ–åˆ†æ•°
        max_score = max(scores) if max(scores) > 0 else 1
        normalized = {i: score/max_score for i, score in enumerate(scores)}

        return normalized

    def _vector_search(self, query: str) -> dict[int, float]:
        """å‘é‡æ£€ç´¢"""
        results = self.vectorstore.similarity_search_with_score(
            query,
            k=len(self.documents)
        )

        # è½¬æ¢ä¸ºç´¢å¼•->åˆ†æ•°æ˜ å°„
        scores = {}
        for doc, score in results:
            idx = self.documents.index(doc.page_content)
            # å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦ï¼ˆå‡è®¾æ˜¯L2è·ç¦»ï¼‰
            scores[idx] = 1 / (1 + score)

        return scores

    def _fuse_scores(self,
                     bm25_scores: dict[int, float],
                     vector_scores: dict[int, float]) -> dict[int, float]:
        """åˆ†æ•°èåˆ"""
        fused = {}
        all_indices = set(bm25_scores.keys()) | set(vector_scores.keys())

        for idx in all_indices:
            bm25 = bm25_scores.get(idx, 0)
            vector = vector_scores.get(idx, 0)

            # åŠ æƒèåˆ
            fused[idx] = (1 - self.alpha) * bm25 + self.alpha * vector

        return fused

    def search_with_rrf(self, query: str, k: int = 10,
                        rrf_k: int = 60) -> list[Tuple[str, float]]:
        """
        ä½¿ç”¨ Reciprocal Rank Fusion (RRF) èåˆ
        RRFå¯¹æ’åæ›´é²æ£’
        """
        # è·å–ä¸¤ä¸ªæ£€ç´¢å™¨çš„æ’å
        bm25_ranking = self._get_bm25_ranking(query)
        vector_ranking = self._get_vector_ranking(query)

        # RRF å…¬å¼: score = sum(1 / (k + rank))
        rrf_scores = {}

        for idx, rank in bm25_ranking.items():
            rrf_scores[idx] = rrf_scores.get(idx, 0) + 1 / (rrf_k + rank)

        for idx, rank in vector_ranking.items():
            rrf_scores[idx] = rrf_scores.get(idx, 0) + 1 / (rrf_k + rank)

        # æ’åº
        sorted_results = sorted(rrf_scores.items(),
                               key=lambda x: x[1],
                               reverse=True)

        return [(self.documents[idx], score)
                for idx, score in sorted_results[:k]]

    def _get_bm25_ranking(self, query: str) -> dict[int, int]:
        """è·å–BM25æ’å"""
        scores = self._bm25_search(query)
        sorted_indices = sorted(scores.keys(),
                               key=lambda x: scores[x],
                               reverse=True)
        return {idx: rank for rank, idx in enumerate(sorted_indices)}

    def _get_vector_ranking(self, query: str) -> dict[int, int]:
        """è·å–å‘é‡æ£€ç´¢æ’å"""
        scores = self._vector_search(query)
        sorted_indices = sorted(scores.keys(),
                               key=lambda x: scores[x],
                               reverse=True)
        return {idx: rank for rank, idx in enumerate(sorted_indices)}
```

### 4.2 å¤šå‘é‡æ£€ç´¢

```python
from typing import List, Dict, Any

class MultiVectorRetriever:
    """
    å¤šå‘é‡æ£€ç´¢å™¨
    ä¸ºæ¯ä¸ªæ–‡æ¡£ç”Ÿæˆå¤šä¸ªå‘é‡è¡¨ç¤º
    """

    def __init__(self, embeddings_model, llm):
        self.embeddings = embeddings_model
        self.llm = llm
        self.doc_store = {}  # doc_id -> original document
        self.vector_store = None  # å­˜å‚¨å¤šä¸ªå‘é‡

    def add_documents(self, documents: list[str]):
        """
        ä¸ºæ¯ä¸ªæ–‡æ¡£åˆ›å»ºå¤šä¸ªå‘é‡:
        1. åŸæ–‡æ¡£å‘é‡
        2. æ‘˜è¦å‘é‡
        3. é—®é¢˜å‘é‡ï¼ˆå‡è®¾æ€§é—®é¢˜ï¼‰
        """
        all_vectors = []
        all_metadata = []

        for i, doc in enumerate(documents):
            doc_id = f"doc_{i}"
            self.doc_store[doc_id] = doc

            # 1. åŸæ–‡æ¡£å‘é‡
            all_vectors.append({
                'text': doc,
                'doc_id': doc_id,
                'vector_type': 'original'
            })

            # 2. ç”Ÿæˆæ‘˜è¦å¹¶åˆ›å»ºå‘é‡
            summary = self._generate_summary(doc)
            all_vectors.append({
                'text': summary,
                'doc_id': doc_id,
                'vector_type': 'summary'
            })

            # 3. ç”Ÿæˆå‡è®¾æ€§é—®é¢˜
            questions = self._generate_questions(doc)
            for q in questions:
                all_vectors.append({
                    'text': q,
                    'doc_id': doc_id,
                    'vector_type': 'question'
                })

        # åˆ›å»ºå‘é‡å­˜å‚¨
        self._build_vector_store(all_vectors)

    def _generate_summary(self, doc: str) -> str:
        """ç”Ÿæˆæ–‡æ¡£æ‘˜è¦"""
        prompt = f"è¯·ç”¨1-2å¥è¯æ€»ç»“ä»¥ä¸‹æ–‡æœ¬çš„æ ¸å¿ƒå†…å®¹:\n\n{doc}"
        return self.llm.predict(prompt)

    def _generate_questions(self, doc: str, n: int = 3) -> list[str]:
        """ç”Ÿæˆå¯ä»¥ç”¨è¯¥æ–‡æ¡£å›ç­”çš„é—®é¢˜"""
        prompt = f"""åŸºäºä»¥ä¸‹æ–‡æ¡£ï¼Œç”Ÿæˆ{n}ä¸ªå¯ä»¥ç”¨è¯¥æ–‡æ¡£å›ç­”çš„é—®é¢˜:

æ–‡æ¡£: {doc}

é—®é¢˜åˆ—è¡¨:"""

        response = self.llm.predict(prompt)
        questions = [q.strip().lstrip('0123456789.-) ')
                    for q in response.split('\n') if q.strip()]
        return questions[:n]

    def _build_vector_store(self, vectors: list[dict]):
        """æ„å»ºå‘é‡å­˜å‚¨"""
        # ä½¿ç”¨LangChainæˆ–å…¶ä»–å‘é‡æ•°æ®åº“
        from langchain.vectorstores import FAISS
        from langchain.schema import Document

        docs = [
            Document(
                page_content=v['text'],
                metadata={'doc_id': v['doc_id'], 'type': v['vector_type']}
            )
            for v in vectors
        ]

        self.vector_store = FAISS.from_documents(docs, self.embeddings)

    def retrieve(self, query: str, k: int = 4) -> list[str]:
        """æ£€ç´¢åŸå§‹æ–‡æ¡£"""
        # æ£€ç´¢ç›¸å…³å‘é‡
        results = self.vector_store.similarity_search(query, k=k*3)

        # è·å–å”¯ä¸€çš„æ–‡æ¡£ID
        seen_doc_ids = set()
        final_docs = []

        for result in results:
            doc_id = result.metadata['doc_id']
            if doc_id not in seen_doc_ids:
                final_docs.append(self.doc_store[doc_id])
                seen_doc_ids.add(doc_id)

                if len(final_docs) >= k:
                    break

        return final_docs
```

---

## 5. é‡æ’åºæŠ€æœ¯

### 5.1 é‡æ’åºæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         é‡æ’åºæµç¨‹                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”‚
â”‚   â”‚    Query     â”‚                                                     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚
â”‚          â”‚                                                             â”‚
â”‚          â–¼                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚  åˆå§‹æ£€ç´¢     â”‚â”€â”€â”€â”€â–¶â”‚  å€™é€‰æ–‡æ¡£é›†åˆ (top-100)                â”‚       â”‚
â”‚   â”‚  (å¬å›é˜¶æ®µ)   â”‚     â”‚  D1, D2, D3, ... D100                â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                           â”‚                            â”‚
â”‚                                           â–¼                            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚                     é‡æ’åºæ¨¡å‹                               â”‚      â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚      â”‚
â”‚   â”‚  â”‚  Cross-Encoder: åŒæ—¶ç¼–ç  query å’Œ document         â”‚   â”‚      â”‚
â”‚   â”‚  â”‚  æ¯” Bi-Encoder æ›´ç²¾ç¡®ï¼Œä½†æ›´æ…¢                       â”‚   â”‚      â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚      â”‚
â”‚   â”‚                                                            â”‚      â”‚
â”‚   â”‚  è¾“å…¥: (query, doc) pairs                                  â”‚      â”‚
â”‚   â”‚  è¾“å‡º: relevance score                                     â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                    â”‚                                   â”‚
â”‚                                    â–¼                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚   â”‚  é‡æ’åºåçš„ç»“æœ (top-k)                                     â”‚        â”‚
â”‚   â”‚  æŒ‰ç›¸å…³æ€§å¾—åˆ†é‡æ–°æ’åˆ—                                        â”‚        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Cross-Encoder é‡æ’åº

```python
from sentence_transformers import CrossEncoder
from typing import List, Tuple

class CrossEncoderReranker:
    """
    Cross-Encoder é‡æ’åºå™¨

    ä¸ Bi-Encoder çš„åŒºåˆ«:
    - Bi-Encoder: åˆ†åˆ«ç¼–ç queryå’Œdocï¼Œè®¡ç®—å‘é‡ç›¸ä¼¼åº¦
    - Cross-Encoder: åŒæ—¶ç¼–ç queryå’Œdocï¼Œç›´æ¥é¢„æµ‹ç›¸å…³æ€§åˆ†æ•°

    Cross-Encoderæ›´ç²¾ç¡®ï¼Œä½†é€Ÿåº¦æ›´æ…¢
    """

    def __init__(self, model_name: str = "cross-encoder/ms-marco-MiniLM-L-6-v2"):
        self.model = CrossEncoder(model_name)

    def rerank(self,
               query: str,
               documents: list[str],
               top_k: int = None) -> list[Tuple[str, float]]:
        """
        é‡æ’åºæ–‡æ¡£

        Args:
            query: æŸ¥è¯¢
            documents: å¾…æ’åºæ–‡æ¡£åˆ—è¡¨
            top_k: è¿”å›å‰kä¸ªç»“æœ

        Returns:
            æ’åºåçš„ (æ–‡æ¡£, åˆ†æ•°) åˆ—è¡¨
        """
        # åˆ›å»º query-document pairs
        pairs = [[query, doc] for doc in documents]

        # è·å–ç›¸å…³æ€§åˆ†æ•°
        scores = self.model.predict(pairs)

        # æ’åº
        doc_scores = list(zip(documents, scores))
        doc_scores.sort(key=lambda x: x[1], reverse=True)

        if top_k:
            doc_scores = doc_scores[:top_k]

        return doc_scores


class ColBERTReranker:
    """
    ColBERT é£æ ¼çš„é‡æ’åº

    ä½¿ç”¨ late interaction:
    - åˆ†åˆ«ç¼–ç queryå’Œdocumentçš„æ¯ä¸ªtoken
    - è®¡ç®—tokençº§åˆ«çš„æœ€å¤§ç›¸ä¼¼åº¦
    - æ›´é«˜æ•ˆçš„cross-encoderæ›¿ä»£æ–¹æ¡ˆ
    """

    def __init__(self, model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
        from sentence_transformers import SentenceTransformer
        self.model = SentenceTransformer(model_name)

    def rerank(self,
               query: str,
               documents: list[str],
               top_k: int = None) -> list[Tuple[str, float]]:
        """ä½¿ç”¨MaxSimè¿›è¡Œé‡æ’åº"""

        # è·å–queryçš„tokenåµŒå…¥
        query_embedding = self.model.encode(
            query,
            output_value='token_embeddings'
        )

        doc_scores = []

        for doc in documents:
            # è·å–documentçš„tokenåµŒå…¥
            doc_embedding = self.model.encode(
                doc,
                output_value='token_embeddings'
            )

            # è®¡ç®—MaxSimåˆ†æ•°
            score = self._compute_maxsim(query_embedding, doc_embedding)
            doc_scores.append((doc, score))

        # æ’åº
        doc_scores.sort(key=lambda x: x[1], reverse=True)

        if top_k:
            doc_scores = doc_scores[:top_k]

        return doc_scores

    def _compute_maxsim(self, query_emb, doc_emb) -> float:
        """
        è®¡ç®— MaxSim åˆ†æ•°
        å¯¹queryä¸­æ¯ä¸ªtokenï¼Œæ‰¾åˆ°docä¸­æœ€ç›¸ä¼¼çš„token
        ç„¶åæ±‚å’Œ
        """
        import numpy as np

        # è®¡ç®—æ‰€æœ‰tokenå¯¹çš„ç›¸ä¼¼åº¦çŸ©é˜µ
        sim_matrix = np.dot(query_emb, doc_emb.T)

        # å¯¹æ¯ä¸ªquery tokenå–æœ€å¤§ç›¸ä¼¼åº¦
        max_sims = sim_matrix.max(axis=1)

        # æ±‚å’Œä½œä¸ºæœ€ç»ˆåˆ†æ•°
        return float(max_sims.sum())
```

### 5.3 LLM é‡æ’åº

```python
class LLMReranker:
    """
    ä½¿ç”¨LLMè¿›è¡Œé‡æ’åº

    ä¼˜ç‚¹: å¯ä»¥ç†è§£å¤æ‚çš„è¯­ä¹‰å…³ç³»
    ç¼ºç‚¹: æˆæœ¬è¾ƒé«˜ï¼Œé€Ÿåº¦è¾ƒæ…¢
    """

    def __init__(self, llm):
        self.llm = llm

    def rerank(self,
               query: str,
               documents: list[str],
               top_k: int = 5) -> list[Tuple[str, float]]:
        """ä½¿ç”¨LLMè¿›è¡Œé‡æ’åº"""

        # æ–¹æ³•1: Pointwise - å¯¹æ¯ä¸ªæ–‡æ¡£å•ç‹¬è¯„åˆ†
        return self._pointwise_rerank(query, documents, top_k)

    def _pointwise_rerank(self, query: str, documents: list[str],
                          top_k: int) -> list[Tuple[str, float]]:
        """é€ç‚¹è¯„åˆ†"""
        scored_docs = []

        for doc in documents:
            score = self._score_document(query, doc)
            scored_docs.append((doc, score))

        scored_docs.sort(key=lambda x: x[1], reverse=True)
        return scored_docs[:top_k]

    def _score_document(self, query: str, document: str) -> float:
        """ä¸ºå•ä¸ªæ–‡æ¡£è¯„åˆ†"""
        prompt = f"""è¯·è¯„ä¼°ä»¥ä¸‹æ–‡æ¡£ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§ã€‚

æŸ¥è¯¢: {query}

æ–‡æ¡£: {document}

è¯·ç»™å‡º1-10çš„ç›¸å…³æ€§è¯„åˆ†ï¼Œå…¶ä¸­:
- 1-3: ä¸ç›¸å…³
- 4-6: éƒ¨åˆ†ç›¸å…³
- 7-10: é«˜åº¦ç›¸å…³

åªè¾“å‡ºæ•°å­—åˆ†æ•°:"""

        response = self.llm.predict(prompt)

        try:
            score = float(response.strip())
            return min(max(score, 1), 10)  # é™åˆ¶åœ¨1-10èŒƒå›´
        except:
            return 5.0  # é»˜è®¤ä¸­ç­‰åˆ†æ•°

    def listwise_rerank(self, query: str, documents: list[str],
                        top_k: int = 5) -> list[str]:
        """
        åˆ—è¡¨çº§é‡æ’åº
        ä¸€æ¬¡æ€§å¯¹æ‰€æœ‰æ–‡æ¡£æ’åº
        æ›´é«˜æ•ˆä½†å¯èƒ½å—ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶
        """

        # ä¸ºæ–‡æ¡£ç¼–å·
        doc_list = "\n".join([f"[{i}] {doc[:200]}..."
                              for i, doc in enumerate(documents)])

        prompt = f"""è¯·æ ¹æ®ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§ï¼Œå¯¹ä»¥ä¸‹æ–‡æ¡£è¿›è¡Œæ’åºã€‚

æŸ¥è¯¢: {query}

æ–‡æ¡£åˆ—è¡¨:
{doc_list}

è¯·æŒ‰ç›¸å…³æ€§ä»é«˜åˆ°ä½è¾“å‡ºæ–‡æ¡£ç¼–å·ï¼Œç”¨é€—å·åˆ†éš”:"""

        response = self.llm.predict(prompt)

        # è§£ææ’åºç»“æœ
        try:
            indices = [int(x.strip().strip('[]'))
                      for x in response.split(',')]
            reranked = [documents[i] for i in indices if i < len(documents)]
            return reranked[:top_k]
        except:
            return documents[:top_k]
```

---

## 6. ä¸Šä¸‹æ–‡å‹ç¼©ä¸ä¼˜åŒ–

### 6.1 ä¸Šä¸‹æ–‡å‹ç¼©ç­–ç•¥

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ä¸Šä¸‹æ–‡å‹ç¼©ç­–ç•¥                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    æ£€ç´¢åˆ°çš„æ–‡æ¡£                                   â”‚   â”‚
â”‚  â”‚  [å¾ˆé•¿çš„æ–‡æ¡£1] [å¾ˆé•¿çš„æ–‡æ¡£2] [å¾ˆé•¿çš„æ–‡æ¡£3] ...                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                          â”‚
â”‚                              â–¼                                          â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚           â”‚            å‹ç¼©ç­–ç•¥é€‰æ‹©               â”‚                     â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                              â”‚                                          â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚        â”‚                     â”‚                     â”‚                    â”‚
â”‚        â–¼                     â–¼                     â–¼                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚   æå–å¼å‹ç¼©   â”‚    â”‚   ç”Ÿæˆå¼å‹ç¼©   â”‚    â”‚  è¿‡æ»¤å¼å‹ç¼©   â”‚             â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”‚
â”‚  â”‚ â€¢ å¥å­æŠ½å–    â”‚    â”‚ â€¢ LLMæ‘˜è¦    â”‚    â”‚ â€¢ ç›¸å…³æ€§è¿‡æ»¤  â”‚             â”‚
â”‚  â”‚ â€¢ å…³é”®æ®µè½    â”‚    â”‚ â€¢ ä¿¡æ¯å‹ç¼©    â”‚    â”‚ â€¢ å†—ä½™åˆ é™¤    â”‚             â”‚
â”‚  â”‚ â€¢ ä¿æŒåŸæ–‡    â”‚    â”‚ â€¢ è¯­ä¹‰ä¿æŒ    â”‚    â”‚ â€¢ å»å™ª        â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚        â”‚                     â”‚                     â”‚                    â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                              â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    å‹ç¼©åçš„ä¸Šä¸‹æ–‡                                  â”‚   â”‚
â”‚  â”‚  [ç²¾ç®€å†…å®¹1] [ç²¾ç®€å†…å®¹2] [ç²¾ç®€å†…å®¹3]                               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 å®ç°

```python
from typing import List
import re

class ContextCompressor:
    """ä¸Šä¸‹æ–‡å‹ç¼©å™¨"""

    def __init__(self, llm):
        self.llm = llm

    def extract_relevant_sentences(self,
                                    query: str,
                                    document: str,
                                    max_sentences: int = 5) -> str:
        """æå–å¼å‹ç¼© - æŠ½å–æœ€ç›¸å…³çš„å¥å­"""

        # åˆ†å‰²å¥å­
        sentences = re.split(r'(?<=[.!?])\s+', document)

        # ä½¿ç”¨LLMé€‰æ‹©æœ€ç›¸å…³çš„å¥å­
        prompt = f"""ç»™å®šæŸ¥è¯¢å’Œæ–‡æ¡£ï¼Œè¯·é€‰æ‹©æœ€ç›¸å…³çš„{max_sentences}ä¸ªå¥å­ã€‚

æŸ¥è¯¢: {query}

æ–‡æ¡£å¥å­:
{chr(10).join([f'{i}. {s}' for i, s in enumerate(sentences)])}

è¯·è¾“å‡ºç›¸å…³å¥å­çš„ç¼–å·ï¼Œç”¨é€—å·åˆ†éš”:"""

        response = self.llm.predict(prompt)

        try:
            indices = [int(x.strip()) for x in response.split(',')]
            selected = [sentences[i] for i in indices if i < len(sentences)]
            return ' '.join(selected)
        except:
            return document[:1000]  # å¤±è´¥æ—¶è¿”å›æˆªæ–­å†…å®¹

    def abstractive_compress(self,
                             query: str,
                             document: str,
                             max_tokens: int = 200) -> str:
        """ç”Ÿæˆå¼å‹ç¼© - LLMé‡å†™"""

        prompt = f"""è¯·æ ¹æ®æŸ¥è¯¢å‹ç¼©ä»¥ä¸‹æ–‡æ¡£ï¼Œåªä¿ç•™å›ç­”æŸ¥è¯¢æ‰€éœ€çš„å…³é”®ä¿¡æ¯ã€‚
å‹ç¼©åçš„å†…å®¹ä¸è¶…è¿‡{max_tokens}è¯ã€‚

æŸ¥è¯¢: {query}

åŸå§‹æ–‡æ¡£: {document}

å‹ç¼©åçš„å†…å®¹:"""

        return self.llm.predict(prompt)

    def filter_irrelevant(self,
                          query: str,
                          documents: list[str],
                          threshold: float = 0.5) -> list[str]:
        """è¿‡æ»¤å¼å‹ç¼© - åˆ é™¤ä¸ç›¸å…³æ–‡æ¡£"""

        filtered = []

        for doc in documents:
            # ä½¿ç”¨LLMåˆ¤æ–­ç›¸å…³æ€§
            prompt = f"""æ–‡æ¡£ä¸æŸ¥è¯¢æ˜¯å¦ç›¸å…³ï¼Ÿåªå›ç­”"æ˜¯"æˆ–"å¦"ã€‚

æŸ¥è¯¢: {query}
æ–‡æ¡£: {doc[:500]}

å›ç­”:"""

            response = self.llm.predict(prompt).strip().lower()

            if 'æ˜¯' in response or 'yes' in response:
                filtered.append(doc)

        return filtered


class LongContextOptimizer:
    """é•¿ä¸Šä¸‹æ–‡ä¼˜åŒ–å™¨"""

    def __init__(self, llm):
        self.llm = llm

    def reorder_documents(self, documents: list[str]) -> list[str]:
        """
        Lost in the Middle ä¼˜åŒ–

        ç ”ç©¶è¡¨æ˜LLMå¯¹ä¸­é—´ä½ç½®çš„å†…å®¹æ³¨æ„åŠ›è¾ƒä½
        å°†é‡è¦æ–‡æ¡£æ”¾åœ¨å¼€å¤´å’Œç»“å°¾
        """
        n = len(documents)
        if n <= 2:
            return documents

        # å‡è®¾æ–‡æ¡£æŒ‰ç›¸å…³æ€§é™åºæ’åˆ—
        reordered = []

        # äº¤æ›¿æ”¾ç½®ï¼šå¼€å¤´å’Œç»“å°¾
        for i, doc in enumerate(documents):
            if i % 2 == 0:
                reordered.insert(0, doc)  # æ”¾å¼€å¤´
            else:
                reordered.append(doc)      # æ”¾ç»“å°¾

        return reordered

    def create_hierarchical_context(self,
                                     query: str,
                                     documents: list[str]) -> str:
        """åˆ›å»ºå±‚æ¬¡åŒ–ä¸Šä¸‹æ–‡"""

        # ä¸ºæ¯ä¸ªæ–‡æ¡£ç”Ÿæˆä¸€è¡Œæ‘˜è¦
        summaries = []
        for i, doc in enumerate(documents):
            summary = self._summarize_short(doc)
            summaries.append(f"[æ–‡æ¡£{i+1}æ‘˜è¦]: {summary}")

        context = f"""ä»¥ä¸‹æ˜¯æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£ï¼š

=== æ–‡æ¡£æ¦‚è§ˆ ===
{chr(10).join(summaries)}

=== è¯¦ç»†å†…å®¹ ===
"""

        for i, doc in enumerate(documents):
            context += f"\n[æ–‡æ¡£{i+1}]\n{doc}\n"

        return context

    def _summarize_short(self, text: str) -> str:
        """ç”Ÿæˆç®€çŸ­æ‘˜è¦"""
        prompt = f"ç”¨ä¸€å¥è¯æ€»ç»“: {text[:500]}"
        return self.llm.predict(prompt)
```

---

## 7. å¤šè·³æ¨ç†RAG

### 7.1 å¤šè·³æ¨ç†æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       å¤šè·³æ¨ç† RAG                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  å¤æ‚é—®é¢˜: "è‹¹æœå…¬å¸CEOå‡ºç”Ÿåœ¨å“ªä¸ªå›½å®¶çš„é¦–éƒ½ï¼Ÿ"                            â”‚
â”‚                                                                         â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚         â”‚               ç¬¬ä¸€è·³                           â”‚              â”‚
â”‚         â”‚  é—®é¢˜åˆ†è§£: "è‹¹æœå…¬å¸çš„CEOæ˜¯è°ï¼Ÿ"                â”‚              â”‚
â”‚         â”‚  æ£€ç´¢ â†’ ç­”æ¡ˆ: Tim Cook                        â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                 â”‚                                       â”‚
â”‚                                 â–¼                                       â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚         â”‚               ç¬¬äºŒè·³                           â”‚              â”‚
â”‚         â”‚  é—®é¢˜: "Tim Cook å‡ºç”Ÿåœ¨å“ªä¸ªåŸå¸‚ï¼Ÿ"             â”‚              â”‚
â”‚         â”‚  æ£€ç´¢ â†’ ç­”æ¡ˆ: Mobile, Alabama                 â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                 â”‚                                       â”‚
â”‚                                 â–¼                                       â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚         â”‚               ç¬¬ä¸‰è·³                           â”‚              â”‚
â”‚         â”‚  é—®é¢˜: "Mobile æ˜¯å“ªä¸ªå›½å®¶çš„é¦–éƒ½ï¼Ÿ"             â”‚              â”‚
â”‚         â”‚  æ£€ç´¢ â†’ ç­”æ¡ˆ: ä¸æ˜¯é¦–éƒ½ (éœ€è¦è°ƒæ•´æ¨ç†)          â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                 â”‚                                       â”‚
â”‚                                 â–¼                                       â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚         â”‚            ç»¼åˆæ¨ç†ç”Ÿæˆç­”æ¡ˆ                     â”‚              â”‚
â”‚         â”‚  åŸºäºæ”¶é›†çš„æ‰€æœ‰ä¿¡æ¯ç”Ÿæˆæœ€ç»ˆå›ç­”                 â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 è¿­ä»£å¼ RAG å®ç°

```python
from dataclasses import dataclass
from typing import Optional, List

@dataclass
class ReasoningStep:
    """æ¨ç†æ­¥éª¤"""
    thought: str          # æ€è€ƒè¿‡ç¨‹
    action: str           # åŠ¨ä½œç±»å‹ (search/lookup/finish)
    action_input: str     # åŠ¨ä½œè¾“å…¥
    observation: str      # è§‚å¯Ÿç»“æœ

class IterativeRAG:
    """
    è¿­ä»£å¼ RAG (ReAct é£æ ¼)

    æ€è€ƒ â†’ è¡ŒåŠ¨ â†’ è§‚å¯Ÿ â†’ æ€è€ƒ â†’ ...
    """

    def __init__(self, retriever, llm, max_iterations: int = 5):
        self.retriever = retriever
        self.llm = llm
        self.max_iterations = max_iterations

    def query(self, question: str) -> tuple[str, list[ReasoningStep]]:
        """è¿­ä»£å¼é—®ç­”"""

        steps: List[ReasoningStep] = []
        context = ""

        for i in range(self.max_iterations):
            # æ„å»ºæç¤º
            prompt = self._build_prompt(question, steps)

            # è·å–ä¸‹ä¸€æ­¥åŠ¨ä½œ
            response = self.llm.predict(prompt)

            # è§£æå“åº”
            thought, action, action_input = self._parse_response(response)

            if action == "Finish":
                # å®Œæˆæ¨ç†
                final_answer = action_input
                steps.append(ReasoningStep(
                    thought=thought,
                    action=action,
                    action_input=action_input,
                    observation="å®Œæˆ"
                ))
                return final_answer, steps

            elif action == "Search":
                # æ‰§è¡Œæ£€ç´¢
                results = self.retriever.search(action_input)
                observation = self._format_results(results)

            elif action == "Lookup":
                # åœ¨å·²æœ‰ä¸Šä¸‹æ–‡ä¸­æŸ¥æ‰¾
                observation = self._lookup_in_context(action_input, context)

            else:
                observation = "æœªçŸ¥åŠ¨ä½œ"

            steps.append(ReasoningStep(
                thought=thought,
                action=action,
                action_input=action_input,
                observation=observation
            ))

            context += f"\n{observation}"

        return "è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°", steps

    def _build_prompt(self, question: str, steps: list[ReasoningStep]) -> str:
        """æ„å»ºReActé£æ ¼çš„æç¤º"""

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ¨ç†åŠ©æ‰‹ã€‚ä½¿ç”¨ä»¥ä¸‹æ ¼å¼å›ç­”é—®é¢˜ï¼š

é—®é¢˜ï¼šéœ€è¦å›ç­”çš„é—®é¢˜
æ€è€ƒï¼šåˆ†æé—®é¢˜ï¼Œå†³å®šä¸‹ä¸€æ­¥
åŠ¨ä½œï¼šSearch[æŸ¥è¯¢] æˆ– Lookup[å…³é”®è¯] æˆ– Finish[æœ€ç»ˆç­”æ¡ˆ]
è§‚å¯Ÿï¼šåŠ¨ä½œçš„ç»“æœ

é—®é¢˜: {question}
"""

        for step in steps:
            prompt += f"""
æ€è€ƒ: {step.thought}
åŠ¨ä½œ: {step.action}[{step.action_input}]
è§‚å¯Ÿ: {step.observation}
"""

        prompt += "\næ€è€ƒ:"

        return prompt

    def _parse_response(self, response: str) -> tuple[str, str, str]:
        """è§£æLLMå“åº”"""
        import re

        thought = response.split("åŠ¨ä½œ:")[0].strip()

        action_match = re.search(r'åŠ¨ä½œ:\s*(\w+)\[(.+?)\]', response)
        if action_match:
            action = action_match.group(1)
            action_input = action_match.group(2)
        else:
            action = "Finish"
            action_input = response

        return thought, action, action_input

    def _format_results(self, results: list) -> str:
        """æ ¼å¼åŒ–æ£€ç´¢ç»“æœ"""
        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
        return "\n".join([f"- {r}" for r in results[:3]])

    def _lookup_in_context(self, keyword: str, context: str) -> str:
        """åœ¨ä¸Šä¸‹æ–‡ä¸­æŸ¥æ‰¾"""
        sentences = context.split('.')
        relevant = [s for s in sentences if keyword.lower() in s.lower()]
        return '. '.join(relevant[:2]) if relevant else "æœªæ‰¾åˆ°ç›¸å…³å†…å®¹"


class SelfRAG:
    """
    Self-RAG: è‡ªæˆ‘åæ€å¢å¼ºçš„RAG

    å†³å®šæ˜¯å¦éœ€è¦æ£€ç´¢ï¼Œå¹¶å¯¹ç»“æœè¿›è¡Œè‡ªæˆ‘è¯„ä¼°
    """

    def __init__(self, retriever, llm):
        self.retriever = retriever
        self.llm = llm

    def query(self, question: str) -> dict:
        """å¸¦è‡ªæˆ‘åæ€çš„é—®ç­”"""

        # 1. åˆ¤æ–­æ˜¯å¦éœ€è¦æ£€ç´¢
        needs_retrieval = self._check_retrieval_need(question)

        if not needs_retrieval:
            # ç›´æ¥å›ç­”
            answer = self._generate_answer(question, "")
            return {
                'answer': answer,
                'retrieved': False,
                'sources': []
            }

        # 2. æ£€ç´¢
        documents = self.retriever.search(question)

        # 3. è¯„ä¼°æ¯ä¸ªæ–‡æ¡£çš„ç›¸å…³æ€§
        relevant_docs = []
        for doc in documents:
            if self._is_relevant(question, doc):
                relevant_docs.append(doc)

        # 4. ç”Ÿæˆç­”æ¡ˆ
        context = "\n\n".join(relevant_docs)
        answer = self._generate_answer(question, context)

        # 5. è‡ªæˆ‘è¯„ä¼°ç­”æ¡ˆè´¨é‡
        is_supported = self._check_support(answer, relevant_docs)
        is_useful = self._check_usefulness(question, answer)

        return {
            'answer': answer,
            'retrieved': True,
            'sources': relevant_docs,
            'is_supported': is_supported,
            'is_useful': is_useful
        }

    def _check_retrieval_need(self, question: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æ£€ç´¢"""
        prompt = f"""è¿™ä¸ªé—®é¢˜æ˜¯å¦éœ€è¦æŸ¥è¯¢å¤–éƒ¨çŸ¥è¯†æ¥å›ç­”ï¼Ÿ

é—®é¢˜: {question}

å›ç­”"æ˜¯"æˆ–"å¦":"""

        response = self.llm.predict(prompt)
        return 'æ˜¯' in response.lower() or 'yes' in response.lower()

    def _is_relevant(self, question: str, document: str) -> bool:
        """åˆ¤æ–­æ–‡æ¡£æ˜¯å¦ç›¸å…³"""
        prompt = f"""è¿™ä¸ªæ–‡æ¡£æ˜¯å¦ä¸é—®é¢˜ç›¸å…³ï¼Ÿ

é—®é¢˜: {question}
æ–‡æ¡£: {document[:500]}

å›ç­”"æ˜¯"æˆ–"å¦":"""

        response = self.llm.predict(prompt)
        return 'æ˜¯' in response.lower() or 'yes' in response.lower()

    def _generate_answer(self, question: str, context: str) -> str:
        """ç”Ÿæˆç­”æ¡ˆ"""
        if context:
            prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜:

ä¿¡æ¯: {context}

é—®é¢˜: {question}

å›ç­”:"""
        else:
            prompt = f"å›ç­”é—®é¢˜: {question}"

        return self.llm.predict(prompt)

    def _check_support(self, answer: str, documents: list[str]) -> bool:
        """æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦æœ‰æ–‡æ¡£æ”¯æŒ"""
        context = "\n".join(documents)
        prompt = f"""æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦æœ‰æ–‡æ¡£æ”¯æŒã€‚

æ–‡æ¡£: {context[:1000]}
ç­”æ¡ˆ: {answer}

ç­”æ¡ˆæ˜¯å¦æœ‰å……åˆ†çš„æ–‡æ¡£æ”¯æŒï¼Ÿå›ç­”"æ˜¯"æˆ–"å¦":"""

        response = self.llm.predict(prompt)
        return 'æ˜¯' in response.lower()

    def _check_usefulness(self, question: str, answer: str) -> bool:
        """æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦æœ‰ç”¨"""
        prompt = f"""è¯„ä¼°ç­”æ¡ˆæ˜¯å¦çœŸæ­£å›ç­”äº†é—®é¢˜ã€‚

é—®é¢˜: {question}
ç­”æ¡ˆ: {answer}

ç­”æ¡ˆæ˜¯å¦æœ‰ç”¨ä¸”ç›¸å…³ï¼Ÿå›ç­”"æ˜¯"æˆ–"å¦":"""

        response = self.llm.predict(prompt)
        return 'æ˜¯' in response.lower()
```

## 8. çŸ¥è¯†å›¾è°±å¢å¼ºRAG

### 8.1 Graph RAG æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Knowledge Graph + RAG                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                      çŸ¥è¯†å›¾è°±å±‚                                   â”‚  â”‚
â”‚   â”‚                                                                   â”‚  â”‚
â”‚   â”‚        [å…¬å¸]                        [äººç‰©]                       â”‚  â”‚
â”‚   â”‚          â”‚                             â”‚                         â”‚  â”‚
â”‚   â”‚          â”‚  åˆ›å§‹äºº                      â”‚  å°±èŒäº                  â”‚  â”‚
â”‚   â”‚          â–¼                             â–¼                         â”‚  â”‚
â”‚   â”‚       â”Œâ”€â”€â”€â”€â”€â”    CEO     â”Œâ”€â”€â”€â”€â”€â”    å·¥ä½œäº    â”Œâ”€â”€â”€â”€â”€â”            â”‚  â”‚
â”‚   â”‚       â”‚Appleâ”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚Tim  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ äº§å“ â”‚            â”‚  â”‚
â”‚   â”‚       â””â”€â”€â”€â”€â”€â”˜           â”‚Cook â”‚           â””â”€â”€â”€â”€â”€â”˜            â”‚  â”‚
â”‚   â”‚          â”‚              â””â”€â”€â”€â”€â”€â”˜              â”‚                â”‚  â”‚
â”‚   â”‚          â”‚ äº§å“                               â”‚                â”‚  â”‚
â”‚   â”‚          â–¼                                   â–¼                â”‚  â”‚
â”‚   â”‚       â”Œâ”€â”€â”€â”€â”€â”                           â”Œâ”€â”€â”€â”€â”€â”              â”‚  â”‚
â”‚   â”‚       â”‚iPhoneâ”‚                          â”‚Visionâ”‚              â”‚  â”‚
â”‚   â”‚       â””â”€â”€â”€â”€â”€â”˜                           â”‚ Pro â”‚              â”‚  â”‚
â”‚   â”‚                                         â””â”€â”€â”€â”€â”€â”˜              â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                   â”‚                                     â”‚
â”‚                                   â–¼                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                      æ£€ç´¢èåˆå±‚                                   â”‚  â”‚
â”‚   â”‚                                                                   â”‚  â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚  â”‚
â”‚   â”‚   â”‚    å‘é‡æ£€ç´¢        â”‚    +    â”‚    å›¾è°±éå†        â”‚             â”‚  â”‚
â”‚   â”‚   â”‚  (è¯­ä¹‰ç›¸ä¼¼)        â”‚         â”‚  (ç»“æ„åŒ–å…³ç³»)      â”‚             â”‚  â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚  â”‚
â”‚   â”‚                                                                   â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.2 GraphRAG å®ç°

```python
from typing import List, Dict, Tuple, Set
from dataclasses import dataclass
import networkx as nx

@dataclass
class Entity:
    """å®ä½“"""
    id: str
    name: str
    type: str
    properties: Dict[str, any]

@dataclass
class Relation:
    """å…³ç³»"""
    source: str
    target: str
    type: str
    properties: Dict[str, any]

class KnowledgeGraph:
    """çŸ¥è¯†å›¾è°±"""

    def __init__(self):
        self.graph = nx.DiGraph()
        self.entities: Dict[str, Entity] = {}

    def add_entity(self, entity: Entity):
        """æ·»åŠ å®ä½“"""
        self.entities[entity.id] = entity
        self.graph.add_node(
            entity.id,
            name=entity.name,
            type=entity.type,
            **entity.properties
        )

    def add_relation(self, relation: Relation):
        """æ·»åŠ å…³ç³»"""
        self.graph.add_edge(
            relation.source,
            relation.target,
            type=relation.type,
            **relation.properties
        )

    def get_neighbors(self, entity_id: str,
                      hop: int = 1) -> List[Tuple[str, dict]]:
        """è·å–é‚»å±…èŠ‚ç‚¹"""
        neighbors = []
        visited = {entity_id}
        queue = [(entity_id, 0)]

        while queue:
            node, depth = queue.pop(0)
            if depth >= hop:
                continue

            for neighbor in self.graph.neighbors(node):
                if neighbor not in visited:
                    visited.add(neighbor)
                    edge_data = self.graph[node][neighbor]
                    neighbors.append((neighbor, edge_data))
                    queue.append((neighbor, depth + 1))

        return neighbors

    def get_subgraph(self, entity_ids: List[str]) -> nx.DiGraph:
        """è·å–å­å›¾"""
        return self.graph.subgraph(entity_ids).copy()

    def find_path(self, source: str, target: str) -> List[str]:
        """æŸ¥æ‰¾ä¸¤ä¸ªå®ä½“ä¹‹é—´çš„è·¯å¾„"""
        try:
            return nx.shortest_path(self.graph, source, target)
        except nx.NetworkXNoPath:
            return []


class GraphRAG:
    """
    å›¾å¢å¼ºçš„RAG
    ç»“åˆçŸ¥è¯†å›¾è°±å’Œå‘é‡æ£€ç´¢
    """

    def __init__(self,
                 knowledge_graph: KnowledgeGraph,
                 vectorstore,
                 llm,
                 embeddings):
        self.kg = knowledge_graph
        self.vectorstore = vectorstore
        self.llm = llm
        self.embeddings = embeddings

    def query(self, question: str, k: int = 5) -> dict:
        """å›¾å¢å¼ºæ£€ç´¢é—®ç­”"""

        # 1. æå–é—®é¢˜ä¸­çš„å®ä½“
        entities = self._extract_entities(question)

        # 2. åœ¨çŸ¥è¯†å›¾è°±ä¸­æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯
        graph_context = self._get_graph_context(entities)

        # 3. å‘é‡æ£€ç´¢
        vector_results = self.vectorstore.similarity_search(question, k=k)
        vector_context = "\n\n".join([r.page_content for r in vector_results])

        # 4. åˆå¹¶ä¸Šä¸‹æ–‡
        combined_context = self._merge_contexts(graph_context, vector_context)

        # 5. ç”Ÿæˆç­”æ¡ˆ
        answer = self._generate_answer(question, combined_context)

        return {
            'answer': answer,
            'entities': entities,
            'graph_context': graph_context,
            'vector_context': vector_context
        }

    def _extract_entities(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–å®ä½“"""
        prompt = f"""è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å…³é”®å®ä½“ï¼ˆäººåã€ç»„ç»‡ã€äº§å“ç­‰ï¼‰ã€‚

æ–‡æœ¬: {text}

è¯·åˆ—å‡ºå®ä½“ï¼Œæ¯è¡Œä¸€ä¸ª:"""

        response = self.llm.predict(prompt)
        entities = [e.strip() for e in response.split('\n') if e.strip()]

        # åœ¨çŸ¥è¯†å›¾è°±ä¸­åŒ¹é…
        matched = []
        for entity in entities:
            for eid, e in self.kg.entities.items():
                if entity.lower() in e.name.lower():
                    matched.append(eid)

        return matched

    def _get_graph_context(self, entity_ids: List[str]) -> str:
        """ä»çŸ¥è¯†å›¾è°±è·å–ä¸Šä¸‹æ–‡"""
        context_parts = []

        for eid in entity_ids:
            entity = self.kg.entities.get(eid)
            if not entity:
                continue

            # å®ä½“ä¿¡æ¯
            context_parts.append(f"å®ä½“: {entity.name} (ç±»å‹: {entity.type})")

            # è·å–é‚»å±…
            neighbors = self.kg.get_neighbors(eid, hop=2)
            for neighbor_id, edge_data in neighbors:
                neighbor = self.kg.entities.get(neighbor_id)
                if neighbor:
                    rel_type = edge_data.get('type', 'ç›¸å…³')
                    context_parts.append(
                        f"  - {rel_type} â†’ {neighbor.name}"
                    )

        return "\n".join(context_parts)

    def _merge_contexts(self, graph_ctx: str, vector_ctx: str) -> str:
        """åˆå¹¶å›¾è°±å’Œå‘é‡æ£€ç´¢çš„ä¸Šä¸‹æ–‡"""
        return f"""=== ç»“æ„åŒ–çŸ¥è¯† ===
{graph_ctx}

=== ç›¸å…³æ–‡æ¡£ ===
{vector_ctx}"""

    def _generate_answer(self, question: str, context: str) -> str:
        """ç”Ÿæˆç­”æ¡ˆ"""
        prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ã€‚

{context}

é—®é¢˜: {question}

å›ç­”:"""

        return self.llm.predict(prompt)


class EntityLinker:
    """å®ä½“é“¾æ¥å™¨ - å°†æ–‡æœ¬ä¸­çš„å®ä½“é“¾æ¥åˆ°çŸ¥è¯†å›¾è°±"""

    def __init__(self, kg: KnowledgeGraph, embeddings):
        self.kg = kg
        self.embeddings = embeddings
        self.entity_embeddings = {}

        # é¢„è®¡ç®—æ‰€æœ‰å®ä½“çš„åµŒå…¥
        for eid, entity in kg.entities.items():
            self.entity_embeddings[eid] = embeddings.embed_query(entity.name)

    def link(self, mention: str, threshold: float = 0.7) -> Optional[str]:
        """å°†æåŠé“¾æ¥åˆ°çŸ¥è¯†å›¾è°±å®ä½“"""
        import numpy as np

        mention_emb = self.embeddings.embed_query(mention)

        best_match = None
        best_score = 0

        for eid, emb in self.entity_embeddings.items():
            score = np.dot(mention_emb, emb) / (
                np.linalg.norm(mention_emb) * np.linalg.norm(emb)
            )
            if score > best_score:
                best_score = score
                best_match = eid

        if best_score >= threshold:
            return best_match
        return None
```

## 9. è‡ªé€‚åº”RAG

### 9.1 è‡ªé€‚åº”æ£€ç´¢ç­–ç•¥

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        è‡ªé€‚åº” RAG å†³ç­–æµç¨‹                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚                         â”‚   ç”¨æˆ·æŸ¥è¯¢    â”‚                               â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                                â”‚                                        â”‚
â”‚                                â–¼                                        â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                    â”‚      æŸ¥è¯¢åˆ†ç±»å™¨        â”‚                           â”‚
â”‚                    â”‚  (åˆ†ææŸ¥è¯¢å¤æ‚åº¦å’Œç±»å‹) â”‚                           â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                                â”‚                                        â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚        â”‚                       â”‚                       â”‚                â”‚
â”‚        â–¼                       â–¼                       â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  ç›´æ¥å›ç­”     â”‚      â”‚  å•æ¬¡æ£€ç´¢     â”‚      â”‚  å¤šè·³æ¨ç†     â”‚          â”‚
â”‚  â”‚  (ç®€å•äº‹å®)   â”‚      â”‚  (æ ‡å‡†RAG)   â”‚      â”‚  (å¤æ‚é—®é¢˜)   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                     â”‚                     â”‚                   â”‚
â”‚         â”‚                     â–¼                     â”‚                   â”‚
â”‚         â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚                   â”‚
â”‚         â”‚           â”‚   ç­–ç•¥é€‰æ‹©å™¨      â”‚           â”‚                   â”‚
â”‚         â”‚           â”‚ â€¢ æ£€ç´¢æºé€‰æ‹©     â”‚           â”‚                   â”‚
â”‚         â”‚           â”‚ â€¢ åˆ†å—ç­–ç•¥é€‰æ‹©   â”‚           â”‚                   â”‚
â”‚         â”‚           â”‚ â€¢ é‡æ’åºç­–ç•¥é€‰æ‹© â”‚           â”‚                   â”‚
â”‚         â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚                   â”‚
â”‚         â”‚                     â”‚                     â”‚                   â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                               â”‚                                         â”‚
â”‚                               â–¼                                         â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚                    â”‚     è‡ªä¿¡åº¦è¯„ä¼°         â”‚                            â”‚
â”‚                    â”‚  (æ˜¯å¦éœ€è¦é‡è¯•/æ”¹è¿›)   â”‚                            â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.2 è‡ªé€‚åº”RAGå®ç°

```python
from enum import Enum
from typing import Callable, Dict, Any

class QueryType(Enum):
    """æŸ¥è¯¢ç±»å‹"""
    SIMPLE_FACT = "simple_fact"      # ç®€å•äº‹å®ï¼Œå¯èƒ½ä¸éœ€è¦æ£€ç´¢
    STANDARD = "standard"             # æ ‡å‡†é—®é¢˜ï¼Œå•æ¬¡æ£€ç´¢
    COMPLEX = "complex"               # å¤æ‚é—®é¢˜ï¼Œéœ€è¦å¤šè·³
    COMPARISON = "comparison"         # æ¯”è¾ƒç±»é—®é¢˜
    AGGREGATION = "aggregation"       # èšåˆç±»é—®é¢˜

class AdaptiveRAG:
    """
    è‡ªé€‚åº”RAGç³»ç»Ÿ
    æ ¹æ®æŸ¥è¯¢ç‰¹å¾è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç­–ç•¥
    """

    def __init__(self,
                 llm,
                 retriever,
                 multi_hop_retriever=None,
                 graph_retriever=None):
        self.llm = llm
        self.retriever = retriever
        self.multi_hop_retriever = multi_hop_retriever
        self.graph_retriever = graph_retriever

        # ç­–ç•¥æ³¨å†Œ
        self.strategies: Dict[QueryType, Callable] = {
            QueryType.SIMPLE_FACT: self._handle_simple,
            QueryType.STANDARD: self._handle_standard,
            QueryType.COMPLEX: self._handle_complex,
            QueryType.COMPARISON: self._handle_comparison,
            QueryType.AGGREGATION: self._handle_aggregation,
        }

    def query(self, question: str) -> Dict[str, Any]:
        """è‡ªé€‚åº”é—®ç­”"""

        # 1. åˆ†ç±»æŸ¥è¯¢
        query_type = self._classify_query(question)

        # 2. é€‰æ‹©ç­–ç•¥å¹¶æ‰§è¡Œ
        strategy = self.strategies.get(query_type, self._handle_standard)
        result = strategy(question)

        # 3. è¯„ä¼°ç»“æœè´¨é‡
        confidence = self._evaluate_confidence(question, result)

        # 4. å¦‚æœä¿¡å¿ƒä¸è¶³ï¼Œå°è¯•å‡çº§ç­–ç•¥
        if confidence < 0.7:
            result = self._retry_with_enhanced_strategy(
                question, query_type, result
            )

        return {
            'answer': result['answer'],
            'query_type': query_type.value,
            'confidence': confidence,
            'sources': result.get('sources', []),
            'strategy_used': result.get('strategy', 'unknown')
        }

    def _classify_query(self, question: str) -> QueryType:
        """åˆ†ç±»æŸ¥è¯¢ç±»å‹"""

        prompt = f"""åˆ†æä»¥ä¸‹é—®é¢˜çš„ç±»å‹ã€‚

é—®é¢˜: {question}

ç±»å‹é€‰é¡¹:
1. simple_fact: ç®€å•äº‹å®é—®é¢˜ï¼ˆå¦‚"ä»€ä¹ˆæ˜¯...çš„é¦–éƒ½"ï¼‰
2. standard: æ ‡å‡†é—®é¢˜ï¼ˆéœ€è¦æ£€ç´¢å•ä¸€æ–‡æ¡£ï¼‰
3. complex: å¤æ‚é—®é¢˜ï¼ˆéœ€è¦ç»¼åˆå¤šä¸ªä¿¡æ¯æºï¼‰
4. comparison: æ¯”è¾ƒç±»é—®é¢˜ï¼ˆéœ€è¦å¯¹æ¯”å¤šä¸ªå®ä½“ï¼‰
5. aggregation: èšåˆç±»é—®é¢˜ï¼ˆéœ€è¦æ±‡æ€»å¤šä¸ªä¿¡æ¯ï¼‰

è¯·åªè¾“å‡ºç±»å‹åç§°:"""

        response = self.llm.predict(prompt).strip().lower()

        type_map = {
            'simple_fact': QueryType.SIMPLE_FACT,
            'standard': QueryType.STANDARD,
            'complex': QueryType.COMPLEX,
            'comparison': QueryType.COMPARISON,
            'aggregation': QueryType.AGGREGATION,
        }

        return type_map.get(response, QueryType.STANDARD)

    def _handle_simple(self, question: str) -> dict:
        """å¤„ç†ç®€å•é—®é¢˜ - å¯èƒ½ä¸éœ€è¦æ£€ç´¢"""

        # å…ˆå°è¯•ç›´æ¥å›ç­”
        prompt = f"""å¦‚æœä½ ç¡®å®šçŸ¥é“ç­”æ¡ˆï¼Œè¯·ç›´æ¥å›ç­”ã€‚å¦‚æœä¸ç¡®å®šï¼Œè¯·å›ç­”"éœ€è¦æ£€ç´¢"ã€‚

é—®é¢˜: {question}

å›ç­”:"""

        response = self.llm.predict(prompt)

        if "éœ€è¦æ£€ç´¢" in response:
            # é™çº§åˆ°æ ‡å‡†æ£€ç´¢
            return self._handle_standard(question)

        return {
            'answer': response,
            'strategy': 'direct_answer',
            'sources': []
        }

    def _handle_standard(self, question: str) -> dict:
        """æ ‡å‡†RAGå¤„ç†"""

        # æ£€ç´¢
        docs = self.retriever.search(question)
        context = "\n\n".join(docs)

        # ç”Ÿæˆ
        prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜:

{context}

é—®é¢˜: {question}

å›ç­”:"""

        answer = self.llm.predict(prompt)

        return {
            'answer': answer,
            'strategy': 'standard_rag',
            'sources': docs
        }

    def _handle_complex(self, question: str) -> dict:
        """å¤„ç†å¤æ‚é—®é¢˜ - ä½¿ç”¨å¤šè·³æ¨ç†"""

        if self.multi_hop_retriever:
            answer, steps = self.multi_hop_retriever.query(question)
            return {
                'answer': answer,
                'strategy': 'multi_hop',
                'sources': [s.observation for s in steps],
                'reasoning_steps': steps
            }

        # é™çº§åˆ°æ ‡å‡†ç­–ç•¥
        return self._handle_standard(question)

    def _handle_comparison(self, question: str) -> dict:
        """å¤„ç†æ¯”è¾ƒç±»é—®é¢˜"""

        # æå–æ¯”è¾ƒå¯¹è±¡
        entities = self._extract_comparison_entities(question)

        # åˆ†åˆ«æ£€ç´¢æ¯ä¸ªå®ä½“çš„ä¿¡æ¯
        all_docs = []
        for entity in entities:
            docs = self.retriever.search(entity)
            all_docs.extend(docs)

        context = "\n\n".join(all_docs)

        prompt = f"""è¯·æ¯”è¾ƒåˆ†æä»¥ä¸‹å®ä½“çš„ä¿¡æ¯ï¼Œå›ç­”é—®é¢˜:

ç›¸å…³ä¿¡æ¯:
{context}

é—®é¢˜: {question}

è¯·ç»“æ„åŒ–åœ°è¿›è¡Œæ¯”è¾ƒåˆ†æ:"""

        answer = self.llm.predict(prompt)

        return {
            'answer': answer,
            'strategy': 'comparison',
            'sources': all_docs,
            'compared_entities': entities
        }

    def _handle_aggregation(self, question: str) -> dict:
        """å¤„ç†èšåˆç±»é—®é¢˜"""

        # æ‰©å¤§æ£€ç´¢èŒƒå›´
        docs = self.retriever.search(question, k=10)

        # æ±‡æ€»ä¿¡æ¯
        context = "\n\n".join(docs)

        prompt = f"""è¿™æ˜¯ä¸€ä¸ªéœ€è¦æ±‡æ€»å¤šæ–¹ä¿¡æ¯çš„é—®é¢˜ã€‚

ç›¸å…³ä¿¡æ¯:
{context}

é—®é¢˜: {question}

è¯·ç»¼åˆæ‰€æœ‰ç›¸å…³ä¿¡æ¯ç»™å‡ºå…¨é¢çš„å›ç­”:"""

        answer = self.llm.predict(prompt)

        return {
            'answer': answer,
            'strategy': 'aggregation',
            'sources': docs
        }

    def _extract_comparison_entities(self, question: str) -> list[str]:
        """æå–æ¯”è¾ƒå®ä½“"""
        prompt = f"""ä»ä»¥ä¸‹é—®é¢˜ä¸­æå–éœ€è¦æ¯”è¾ƒçš„å®ä½“:

é—®é¢˜: {question}

è¯·åˆ—å‡ºå®ä½“ï¼Œç”¨é€—å·åˆ†éš”:"""

        response = self.llm.predict(prompt)
        return [e.strip() for e in response.split(',')]

    def _evaluate_confidence(self, question: str, result: dict) -> float:
        """è¯„ä¼°ç­”æ¡ˆç½®ä¿¡åº¦"""

        answer = result.get('answer', '')
        sources = result.get('sources', [])

        # ç®€å•è¯„ä¼°è§„åˆ™
        score = 0.5

        # æœ‰æ¥æºåŠ åˆ†
        if sources:
            score += 0.2

        # ç­”æ¡ˆé•¿åº¦é€‚ä¸­åŠ åˆ†
        if 50 < len(answer) < 1000:
            score += 0.1

        # ä½¿ç”¨LLMè¯„ä¼°
        prompt = f"""è¯„ä¼°è¿™ä¸ªå›ç­”çš„è´¨é‡ï¼ˆ0-1åˆ†ï¼‰:

é—®é¢˜: {question}
å›ç­”: {answer}

åªè¾“å‡ºåˆ†æ•°:"""

        try:
            llm_score = float(self.llm.predict(prompt).strip())
            score = (score + llm_score) / 2
        except:
            pass

        return min(score, 1.0)

    def _retry_with_enhanced_strategy(self,
                                       question: str,
                                       original_type: QueryType,
                                       original_result: dict) -> dict:
        """ä½¿ç”¨å¢å¼ºç­–ç•¥é‡è¯•"""

        # å‡çº§ç­–ç•¥æ˜ å°„
        upgrade_map = {
            QueryType.SIMPLE_FACT: QueryType.STANDARD,
            QueryType.STANDARD: QueryType.COMPLEX,
            QueryType.COMPLEX: QueryType.AGGREGATION,
        }

        upgraded_type = upgrade_map.get(original_type)

        if upgraded_type:
            strategy = self.strategies.get(upgraded_type)
            if strategy:
                result = strategy(question)
                result['upgraded_from'] = original_type.value
                return result

        return original_result
```

## 10. RAGè¯„ä¼°ä½“ç³»

### 10.1 è¯„ä¼°ç»´åº¦

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RAG è¯„ä¼°æ¡†æ¶                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    æ£€ç´¢è´¨é‡è¯„ä¼°                                  â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚    â”‚
â”‚  â”‚  â”‚   å¬å›ç‡      â”‚ â”‚   ç²¾ç¡®ç‡      â”‚ â”‚   MRR/NDCG   â”‚           â”‚    â”‚
â”‚  â”‚  â”‚  Recall@K    â”‚ â”‚ Precision@K  â”‚ â”‚   æ’åºè´¨é‡    â”‚           â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    ç”Ÿæˆè´¨é‡è¯„ä¼°                                  â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚    â”‚
â”‚  â”‚  â”‚   å¿ å®åº¦      â”‚ â”‚   ç›¸å…³æ€§      â”‚ â”‚   å®Œæ•´æ€§      â”‚           â”‚    â”‚
â”‚  â”‚  â”‚ Faithfulness â”‚ â”‚  Relevance   â”‚ â”‚ Completeness â”‚           â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    ç«¯åˆ°ç«¯è¯„ä¼°                                    â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚    â”‚
â”‚  â”‚  â”‚   ç­”æ¡ˆæ­£ç¡®æ€§   â”‚ â”‚   ç”¨æˆ·æ»¡æ„åº¦   â”‚ â”‚   å»¶è¿Ÿ/æˆæœ¬   â”‚           â”‚    â”‚
â”‚  â”‚  â”‚  Correctness â”‚ â”‚ User Rating  â”‚ â”‚   Latency    â”‚           â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 10.2 è¯„ä¼°å®ç°

```python
from dataclasses import dataclass
from typing import List, Optional
import numpy as np

@dataclass
class RAGEvalResult:
    """RAGè¯„ä¼°ç»“æœ"""
    # æ£€ç´¢æŒ‡æ ‡
    retrieval_precision: float
    retrieval_recall: float
    retrieval_mrr: float

    # ç”ŸæˆæŒ‡æ ‡
    faithfulness: float
    answer_relevance: float
    context_relevance: float

    # ç«¯åˆ°ç«¯æŒ‡æ ‡
    answer_correctness: float
    latency_ms: float

class RAGEvaluator:
    """RAGç³»ç»Ÿè¯„ä¼°å™¨"""

    def __init__(self, llm):
        self.llm = llm

    def evaluate(self,
                 question: str,
                 answer: str,
                 contexts: List[str],
                 ground_truth: Optional[str] = None,
                 relevant_docs: Optional[List[str]] = None) -> RAGEvalResult:
        """å…¨é¢è¯„ä¼°RAGç³»ç»Ÿ"""

        # æ£€ç´¢è¯„ä¼°
        if relevant_docs:
            precision = self._calc_precision(contexts, relevant_docs)
            recall = self._calc_recall(contexts, relevant_docs)
            mrr = self._calc_mrr(contexts, relevant_docs)
        else:
            precision = recall = mrr = None

        # ç”Ÿæˆè¯„ä¼°
        faithfulness = self._eval_faithfulness(answer, contexts)
        answer_relevance = self._eval_answer_relevance(question, answer)
        context_relevance = self._eval_context_relevance(question, contexts)

        # ç­”æ¡ˆæ­£ç¡®æ€§
        if ground_truth:
            correctness = self._eval_correctness(answer, ground_truth)
        else:
            correctness = None

        return RAGEvalResult(
            retrieval_precision=precision,
            retrieval_recall=recall,
            retrieval_mrr=mrr,
            faithfulness=faithfulness,
            answer_relevance=answer_relevance,
            context_relevance=context_relevance,
            answer_correctness=correctness,
            latency_ms=0  # éœ€è¦å¤–éƒ¨æµ‹é‡
        )

    def _calc_precision(self, retrieved: List[str],
                        relevant: List[str]) -> float:
        """è®¡ç®—ç²¾ç¡®ç‡"""
        if not retrieved:
            return 0.0

        relevant_set = set(relevant)
        hits = sum(1 for doc in retrieved if doc in relevant_set)
        return hits / len(retrieved)

    def _calc_recall(self, retrieved: List[str],
                     relevant: List[str]) -> float:
        """è®¡ç®—å¬å›ç‡"""
        if not relevant:
            return 0.0

        retrieved_set = set(retrieved)
        hits = sum(1 for doc in relevant if doc in retrieved_set)
        return hits / len(relevant)

    def _calc_mrr(self, retrieved: List[str],
                  relevant: List[str]) -> float:
        """è®¡ç®—Mean Reciprocal Rank"""
        relevant_set = set(relevant)

        for i, doc in enumerate(retrieved):
            if doc in relevant_set:
                return 1.0 / (i + 1)
        return 0.0

    def _eval_faithfulness(self, answer: str, contexts: List[str]) -> float:
        """
        è¯„ä¼°å¿ å®åº¦
        ç­”æ¡ˆæ˜¯å¦èƒ½ä»ä¸Šä¸‹æ–‡ä¸­æ¨å¯¼å‡ºæ¥
        """
        context = "\n\n".join(contexts)

        prompt = f"""è¯„ä¼°å›ç­”æ˜¯å¦å¿ å®äºç»™å®šçš„ä¸Šä¸‹æ–‡ã€‚
å¿ å®æ„å‘³ç€å›ç­”ä¸­çš„æ‰€æœ‰ä¿¡æ¯éƒ½å¯ä»¥ä»ä¸Šä¸‹æ–‡ä¸­æ‰¾åˆ°æˆ–æ¨å¯¼å‡ºæ¥ã€‚

ä¸Šä¸‹æ–‡:
{context}

å›ç­”: {answer}

è¯„åˆ†æ ‡å‡†:
1-3: åŒ…å«ä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰çš„ä¿¡æ¯ï¼ˆå¹»è§‰ï¼‰
4-6: éƒ¨åˆ†ä¿¡æ¯å¯ä»¥è¿½æº¯åˆ°ä¸Šä¸‹æ–‡
7-10: æ‰€æœ‰ä¿¡æ¯éƒ½å¯ä»¥ä»ä¸Šä¸‹æ–‡ä¸­æ‰¾åˆ°

åªè¾“å‡ºåˆ†æ•°(1-10):"""

        try:
            score = float(self.llm.predict(prompt).strip())
            return score / 10
        except:
            return 0.5

    def _eval_answer_relevance(self, question: str, answer: str) -> float:
        """è¯„ä¼°ç­”æ¡ˆç›¸å…³æ€§"""

        prompt = f"""è¯„ä¼°å›ç­”ä¸é—®é¢˜çš„ç›¸å…³æ€§ã€‚

é—®é¢˜: {question}
å›ç­”: {answer}

è¯„åˆ†æ ‡å‡†:
1-3: å›ç­”ä¸é—®é¢˜æ— å…³
4-6: éƒ¨åˆ†å›ç­”äº†é—®é¢˜
7-10: å®Œå…¨å›ç­”äº†é—®é¢˜

åªè¾“å‡ºåˆ†æ•°(1-10):"""

        try:
            score = float(self.llm.predict(prompt).strip())
            return score / 10
        except:
            return 0.5

    def _eval_context_relevance(self, question: str,
                                 contexts: List[str]) -> float:
        """è¯„ä¼°ä¸Šä¸‹æ–‡ç›¸å…³æ€§"""
        scores = []

        for ctx in contexts:
            prompt = f"""è¯„ä¼°è¿™æ®µä¸Šä¸‹æ–‡ä¸é—®é¢˜çš„ç›¸å…³æ€§ã€‚

é—®é¢˜: {question}
ä¸Šä¸‹æ–‡: {ctx[:500]}

åªè¾“å‡ºåˆ†æ•°(1-10):"""

            try:
                score = float(self.llm.predict(prompt).strip())
                scores.append(score / 10)
            except:
                scores.append(0.5)

        return np.mean(scores) if scores else 0.5

    def _eval_correctness(self, answer: str, ground_truth: str) -> float:
        """è¯„ä¼°ç­”æ¡ˆæ­£ç¡®æ€§"""

        prompt = f"""æ¯”è¾ƒç”Ÿæˆçš„ç­”æ¡ˆä¸æ ‡å‡†ç­”æ¡ˆã€‚

æ ‡å‡†ç­”æ¡ˆ: {ground_truth}
ç”Ÿæˆç­”æ¡ˆ: {answer}

è¯„åˆ†æ ‡å‡†:
1-3: ç­”æ¡ˆé”™è¯¯æˆ–å®Œå…¨ä¸åŒ
4-6: éƒ¨åˆ†æ­£ç¡®
7-10: å®Œå…¨æ­£ç¡®ï¼ˆå¯ä»¥è¡¨è¿°ä¸åŒï¼‰

åªè¾“å‡ºåˆ†æ•°(1-10):"""

        try:
            score = float(self.llm.predict(prompt).strip())
            return score / 10
        except:
            return 0.5


class RAGBenchmark:
    """RAGåŸºå‡†æµ‹è¯•"""

    def __init__(self, rag_system, evaluator: RAGEvaluator):
        self.rag = rag_system
        self.evaluator = evaluator

    def run_benchmark(self, test_cases: List[dict]) -> dict:
        """è¿è¡ŒåŸºå‡†æµ‹è¯•"""

        results = []

        for case in test_cases:
            question = case['question']
            ground_truth = case.get('answer')
            relevant_docs = case.get('relevant_docs', [])

            # è¿è¡ŒRAG
            import time
            start = time.time()
            rag_result = self.rag.query(question)
            latency = (time.time() - start) * 1000

            # è¯„ä¼°
            eval_result = self.evaluator.evaluate(
                question=question,
                answer=rag_result['answer'],
                contexts=rag_result.get('sources', []),
                ground_truth=ground_truth,
                relevant_docs=relevant_docs
            )
            eval_result.latency_ms = latency

            results.append(eval_result)

        # æ±‡æ€»ç»Ÿè®¡
        return self._aggregate_results(results)

    def _aggregate_results(self, results: List[RAGEvalResult]) -> dict:
        """æ±‡æ€»è¯„ä¼°ç»“æœ"""

        def safe_mean(values):
            valid = [v for v in values if v is not None]
            return np.mean(valid) if valid else None

        return {
            'retrieval': {
                'precision': safe_mean([r.retrieval_precision for r in results]),
                'recall': safe_mean([r.retrieval_recall for r in results]),
                'mrr': safe_mean([r.retrieval_mrr for r in results]),
            },
            'generation': {
                'faithfulness': safe_mean([r.faithfulness for r in results]),
                'answer_relevance': safe_mean([r.answer_relevance for r in results]),
                'context_relevance': safe_mean([r.context_relevance for r in results]),
            },
            'end_to_end': {
                'correctness': safe_mean([r.answer_correctness for r in results]),
                'avg_latency_ms': safe_mean([r.latency_ms for r in results]),
            },
            'num_samples': len(results)
        }
```

## 11. ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

### 11.1 ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ç”Ÿäº§çº§ RAG ç³»ç»Ÿæ¶æ„                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚    â”‚                          ç½‘å…³å±‚                                  â”‚ â”‚
â”‚    â”‚  [API Gateway] â”€â”€â”€ [Rate Limiter] â”€â”€â”€ [Auth] â”€â”€â”€ [Load Balancer]â”‚ â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                                    â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚    â”‚                         æœåŠ¡å±‚                                   â”‚ â”‚
â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚ â”‚
â”‚    â”‚  â”‚  Query   â”‚  â”‚Retrieval â”‚  â”‚ Rerank   â”‚  â”‚Generationâ”‚        â”‚ â”‚
â”‚    â”‚  â”‚ Service  â”‚  â”‚ Service  â”‚  â”‚ Service  â”‚  â”‚ Service  â”‚        â”‚ â”‚
â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚ â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                                    â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚    â”‚                        æ•°æ®å±‚                                    â”‚ â”‚
â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚ â”‚
â”‚    â”‚  â”‚ Vector   â”‚  â”‚  Graph   â”‚  â”‚  Cache   â”‚  â”‚ Document â”‚        â”‚ â”‚
â”‚    â”‚  â”‚   DB     â”‚  â”‚    DB    â”‚  â”‚ (Redis)  â”‚  â”‚  Store   â”‚        â”‚ â”‚
â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚ â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                                    â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚    â”‚                       ç›‘æ§å±‚                                     â”‚ â”‚
â”‚    â”‚  [Metrics] â”€â”€â”€ [Logging] â”€â”€â”€ [Tracing] â”€â”€â”€ [Alerting]          â”‚ â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 11.2 ä¼˜åŒ–ç­–ç•¥

```python
import asyncio
from functools import lru_cache
import hashlib
from typing import List, Dict, Any
import redis

class ProductionRAG:
    """ç”Ÿäº§çº§RAGç³»ç»Ÿ"""

    def __init__(self, config: dict):
        self.config = config
        self.cache = redis.Redis(
            host=config.get('redis_host', 'localhost'),
            port=config.get('redis_port', 6379)
        )
        self.cache_ttl = config.get('cache_ttl', 3600)

        # åˆå§‹åŒ–ç»„ä»¶
        self._init_components()

    def _init_components(self):
        """åˆå§‹åŒ–å„ç»„ä»¶"""
        # å‘é‡æ•°æ®åº“è¿æ¥æ± 
        # é‡æ’åºæ¨¡å‹é¢„åŠ è½½
        # LLMå®¢æˆ·ç«¯åˆå§‹åŒ–
        pass

    async def query(self,
                    question: str,
                    user_id: str = None,
                    session_id: str = None) -> Dict[str, Any]:
        """
        ç”Ÿäº§çº§æŸ¥è¯¢æ¥å£

        Features:
        - ç¼“å­˜å±‚
        - å¼‚æ­¥å¤„ç†
        - é”™è¯¯å¤„ç†
        - ç›‘æ§åŸ‹ç‚¹
        """

        # 1. æ£€æŸ¥ç¼“å­˜
        cache_key = self._get_cache_key(question)
        cached = self._get_from_cache(cache_key)
        if cached:
            return {**cached, 'cached': True}

        try:
            # 2. å¼‚æ­¥æ‰§è¡Œæ£€ç´¢
            retrieval_task = asyncio.create_task(
                self._async_retrieve(question)
            )

            # 3. å¹¶è¡Œæ‰§è¡ŒæŸ¥è¯¢åˆ†æ
            analysis_task = asyncio.create_task(
                self._analyze_query(question)
            )

            # ç­‰å¾…ç»“æœ
            docs, analysis = await asyncio.gather(
                retrieval_task,
                analysis_task
            )

            # 4. æ ¹æ®åˆ†æé€‰æ‹©ç­–ç•¥
            if analysis['needs_rerank']:
                docs = await self._async_rerank(question, docs)

            # 5. ç”Ÿæˆç­”æ¡ˆ
            answer = await self._async_generate(question, docs)

            result = {
                'answer': answer,
                'sources': docs[:3],  # é™åˆ¶è¿”å›çš„æº
                'query_type': analysis['type'],
                'cached': False
            }

            # 6. å­˜å…¥ç¼“å­˜
            self._set_cache(cache_key, result)

            # 7. è®°å½•ç›‘æ§æŒ‡æ ‡
            self._record_metrics(question, result)

            return result

        except Exception as e:
            # é”™è¯¯å¤„ç†
            self._record_error(e, question)
            return {
                'answer': "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ã€‚è¯·ç¨åé‡è¯•ã€‚",
                'error': str(e),
                'cached': False
            }

    def _get_cache_key(self, question: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return f"rag:query:{hashlib.md5(question.encode()).hexdigest()}"

    def _get_from_cache(self, key: str) -> dict:
        """ä»ç¼“å­˜è·å–"""
        try:
            import json
            cached = self.cache.get(key)
            if cached:
                return json.loads(cached)
        except:
            pass
        return None

    def _set_cache(self, key: str, value: dict):
        """è®¾ç½®ç¼“å­˜"""
        try:
            import json
            self.cache.setex(
                key,
                self.cache_ttl,
                json.dumps(value, ensure_ascii=False)
            )
        except:
            pass

    async def _async_retrieve(self, question: str) -> List[str]:
        """å¼‚æ­¥æ£€ç´¢"""
        # å®ç°å¼‚æ­¥æ£€ç´¢é€»è¾‘
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            None,
            self._sync_retrieve,
            question
        )

    def _sync_retrieve(self, question: str) -> List[str]:
        """åŒæ­¥æ£€ç´¢ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰"""
        # å®é™…çš„æ£€ç´¢é€»è¾‘
        return []

    async def _analyze_query(self, question: str) -> dict:
        """åˆ†ææŸ¥è¯¢"""
        return {
            'type': 'standard',
            'needs_rerank': True,
            'estimated_complexity': 'medium'
        }

    async def _async_rerank(self, question: str,
                            docs: List[str]) -> List[str]:
        """å¼‚æ­¥é‡æ’åº"""
        return docs

    async def _async_generate(self, question: str,
                              docs: List[str]) -> str:
        """å¼‚æ­¥ç”Ÿæˆ"""
        return "ç”Ÿæˆçš„ç­”æ¡ˆ"

    def _record_metrics(self, question: str, result: dict):
        """è®°å½•ç›‘æ§æŒ‡æ ‡"""
        # å‘é€åˆ°ç›‘æ§ç³»ç»Ÿ
        pass

    def _record_error(self, error: Exception, question: str):
        """è®°å½•é”™è¯¯"""
        # å‘é€åˆ°é”™è¯¯è¿½è¸ªç³»ç»Ÿ
        pass


class RAGOptimizer:
    """RAGç³»ç»Ÿä¼˜åŒ–å™¨"""

    @staticmethod
    def optimize_embedding_calls(texts: List[str],
                                  embeddings_model,
                                  batch_size: int = 32) -> List[List[float]]:
        """æ‰¹é‡ä¼˜åŒ–åµŒå…¥è°ƒç”¨"""
        all_embeddings = []

        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            batch_embeddings = embeddings_model.embed_documents(batch)
            all_embeddings.extend(batch_embeddings)

        return all_embeddings

    @staticmethod
    def create_index_with_metadata(documents: List[dict],
                                    vectorstore_class,
                                    embeddings_model) -> any:
        """
        åˆ›å»ºå¸¦å…ƒæ•°æ®çš„ç´¢å¼•
        æ”¯æŒæ›´ç²¾ç»†çš„è¿‡æ»¤
        """
        from langchain.schema import Document

        docs = [
            Document(
                page_content=d['content'],
                metadata={
                    'source': d.get('source', ''),
                    'category': d.get('category', ''),
                    'timestamp': d.get('timestamp', ''),
                    'author': d.get('author', ''),
                }
            )
            for d in documents
        ]

        return vectorstore_class.from_documents(docs, embeddings_model)

    @staticmethod
    def setup_fallback_strategy(primary_retriever,
                                 secondary_retriever,
                                 threshold: float = 0.5):
        """è®¾ç½®æ£€ç´¢å¤±è´¥å›é€€ç­–ç•¥"""

        def retrieve_with_fallback(query: str, k: int = 4):
            # å°è¯•ä¸»æ£€ç´¢å™¨
            results = primary_retriever.search(query, k=k)

            # æ£€æŸ¥ç»“æœè´¨é‡
            if not results or len(results) < k // 2:
                # å›é€€åˆ°å¤‡ç”¨æ£€ç´¢å™¨
                backup_results = secondary_retriever.search(query, k=k)
                results = results + backup_results

            return results[:k]

        return retrieve_with_fallback
```

### 11.3 æ€§èƒ½ä¼˜åŒ–æ¸…å•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ€§èƒ½ä¼˜åŒ–æ£€æŸ¥æ¸…å• â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ âœ… ç´¢å¼•ä¼˜åŒ– â”‚
â”‚ â–¡ ä½¿ç”¨åˆé€‚çš„å‘é‡ç´¢å¼•ç±»å‹ (HNSW, IVF, etc.) â”‚
â”‚ â–¡ è°ƒæ•´ç´¢å¼•å‚æ•° (ef_construction, M, nlist) â”‚
â”‚ â–¡ å®šæœŸé‡å»ºç´¢å¼•ä¼˜åŒ–æ€§èƒ½ â”‚
â”‚ â”‚
â”‚ âœ… ç¼“å­˜ç­–ç•¥ â”‚
â”‚ â–¡ å®ç°æŸ¥è¯¢ç»“æœç¼“å­˜ â”‚
â”‚ â–¡ åµŒå…¥å‘é‡ç¼“å­˜ â”‚
â”‚ â–¡ LLMå“åº”ç¼“å­˜ï¼ˆç›¸ä¼¼æŸ¥è¯¢ï¼‰ â”‚
â”‚ â”‚
â”‚ âœ… æ‰¹å¤„ç†ä¼˜åŒ– â”‚
â”‚ â–¡ æ‰¹é‡åµŒå…¥è®¡ç®— â”‚
â”‚ â–¡ æ‰¹é‡LLMè°ƒç”¨ â”‚
â”‚ â–¡ å¼‚æ­¥å¹¶è¡Œå¤„ç† â”‚
â”‚ â”‚
â”‚ âœ… æ¨¡å‹ä¼˜åŒ– â”‚
â”‚ â–¡ ä½¿ç”¨é‡åŒ–æ¨¡å‹å‡å°‘å†…å­˜ â”‚
â”‚ â–¡ é€‰æ‹©åˆé€‚å¤§å°çš„åµŒå…¥æ¨¡å‹ â”‚
â”‚ â–¡ è€ƒè™‘ä½¿ç”¨æœ¬åœ°æ¨¡å‹ â”‚
â”‚ â”‚
â”‚ âœ… èµ„æºç®¡ç† â”‚
â”‚ â–¡ è¿æ¥æ± ç®¡ç† â”‚
â”‚ â–¡ å†…å­˜ä½¿ç”¨ç›‘æ§ â”‚
â”‚ â–¡ GPUèµ„æºä¼˜åŒ– â”‚
â”‚ â”‚
â”‚ âœ… ç›‘æ§å‘Šè­¦ â”‚
â”‚ â–¡ å»¶è¿Ÿç›‘æ§ (P50, P95, P99) â”‚
â”‚ â–¡ å‡†ç¡®ç‡ç›‘æ§ â”‚
â”‚ â–¡ é”™è¯¯ç‡ç›‘æ§ â”‚
â”‚ â–¡ æˆæœ¬ç›‘æ§ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“š æ€»ç»“
æ ¸å¿ƒæŠ€æœ¯æ ˆ
æŠ€æœ¯é¢†åŸŸ å…³é”®æŠ€æœ¯ æ¨èå·¥å…·
åˆ†å— è¯­ä¹‰åˆ†å—ã€çˆ¶å­åˆ†å— LangChain, LlamaIndex
æ£€ç´¢ æ··åˆæ£€ç´¢ã€å¤šå‘é‡æ£€ç´¢ FAISS, Milvus, Pinecone
é‡æ’åº Cross-Encoder, ColBERT sentence-transformers
æŸ¥è¯¢ä¼˜åŒ– HyDE, Multi-Query LangChain
è¯„ä¼° RAGAS, TruLens RAGAS, DeepEval
çŸ¥è¯†å›¾è°± Graph RAG Neo4j, LlamaIndex

## å­¦ä¹ è·¯å¾„

```
ç¬¬ä¸€é˜¶æ®µ: åŸºç¡€æŒæ¡
â”œâ”€â”€ ç†è§£ RAG åŸºæœ¬åŸç†
â”œâ”€â”€ å®ç°ç®€å•çš„ RAG ç³»ç»Ÿ
â””â”€â”€ å­¦ä¹ å‘é‡æ•°æ®åº“ä½¿ç”¨

ç¬¬äºŒé˜¶æ®µ: è¿›é˜¶æå‡
â”œâ”€â”€ å®ç°é«˜çº§åˆ†å—ç­–ç•¥
â”œâ”€â”€ æŒæ¡æ··åˆæ£€ç´¢
â”œâ”€â”€ å®ç°é‡æ’åºæœºåˆ¶
â””â”€â”€ å­¦ä¹ æŸ¥è¯¢ä¼˜åŒ–æŠ€æœ¯

ç¬¬ä¸‰é˜¶æ®µ: é«˜çº§åº”ç”¨
â”œâ”€â”€ å¤šè·³æ¨ç† RAG
â”œâ”€â”€ çŸ¥è¯†å›¾è°±å¢å¼º
â”œâ”€â”€ è‡ªé€‚åº” RAG ç³»ç»Ÿ
â””â”€â”€ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

ç¬¬å››é˜¶æ®µ: ä¸“å®¶çº§
â”œâ”€â”€ è‡ªå®šä¹‰è¯„ä¼°ä½“ç³»
â”œâ”€â”€ æ€§èƒ½ä¼˜åŒ–è°ƒä¼˜
â”œâ”€â”€ ç‰¹å®šé¢†åŸŸé€‚é…
â””â”€â”€ å‰æ²¿æŠ€æœ¯è·Ÿè¸ª
```
