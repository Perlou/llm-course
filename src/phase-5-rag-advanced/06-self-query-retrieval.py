"""
è‡ªæŸ¥è¯¢æ£€ç´¢
==========

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£è‡ªæŸ¥è¯¢æ£€ç´¢çš„åŸç†
    2. æŒæ¡ LangChain SelfQueryRetriever
    3. å­¦ä¼šç»“æ„åŒ–å…ƒæ•°æ®è¿‡æ»¤

æ ¸å¿ƒæ¦‚å¿µï¼š
    - Self-Queryï¼šLLM è‡ªåŠ¨è§£ææŸ¥è¯¢æ„å›¾
    - å…ƒæ•°æ®è¿‡æ»¤ï¼šåŸºäºå±æ€§çš„ç²¾ç¡®ç­›é€‰
    - ç»“æ„åŒ–æŸ¥è¯¢ï¼šè¯­ä¹‰ + è¿‡æ»¤

å‰ç½®çŸ¥è¯†ï¼š
    - 05-multi-query-retrieval.py

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install langchain langchain-google-genai chromadb lark python-dotenv
"""

import os
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šè‡ªæŸ¥è¯¢æ£€ç´¢æ¦‚å¿µ ====================


def self_query_concept():
    """è‡ªæŸ¥è¯¢æ£€ç´¢æ¦‚å¿µ"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šè‡ªæŸ¥è¯¢æ£€ç´¢æ¦‚å¿µ")
    print("=" * 60)

    print("""
    è‡ªæŸ¥è¯¢æ£€ç´¢çš„ä¼˜åŠ¿ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    ä¼ ç»Ÿæ£€ç´¢åªèƒ½åšè¯­ä¹‰åŒ¹é…
    ä½†ç”¨æˆ·çš„æŸ¥è¯¢å¾€å¾€åŒ…å«è¿‡æ»¤æ¡ä»¶
    
    ç¤ºä¾‹æŸ¥è¯¢ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ã€Œæ‰¾ä¸€ç¯‡ 2023 å¹´å‘å¸ƒçš„å…³äº RAG çš„è®ºæ–‡ã€
    
    ä¼ ç»Ÿæ£€ç´¢ï¼šåªèƒ½è¯­ä¹‰åŒ¹é… "RAG"
    è‡ªæŸ¥è¯¢ï¼šåŒæ—¶è¿‡æ»¤ å¹´ä»½=2023 AND ç±»å‹=è®ºæ–‡
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ç”¨æˆ·æŸ¥è¯¢: "2023å¹´å…³äºRAGçš„è®ºæ–‡"                     â”‚
    â”‚                     â”‚                               â”‚
    â”‚                     â–¼                               â”‚
    â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
    â”‚          â”‚   LLM æ„å›¾è§£æ     â”‚                     â”‚
    â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
    â”‚                     â”‚                               â”‚
    â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
    â”‚         â–¼                       â–¼                   â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
    â”‚  â”‚  è¯­ä¹‰æŸ¥è¯¢    â”‚        â”‚  å…ƒæ•°æ®è¿‡æ»¤  â”‚           â”‚
    â”‚  â”‚  "RAG"      â”‚        â”‚  year=2023  â”‚           â”‚
    â”‚  â”‚             â”‚        â”‚  type=paper â”‚           â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜           â”‚
    â”‚         â”‚                      â”‚                   â”‚
    â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
    â”‚                    â–¼                               â”‚
    â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
    â”‚            â”‚ è”åˆæ£€ç´¢      â”‚                        â”‚
    â”‚            â”‚ å‘é‡ + è¿‡æ»¤   â”‚                        â”‚
    â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
    â”‚                                                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šå…ƒæ•°æ®è®¾è®¡ ====================


def metadata_design():
    """å…ƒæ•°æ®è®¾è®¡"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šå…ƒæ•°æ®è®¾è®¡")
    print("=" * 60)

    print("""
    å¸¸è§çš„å…ƒæ•°æ®å­—æ®µï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    æ–‡æ¡£ç±»å‹å…ƒæ•°æ®ï¼š
    - source: æ¥æº (blog, paper, doc)
    - type: ç±»å‹ (tutorial, reference, news)
    - author: ä½œè€…
    - date/year: å‘å¸ƒæ—¥æœŸ
    
    å†…å®¹ç›¸å…³å…ƒæ•°æ®ï¼š
    - topic: ä¸»é¢˜æ ‡ç­¾
    - language: è¯­è¨€
    - difficulty: éš¾åº¦çº§åˆ«
    - rating: è¯„åˆ†
    
    æŠ€æœ¯å…ƒæ•°æ®ï¼š
    - word_count: å­—æ•°
    - page_number: é¡µç 
    - chunk_id: åˆ†å—ID
    """)

    from langchain_core.documents import Document

    # ç¤ºä¾‹ï¼šå¸¦å…ƒæ•°æ®çš„æ–‡æ¡£
    docs = [
        Document(
            page_content="RAG æŠ€æœ¯ç»¼è¿°ï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆçš„åŸç†ä¸åº”ç”¨",
            metadata={
                "source": "paper",
                "year": 2023,
                "topic": "RAG",
                "language": "zh",
            },
        ),
        Document(
            page_content="LangChain å…¥é—¨æ•™ç¨‹ï¼šæ„å»ºä½ çš„ç¬¬ä¸€ä¸ª AI åº”ç”¨",
            metadata={
                "source": "tutorial",
                "year": 2024,
                "topic": "LangChain",
                "difficulty": "beginner",
            },
        ),
    ]

    print("ğŸ“Œ ç¤ºä¾‹æ–‡æ¡£ï¼š")
    for doc in docs:
        print(f"  å†…å®¹: {doc.page_content[:30]}...")
        print(f"  å…ƒæ•°æ®: {doc.metadata}")
        print()


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šLangChain SelfQueryRetriever ====================


def langchain_self_query():
    """LangChain SelfQueryRetriever"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šLangChain SelfQueryRetriever")
    print("=" * 60)

    try:
        from langchain_classic.chains.query_constructor.base import AttributeInfo
        from langchain_classic.retrievers.self_query.base import SelfQueryRetriever
        from langchain_google_genai import (
            ChatGoogleGenerativeAI,
            GoogleGenerativeAIEmbeddings,
        )
        from langchain_chroma import Chroma
        from langchain_core.documents import Document

        # æ–‡æ¡£å…ƒæ•°æ®æè¿°
        metadata_field_info = [
            AttributeInfo(
                name="category",
                description="æ–‡æ¡£ç±»åˆ«ï¼šæ•™ç¨‹ã€APIæ–‡æ¡£ã€åšå®¢",
                type="string",
            ),
            AttributeInfo(
                name="difficulty",
                description="éš¾åº¦çº§åˆ«ï¼šåˆçº§ã€ä¸­çº§ã€é«˜çº§",
                type="string",
            ),
            AttributeInfo(name="year", description="å‘å¸ƒå¹´ä»½", type="integer"),
        ]

        # å‡†å¤‡æ–‡æ¡£
        docs = [
            Document(
                page_content="Python åŸºç¡€è¯­æ³•æ•™ç¨‹",
                metadata={"category": "æ•™ç¨‹", "difficulty": "åˆçº§", "year": 2023},
            ),
            Document(
                page_content="æœºå™¨å­¦ä¹ ç®—æ³•è¯¦è§£",
                metadata={"category": "æ•™ç¨‹", "difficulty": "ä¸­çº§", "year": 2024},
            ),
            Document(
                page_content="FastAPI å®˜æ–¹æ–‡æ¡£",
                metadata={"category": "APIæ–‡æ¡£", "difficulty": "ä¸­çº§", "year": 2024},
            ),
        ]

        # åˆ›å»ºå‘é‡å­˜å‚¨
        embeddings = GoogleGenerativeAIEmbeddings(model="gemini-embedding-001")
        vectorstore = Chroma.from_documents(docs, embeddings)

        # åˆ›å»º SelfQueryRetriever
        llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)
        retriever = SelfQueryRetriever.from_llm(
            llm=llm,
            vectorstore=vectorstore,
            document_contents="æŠ€æœ¯æ–‡æ¡£å…³äº AI å’Œ LLM çš„å†…å®¹",
            metadata_field_info=metadata_field_info,
        )

        # æµ‹è¯•æŸ¥è¯¢
        queries = [
            "2023å¹´çš„ RAG è®ºæ–‡",
            "å…³äºå‘é‡æ•°æ®åº“çš„æ•™ç¨‹",
            "2024å¹´å‘å¸ƒçš„å†…å®¹",
        ]

        for query in queries:
            results = retriever.invoke(query)
            print(f"\nğŸ“Œ æŸ¥è¯¢: '{query}'")
            for doc in results:
                print(f"  - {doc.page_content[:40]}...")
                print(f"    å…ƒæ•°æ®: {doc.metadata}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        print("â„¹ï¸ éœ€è¦å®‰è£…: pip install lark")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šè‡ªå®šä¹‰è¿‡æ»¤å™¨ ====================


def custom_filter():
    """è‡ªå®šä¹‰è¿‡æ»¤å™¨"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šè‡ªå®šä¹‰è¿‡æ»¤å™¨")
    print("=" * 60)

    print("""
    Chroma è¿‡æ»¤å™¨è¯­æ³•ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    å•æ¡ä»¶è¿‡æ»¤ï¼š
    {"field": {"$eq": value}}     # ç­‰äº
    {"field": {"$ne": value}}     # ä¸ç­‰äº
    {"field": {"$gt": value}}     # å¤§äº
    {"field": {"$lt": value}}     # å°äº
    
    å¤šæ¡ä»¶ç»„åˆï¼š
    {"$and": [æ¡ä»¶1, æ¡ä»¶2]}
    {"$or": [æ¡ä»¶1, æ¡ä»¶2]}
    """)

    try:
        from langchain_google_genai import GoogleGenerativeAIEmbeddings
        from langchain_chroma import Chroma
        from langchain_core.documents import Document

        docs = [
            Document(
                page_content="Python åŸºç¡€æ•™ç¨‹", metadata={"level": 1, "lang": "zh"}
            ),
            Document(
                page_content="Python é«˜çº§ç‰¹æ€§", metadata={"level": 3, "lang": "zh"}
            ),
            Document(
                page_content="Python Advanced", metadata={"level": 3, "lang": "en"}
            ),
        ]

        embeddings = GoogleGenerativeAIEmbeddings(model="gemini-embedding-001")
        vectorstore = Chroma.from_documents(docs, embeddings)

        # å¸¦è¿‡æ»¤çš„æ£€ç´¢
        retriever = vectorstore.as_retriever(
            search_kwargs={
                "k": 2,
                "filter": {"level": {"$gt": 1}},  # level > 1
            }
        )

        results = retriever.invoke("Python")

        print("ğŸ“Œ è¿‡æ»¤æ¡ä»¶: level > 1")
        print("\næ£€ç´¢ç»“æœï¼š")
        for doc in results:
            print(f"  - {doc.page_content}")
            print(f"    å…ƒæ•°æ®: {doc.metadata}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šæŸ¥è¯¢è§£æå®ç° ====================


def query_parsing():
    """æŸ¥è¯¢è§£æå®ç°"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šæŸ¥è¯¢è§£æå®ç°")
    print("=" * 60)

    code_example = '''
class QueryParser:
    """æŸ¥è¯¢è§£æå™¨"""
    
    def __init__(self, llm, field_info):
        self.llm = llm
        self.field_info = field_info
    
    def parse(self, query: str) -> dict:
        """è§£ææŸ¥è¯¢ä¸ºç»“æ„åŒ–æ ¼å¼"""
        
        prompt = f"""
åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œæå–ï¼š
1. è¯­ä¹‰æŸ¥è¯¢éƒ¨åˆ†ï¼ˆç”¨äºå‘é‡æ£€ç´¢ï¼‰
2. è¿‡æ»¤æ¡ä»¶ï¼ˆåŸºäºå…ƒæ•°æ®å­—æ®µï¼‰

å¯ç”¨å­—æ®µ: {self.field_info}

ç”¨æˆ·æŸ¥è¯¢: {query}

è¾“å‡º JSON æ ¼å¼:
{{
  "semantic_query": "...",
  "filters": {{
    "field1": "value1",
    ...
  }}
}}
"""
        response = self.llm.predict(prompt)
        return json.loads(response)
    
    def search(self, query: str, vectorstore):
        parsed = self.parse(query)
        
        return vectorstore.similarity_search(
            parsed["semantic_query"],
            filter=parsed["filters"]
        )
'''
    print("ğŸ“Œ æŸ¥è¯¢è§£æå™¨ç¤ºä¾‹ï¼š")
    print(code_example)


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šè®¾è®¡å…ƒæ•°æ®
        ä¸ºä½ çš„æ–‡æ¡£è®¾è®¡åˆé€‚çš„å…ƒæ•°æ®ç»“æ„ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        # æŠ€æœ¯æ–‡æ¡£å…ƒæ•°æ®è®¾è®¡
        tech_doc_metadata = {
            "title": str,      # æ–‡æ¡£æ ‡é¢˜
            "author": str,     # ä½œè€…
            "date": str,       # å‘å¸ƒæ—¥æœŸ (YYYY-MM-DD)
            "category": str,   # åˆ†ç±»ï¼štutorial, reference, guide
            "difficulty": str, # éš¾åº¦ï¼šbeginner, intermediate, advanced
            "language": str,   # ç¼–ç¨‹è¯­è¨€
            "version": str,    # ç‰ˆæœ¬å·
            "tags": list,      # æ ‡ç­¾åˆ—è¡¨
        }

        # å•†å“å…ƒæ•°æ®è®¾è®¡
        product_metadata = {
            "name": str,
            "price": float,
            "category": str,
            "brand": str,
            "rating": float,
            "in_stock": bool,
        }

        # LangChain AttributeInfo å®šä¹‰
        from langchain_classic.chains.query_constructor.base import AttributeInfo

        metadata_field_info = [
            AttributeInfo(name="category", description="æ–‡æ¡£ç±»åˆ«", type="string"),
            AttributeInfo(name="difficulty", description="éš¾åº¦çº§åˆ«", type="string"),
            AttributeInfo(name="date", description="å‘å¸ƒæ—¥æœŸ", type="string"),
        ]
        ```

    ç»ƒä¹  2ï¼šå¤æ‚è¿‡æ»¤
        å®ç°å¤šæ¡ä»¶ç»„åˆè¿‡æ»¤ï¼ˆAND/ORï¼‰ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        # è‡ªå®šä¹‰æŸ¥è¯¢è§£æ
        def parse_complex_query(query: str):
            '''è§£æåŒ…å«æ¡ä»¶çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢'''
            prompt = f'''
            åˆ†æä»¥ä¸‹æŸ¥è¯¢ï¼Œæå–æœç´¢è¯å’Œè¿‡æ»¤æ¡ä»¶ï¼š
            æŸ¥è¯¢ï¼š{query}
            
            è¿”å› JSON æ ¼å¼ï¼š
            {{"search": "æœç´¢è¯", "filters": {{"field": "value"}}}}
            '''
            return llm.invoke(prompt)

        # ä½¿ç”¨ Chroma çš„è¿‡æ»¤è¯­æ³•
        # AND æ¡ä»¶
        results = vectorstore.similarity_search(
            "Python",
            filter={
                "$and": [
                    {"category": "tutorial"},
                    {"difficulty": "beginner"}
                ]
            }
        )

        # OR æ¡ä»¶
        results = vectorstore.similarity_search(
            "Python",
            filter={
                "$or": [
                    {"language": "python"},
                    {"language": "javascript"}
                ]
            }
        )
        ```

    ç»ƒä¹  3ï¼šå¯¹æ¯”æ•ˆæœ
        å¯¹æ¯”è‡ªæŸ¥è¯¢ä¸æ™®é€šæ£€ç´¢çš„å‡†ç¡®ç‡ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        test_cases = [
            {
                "query": "2024å¹´å‘å¸ƒçš„Pythonåˆçº§æ•™ç¨‹",
                "expected_filter": {"date": {"$gte": "2024-01-01"}, "difficulty": "beginner"}
            },
            {
                "query": "ä»·æ ¼ä½äº100çš„ç”µå­äº§å“",
                "expected_filter": {"price": {"$lt": 100}, "category": "electronics"}
            },
        ]

        def evaluate_self_query():
            correct = 0
            for case in test_cases:
                # æ™®é€šæ£€ç´¢
                normal_results = retriever.invoke(case["query"])
                
                # è‡ªæŸ¥è¯¢
                self_query_results = self_query_retriever.invoke(case["query"])
                
                # æ£€æŸ¥è¿‡æ»¤æ˜¯å¦æ­£ç¡®åº”ç”¨
                for doc in self_query_results:
                    if matches_filter(doc.metadata, case["expected_filter"]):
                        correct += 1
            
            print(f"è‡ªæŸ¥è¯¢å‡†ç¡®ç‡: {correct/len(test_cases):.2%}")
        ```

    æ€è€ƒé¢˜ï¼š
        1. å…ƒæ•°æ®è¿‡æ»¤çš„æ€§èƒ½å½±å“ï¼Ÿ
           
           âœ… ç­”æ¡ˆï¼š
           - å‘é‡æ•°æ®åº“é€šå¸¸å…ˆè¿‡æ»¤åæœç´¢ï¼Œæ€§èƒ½å½±å“è¾ƒå°
           - ç´¢å¼•è®¾è®¡å¾ˆé‡è¦ï¼šå¸¸ç”¨è¿‡æ»¤å­—æ®µå»ºç«‹ç´¢å¼•
           - å¤æ‚è¿‡æ»¤ï¼ˆå¤šæ¡ä»¶ ORï¼‰å¯èƒ½è¾ƒæ…¢
           - å»ºè®®ï¼šæµ‹è¯•ä¸åŒè¿‡æ»¤æ¡ä»¶çš„å“åº”æ—¶é—´

        2. å¦‚ä½•å¤„ç† LLM è§£æé”™è¯¯ï¼Ÿ
           
           âœ… ç­”æ¡ˆï¼š
           - è®¾ç½®é»˜è®¤å€¼ï¼šè§£æå¤±è´¥æ—¶ä½¿ç”¨çº¯è¯­ä¹‰æ£€ç´¢
           - éªŒè¯è¿‡æ»¤æ¡ä»¶ï¼šæ£€æŸ¥å­—æ®µåå’Œå€¼æ˜¯å¦æœ‰æ•ˆ
           - é‡è¯•æœºåˆ¶ï¼šè§£æå¤±è´¥æ—¶é‡æ–°å°è¯•
           - Fallbackï¼šé™çº§åˆ°æ™®é€šæ£€ç´¢
           - æ—¥å¿—è®°å½•ï¼šè®°å½•å¤±è´¥æ¡ˆä¾‹ç”¨äºæ”¹è¿›
    """)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ è‡ªæŸ¥è¯¢æ£€ç´¢")
    print("=" * 60)

    try:
        self_query_concept()
        metadata_design()
        langchain_self_query()
        custom_filter()
        query_parsing()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        return

    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š07-hypothetical-questions.py")
    print("=" * 60)


if __name__ == "__main__":
    main()
