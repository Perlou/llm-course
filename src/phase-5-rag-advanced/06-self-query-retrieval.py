"""
è‡ªæŸ¥è¯¢æ£€ç´¢
==========

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£è‡ªæŸ¥è¯¢æ£€ç´¢çš„åŸç†
    2. æŒæ¡ LangChain SelfQueryRetriever
    3. å­¦ä¼šç»“æ„åŒ–å…ƒæ•°æ®è¿‡æ»¤

æ ¸å¿ƒæ¦‚å¿µï¼š
    - Self-Queryï¼šLLM è‡ªåŠ¨è§£ææŸ¥è¯¢æ„å›¾
    - å…ƒæ•°æ®è¿‡æ»¤ï¼šåŸºäºå±æ€§çš„ç²¾ç¡®ç­›é€‰
    - ç»“æ„åŒ–æŸ¥è¯¢ï¼šè¯­ä¹‰ + è¿‡æ»¤

å‰ç½®çŸ¥è¯†ï¼š
    - 05-multi-query-retrieval.py

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install langchain langchain-openai chromadb lark python-dotenv
"""

import os
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šè‡ªæŸ¥è¯¢æ£€ç´¢æ¦‚å¿µ ====================


def self_query_concept():
    """è‡ªæŸ¥è¯¢æ£€ç´¢æ¦‚å¿µ"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šè‡ªæŸ¥è¯¢æ£€ç´¢æ¦‚å¿µ")
    print("=" * 60)

    print("""
    è‡ªæŸ¥è¯¢æ£€ç´¢çš„ä¼˜åŠ¿ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    ä¼ ç»Ÿæ£€ç´¢åªèƒ½åšè¯­ä¹‰åŒ¹é…
    ä½†ç”¨æˆ·çš„æŸ¥è¯¢å¾€å¾€åŒ…å«è¿‡æ»¤æ¡ä»¶
    
    ç¤ºä¾‹æŸ¥è¯¢ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ã€Œæ‰¾ä¸€ç¯‡ 2023 å¹´å‘å¸ƒçš„å…³äº RAG çš„è®ºæ–‡ã€
    
    ä¼ ç»Ÿæ£€ç´¢ï¼šåªèƒ½è¯­ä¹‰åŒ¹é… "RAG"
    è‡ªæŸ¥è¯¢ï¼šåŒæ—¶è¿‡æ»¤ å¹´ä»½=2023 AND ç±»å‹=è®ºæ–‡
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ç”¨æˆ·æŸ¥è¯¢: "2023å¹´å…³äºRAGçš„è®ºæ–‡"                     â”‚
    â”‚                     â”‚                               â”‚
    â”‚                     â–¼                               â”‚
    â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
    â”‚          â”‚   LLM æ„å›¾è§£æ     â”‚                     â”‚
    â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
    â”‚                     â”‚                               â”‚
    â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
    â”‚         â–¼                       â–¼                   â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
    â”‚  â”‚  è¯­ä¹‰æŸ¥è¯¢    â”‚        â”‚  å…ƒæ•°æ®è¿‡æ»¤  â”‚           â”‚
    â”‚  â”‚  "RAG"      â”‚        â”‚  year=2023  â”‚           â”‚
    â”‚  â”‚             â”‚        â”‚  type=paper â”‚           â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜           â”‚
    â”‚         â”‚                      â”‚                   â”‚
    â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
    â”‚                    â–¼                               â”‚
    â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
    â”‚            â”‚ è”åˆæ£€ç´¢      â”‚                        â”‚
    â”‚            â”‚ å‘é‡ + è¿‡æ»¤   â”‚                        â”‚
    â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
    â”‚                                                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šå…ƒæ•°æ®è®¾è®¡ ====================


def metadata_design():
    """å…ƒæ•°æ®è®¾è®¡"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šå…ƒæ•°æ®è®¾è®¡")
    print("=" * 60)

    print("""
    å¸¸è§çš„å…ƒæ•°æ®å­—æ®µï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    æ–‡æ¡£ç±»å‹å…ƒæ•°æ®ï¼š
    - source: æ¥æº (blog, paper, doc)
    - type: ç±»å‹ (tutorial, reference, news)
    - author: ä½œè€…
    - date/year: å‘å¸ƒæ—¥æœŸ
    
    å†…å®¹ç›¸å…³å…ƒæ•°æ®ï¼š
    - topic: ä¸»é¢˜æ ‡ç­¾
    - language: è¯­è¨€
    - difficulty: éš¾åº¦çº§åˆ«
    - rating: è¯„åˆ†
    
    æŠ€æœ¯å…ƒæ•°æ®ï¼š
    - word_count: å­—æ•°
    - page_number: é¡µç 
    - chunk_id: åˆ†å—ID
    """)

    from langchain_core.documents import Document

    # ç¤ºä¾‹ï¼šå¸¦å…ƒæ•°æ®çš„æ–‡æ¡£
    docs = [
        Document(
            page_content="RAG æŠ€æœ¯ç»¼è¿°ï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆçš„åŸç†ä¸åº”ç”¨",
            metadata={
                "source": "paper",
                "year": 2023,
                "topic": "RAG",
                "language": "zh",
            },
        ),
        Document(
            page_content="LangChain å…¥é—¨æ•™ç¨‹ï¼šæ„å»ºä½ çš„ç¬¬ä¸€ä¸ª AI åº”ç”¨",
            metadata={
                "source": "tutorial",
                "year": 2024,
                "topic": "LangChain",
                "difficulty": "beginner",
            },
        ),
    ]

    print("ğŸ“Œ ç¤ºä¾‹æ–‡æ¡£ï¼š")
    for doc in docs:
        print(f"  å†…å®¹: {doc.page_content[:30]}...")
        print(f"  å…ƒæ•°æ®: {doc.metadata}")
        print()


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šLangChain SelfQueryRetriever ====================


def langchain_self_query():
    """LangChain SelfQueryRetriever"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šLangChain SelfQueryRetriever")
    print("=" * 60)

    try:
        from langchain.chains.query_constructor.base import AttributeInfo
        from langchain.retrievers.self_query.base import SelfQueryRetriever
        from langchain_openai import ChatOpenAI, OpenAIEmbeddings
        from langchain_chroma import Chroma
        from langchain_core.documents import Document

        # å‡†å¤‡å¸¦å…ƒæ•°æ®çš„æ–‡æ¡£
        docs = [
            Document(
                page_content="RAG (Retrieval-Augmented Generation) æ˜¯ä¸€ç§ç»“åˆæ£€ç´¢å’Œç”Ÿæˆçš„æŠ€æœ¯",
                metadata={"source": "paper", "year": 2023, "topic": "RAG"},
            ),
            Document(
                page_content="å‘é‡æ•°æ®åº“ç”¨äºé«˜æ•ˆå­˜å‚¨å’Œæ£€ç´¢å‘é‡",
                metadata={"source": "tutorial", "year": 2024, "topic": "vector_db"},
            ),
            Document(
                page_content="LangChain æ˜¯æ„å»º LLM åº”ç”¨çš„æ¡†æ¶",
                metadata={"source": "doc", "year": 2023, "topic": "LangChain"},
            ),
            Document(
                page_content="GPT-4 çš„å¤šæ¨¡æ€èƒ½åŠ›ä½¿å…¶å¯ä»¥å¤„ç†å›¾åƒ",
                metadata={"source": "news", "year": 2024, "topic": "LLM"},
            ),
        ]

        # åˆ›å»ºå‘é‡å­˜å‚¨
        embeddings = OpenAIEmbeddings()
        vectorstore = Chroma.from_documents(docs, embeddings)

        # å®šä¹‰å…ƒæ•°æ®å±æ€§
        metadata_field_info = [
            AttributeInfo(
                name="source",
                description="æ–‡æ¡£æ¥æºç±»å‹: paper, tutorial, doc, news",
                type="string",
            ),
            AttributeInfo(name="year", description="å‘å¸ƒå¹´ä»½", type="integer"),
            AttributeInfo(name="topic", description="ä¸»é¢˜æ ‡ç­¾", type="string"),
        ]

        # åˆ›å»ºè‡ªæŸ¥è¯¢æ£€ç´¢å™¨
        llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
        retriever = SelfQueryRetriever.from_llm(
            llm=llm,
            vectorstore=vectorstore,
            document_contents="æŠ€æœ¯æ–‡æ¡£å…³äº AI å’Œ LLM çš„å†…å®¹",
            metadata_field_info=metadata_field_info,
        )

        # æµ‹è¯•æŸ¥è¯¢
        queries = [
            "2023å¹´çš„ RAG è®ºæ–‡",
            "å…³äºå‘é‡æ•°æ®åº“çš„æ•™ç¨‹",
            "2024å¹´å‘å¸ƒçš„å†…å®¹",
        ]

        for query in queries:
            results = retriever.invoke(query)
            print(f"\nğŸ“Œ æŸ¥è¯¢: '{query}'")
            for doc in results:
                print(f"  - {doc.page_content[:40]}...")
                print(f"    å…ƒæ•°æ®: {doc.metadata}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        print("â„¹ï¸ éœ€è¦å®‰è£…: pip install lark")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šè‡ªå®šä¹‰è¿‡æ»¤å™¨ ====================


def custom_filter():
    """è‡ªå®šä¹‰è¿‡æ»¤å™¨"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šè‡ªå®šä¹‰è¿‡æ»¤å™¨")
    print("=" * 60)

    print("""
    Chroma è¿‡æ»¤å™¨è¯­æ³•ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    å•æ¡ä»¶è¿‡æ»¤ï¼š
    {"field": {"$eq": value}}     # ç­‰äº
    {"field": {"$ne": value}}     # ä¸ç­‰äº
    {"field": {"$gt": value}}     # å¤§äº
    {"field": {"$lt": value}}     # å°äº
    
    å¤šæ¡ä»¶ç»„åˆï¼š
    {"$and": [æ¡ä»¶1, æ¡ä»¶2]}
    {"$or": [æ¡ä»¶1, æ¡ä»¶2]}
    """)

    try:
        from langchain_openai import OpenAIEmbeddings
        from langchain_chroma import Chroma
        from langchain_core.documents import Document

        docs = [
            Document(
                page_content="Python åŸºç¡€æ•™ç¨‹", metadata={"level": 1, "lang": "zh"}
            ),
            Document(
                page_content="Python é«˜çº§ç‰¹æ€§", metadata={"level": 3, "lang": "zh"}
            ),
            Document(
                page_content="Python Advanced", metadata={"level": 3, "lang": "en"}
            ),
        ]

        embeddings = OpenAIEmbeddings()
        vectorstore = Chroma.from_documents(docs, embeddings)

        # å¸¦è¿‡æ»¤çš„æ£€ç´¢
        retriever = vectorstore.as_retriever(
            search_kwargs={
                "k": 2,
                "filter": {"level": {"$gt": 1}},  # level > 1
            }
        )

        results = retriever.invoke("Python")

        print("ğŸ“Œ è¿‡æ»¤æ¡ä»¶: level > 1")
        print("\næ£€ç´¢ç»“æœï¼š")
        for doc in results:
            print(f"  - {doc.page_content}")
            print(f"    å…ƒæ•°æ®: {doc.metadata}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šæŸ¥è¯¢è§£æå®ç° ====================


def query_parsing():
    """æŸ¥è¯¢è§£æå®ç°"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šæŸ¥è¯¢è§£æå®ç°")
    print("=" * 60)

    code_example = '''
class QueryParser:
    """æŸ¥è¯¢è§£æå™¨"""
    
    def __init__(self, llm, field_info):
        self.llm = llm
        self.field_info = field_info
    
    def parse(self, query: str) -> dict:
        """è§£ææŸ¥è¯¢ä¸ºç»“æ„åŒ–æ ¼å¼"""
        
        prompt = f"""
åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œæå–ï¼š
1. è¯­ä¹‰æŸ¥è¯¢éƒ¨åˆ†ï¼ˆç”¨äºå‘é‡æ£€ç´¢ï¼‰
2. è¿‡æ»¤æ¡ä»¶ï¼ˆåŸºäºå…ƒæ•°æ®å­—æ®µï¼‰

å¯ç”¨å­—æ®µ: {self.field_info}

ç”¨æˆ·æŸ¥è¯¢: {query}

è¾“å‡º JSON æ ¼å¼:
{{
  "semantic_query": "...",
  "filters": {{
    "field1": "value1",
    ...
  }}
}}
"""
        response = self.llm.predict(prompt)
        return json.loads(response)
    
    def search(self, query: str, vectorstore):
        parsed = self.parse(query)
        
        return vectorstore.similarity_search(
            parsed["semantic_query"],
            filter=parsed["filters"]
        )
'''
    print("ğŸ“Œ æŸ¥è¯¢è§£æå™¨ç¤ºä¾‹ï¼š")
    print(code_example)


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šè®¾è®¡å…ƒæ•°æ®
        ä¸ºä½ çš„æ–‡æ¡£è®¾è®¡åˆé€‚çš„å…ƒæ•°æ®ç»“æ„ã€‚

    ç»ƒä¹  2ï¼šå¤æ‚è¿‡æ»¤
        å®ç°å¤šæ¡ä»¶ç»„åˆè¿‡æ»¤ï¼ˆAND/ORï¼‰ã€‚

    ç»ƒä¹  3ï¼šå¯¹æ¯”æ•ˆæœ
        å¯¹æ¯”è‡ªæŸ¥è¯¢ä¸æ™®é€šæ£€ç´¢çš„å‡†ç¡®ç‡ã€‚

    æ€è€ƒé¢˜ï¼š
        1. å…ƒæ•°æ®è¿‡æ»¤çš„æ€§èƒ½å½±å“ï¼Ÿ
        2. å¦‚ä½•å¤„ç† LLM è§£æé”™è¯¯ï¼Ÿ
    """)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ è‡ªæŸ¥è¯¢æ£€ç´¢")
    print("=" * 60)

    try:
        self_query_concept()
        metadata_design()
        langchain_self_query()
        custom_filter()
        query_parsing()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        return

    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š07-hypothetical-questions.py")
    print("=" * 60)


if __name__ == "__main__":
    main()
