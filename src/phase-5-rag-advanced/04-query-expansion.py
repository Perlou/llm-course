"""
æŸ¥è¯¢æ‰©å±•
========

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£æŸ¥è¯¢æ‰©å±•çš„ä½œç”¨
    2. æŒæ¡åŒä¹‰è¯æ‰©å±•å’Œ LLM æ‰©å±•
    3. å­¦ä¼šå®ç°æŸ¥è¯¢æ”¹å†™

æ ¸å¿ƒæ¦‚å¿µï¼š
    - Query Expansionï¼šæ‰©å±•åŸå§‹æŸ¥è¯¢
    - Query Rewritingï¼šæ”¹å†™æŸ¥è¯¢è¯­å¥
    - Multi-Queryï¼šç”Ÿæˆå¤šä¸ªæŸ¥è¯¢å˜ä½“

å‰ç½®çŸ¥è¯†ï¼š
    - 03-parent-document-retriever.py

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install langchain langchain-openai python-dotenv
"""

import os
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šæŸ¥è¯¢æ‰©å±•æ¦‚å¿µ ====================


def query_expansion_concept():
    """æŸ¥è¯¢æ‰©å±•æ¦‚å¿µ"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šæŸ¥è¯¢æ‰©å±•æ¦‚å¿µ")
    print("=" * 60)

    print("""
    ä¸ºä»€ä¹ˆéœ€è¦æŸ¥è¯¢æ‰©å±•ï¼Ÿ
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    ç”¨æˆ·æŸ¥è¯¢å¾€å¾€ï¼š
    - è¡¨è¿°ä¸å®Œæ•´
    - ä½¿ç”¨æ¨¡ç³Šæœ¯è¯­
    - ç¼ºå°‘åŒä¹‰è¯
    
    ç¤ºä¾‹ï¼š
    â”€â”€â”€â”€â”€
    åŸå§‹æŸ¥è¯¢ï¼šã€Œå¦‚ä½•å‡è‚¥ã€
    
    æ‰©å±•åï¼š
    - å¦‚ä½•å‡è‚¥
    - ä½“é‡ç®¡ç†æ–¹æ³•
    - å¥åº·ç˜¦èº«æŠ€å·§
    - å‡é‡é¥®é£Ÿè®¡åˆ’
    - è¿åŠ¨å‡è„‚æ–¹æ¡ˆ
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 åŸå§‹æŸ¥è¯¢                         â”‚
    â”‚           "å¦‚ä½•å†™å¥½ä»£ç "                         â”‚
    â”‚                   â”‚                             â”‚
    â”‚                   â–¼                             â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚           æŸ¥è¯¢æ‰©å±•æ¨¡å—                    â”‚   â”‚
    â”‚  â”‚  â€¢ åŒä¹‰è¯æ‰©å±•                            â”‚   â”‚
    â”‚  â”‚  â€¢ LLM ç”Ÿæˆå˜ä½“                          â”‚   â”‚
    â”‚  â”‚  â€¢ å†å²æŸ¥è¯¢è¡¥å……                          â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                   â”‚                             â”‚
    â”‚                   â–¼                             â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”         â”‚
    â”‚  â”‚å†™å¥½  â”‚ â”‚ä»£ç   â”‚ â”‚ç¼–ç¨‹  â”‚ â”‚å¼€å‘  â”‚         â”‚
    â”‚  â”‚ä»£ç   â”‚ â”‚è§„èŒƒ  â”‚ â”‚æœ€ä½³  â”‚ â”‚æŠ€å·§  â”‚         â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â”‚å®è·µ  â”‚ â””â”€â”€â”€â”€â”€â”€â”˜         â”‚
    â”‚                    â””â”€â”€â”€â”€â”€â”€â”˜                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šåŒä¹‰è¯æ‰©å±• ====================


def synonym_expansion():
    """åŒä¹‰è¯æ‰©å±•"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šåŒä¹‰è¯æ‰©å±•")
    print("=" * 60)

    # ç®€å•çš„åŒä¹‰è¯è¡¨
    synonyms = {
        "ç¼–ç¨‹": ["ç¼–ç ", "å†™ä»£ç ", "ç¨‹åºè®¾è®¡"],
        "æœºå™¨å­¦ä¹ ": ["ML", "æœºå™¨æ™ºèƒ½", "ç»Ÿè®¡å­¦ä¹ "],
        "äººå·¥æ™ºèƒ½": ["AI", "æ™ºèƒ½ç³»ç»Ÿ", "äººå·¥æ™ºæ…§"],
        "æ•°æ®åº“": ["DB", "æ•°æ®å­˜å‚¨", "æ•°æ®ä»“åº“"],
    }

    def expand_query(query: str, syn_dict: dict) -> list:
        """ä½¿ç”¨åŒä¹‰è¯æ‰©å±•æŸ¥è¯¢"""
        expanded = [query]
        for term, syns in syn_dict.items():
            if term in query:
                for syn in syns:
                    expanded.append(query.replace(term, syn))
        return expanded

    query = "æœºå™¨å­¦ä¹ å…¥é—¨æ•™ç¨‹"
    expanded = expand_query(query, synonyms)

    print(f"ğŸ“Œ åŸå§‹æŸ¥è¯¢: '{query}'")
    print("\næ‰©å±•ç»“æœï¼š")
    for q in expanded:
        print(f"  - {q}")


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šLLM æŸ¥è¯¢æ‰©å±• ====================


def llm_query_expansion():
    """LLM æŸ¥è¯¢æ‰©å±•"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šLLM æŸ¥è¯¢æ‰©å±•")
    print("=" * 60)

    try:
        from langchain_openai import ChatOpenAI
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser

        llm = ChatOpenAI(model="gpt-3.5-turbo")

        prompt = ChatPromptTemplate.from_template("""
ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢æ‰©å±•ä¸“å®¶ã€‚ç»™å®šç”¨æˆ·çš„åŸå§‹æŸ¥è¯¢ï¼Œè¯·ç”Ÿæˆ 3-5 ä¸ªè¯­ä¹‰ç›¸è¿‘ä½†è¡¨è¿°ä¸åŒçš„æŸ¥è¯¢å˜ä½“ã€‚
è¿™äº›å˜ä½“åº”è¯¥èƒ½å¸®åŠ©æ£€ç´¢åˆ°æ›´å¤šç›¸å…³æ–‡æ¡£ã€‚

åŸå§‹æŸ¥è¯¢: {query}

è¯·ç›´æ¥åˆ—å‡ºæŸ¥è¯¢å˜ä½“ï¼Œæ¯è¡Œä¸€ä¸ª:""")

        chain = prompt | llm | StrOutputParser()

        query = "Python å¼‚æ­¥ç¼–ç¨‹"
        variants = chain.invoke({"query": query})

        print(f"ğŸ“Œ åŸå§‹æŸ¥è¯¢: '{query}'")
        print("\nLLM ç”Ÿæˆçš„å˜ä½“ï¼š")
        for line in variants.strip().split("\n"):
            if line.strip():
                print(f"  {line.strip()}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šæŸ¥è¯¢æ”¹å†™ ====================


def query_rewriting():
    """æŸ¥è¯¢æ”¹å†™"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šæŸ¥è¯¢æ”¹å†™")
    print("=" * 60)

    try:
        from langchain_openai import ChatOpenAI
        from langchain_core.prompts import ChatPromptTemplate

        llm = ChatOpenAI(model="gpt-3.5-turbo")

        # å¯¹è¯å†å²æ”¹å†™
        history_rewrite_prompt = ChatPromptTemplate.from_template("""
æ ¹æ®å¯¹è¯å†å²ï¼Œå°†ç”¨æˆ·çš„åç»­é—®é¢˜æ”¹å†™ä¸ºç‹¬ç«‹çš„å®Œæ•´é—®é¢˜ã€‚

å¯¹è¯å†å²:
{history}

ç”¨æˆ·é—®é¢˜: {question}

ç‹¬ç«‹é—®é¢˜:""")

        history = """
ç”¨æˆ·: Python æœ‰å“ªäº› Web æ¡†æ¶ï¼Ÿ
åŠ©æ‰‹: Python å¸¸è§çš„ Web æ¡†æ¶æœ‰ Djangoã€Flaskã€FastAPI ç­‰ã€‚
"""
        question = "å®ƒä»¬æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ"

        chain = history_rewrite_prompt | llm
        result = chain.invoke({"history": history, "question": question})

        print(f"ğŸ“Œ å¯¹è¯æ”¹å†™ç¤ºä¾‹ï¼š")
        print(f"  åŸå§‹é—®é¢˜: {question}")
        print(f"  æ”¹å†™å: {result.content}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šStep-Back Prompting ====================


def step_back_prompting():
    """Step-Back Prompting"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šStep-Back Prompting")
    print("=" * 60)

    print("""
    Step-Back ç­–ç•¥ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    å¯¹äºå…·ä½“é—®é¢˜ï¼Œå…ˆã€Œé€€ä¸€æ­¥ã€é—®æ›´æŠ½è±¡çš„é—®é¢˜
    
    ç¤ºä¾‹ï¼š
    â”€â”€â”€â”€â”€
    å…·ä½“é—®é¢˜ï¼šã€ŒiPhone 15 çš„ç”µæ± å®¹é‡æ˜¯å¤šå°‘ï¼Ÿã€
    
    Step-Backï¼šã€Œæ™ºèƒ½æ‰‹æœºçš„ç”µæ± æŠ€æœ¯æœ‰å“ªäº›ï¼Ÿã€
    
    è¿™æ ·å¯ä»¥è·å–æ›´å¤šèƒŒæ™¯çŸ¥è¯†
    """)

    try:
        from langchain_openai import ChatOpenAI
        from langchain_core.prompts import ChatPromptTemplate

        llm = ChatOpenAI(model="gpt-3.5-turbo")

        step_back_prompt = ChatPromptTemplate.from_template("""
ç»™å®šä¸€ä¸ªå…·ä½“é—®é¢˜ï¼Œè¯·ç”Ÿæˆä¸€ä¸ªæ›´æŠ½è±¡ã€æ›´åŸºç¡€çš„é—®é¢˜ã€‚
è¿™ä¸ªé—®é¢˜çš„ç­”æ¡ˆèƒ½æä¾›å›ç­”åŸé—®é¢˜æ‰€éœ€çš„èƒŒæ™¯çŸ¥è¯†ã€‚

å…·ä½“é—®é¢˜: {question}

æŠ½è±¡é—®é¢˜:""")

        question = "GPT-4 çš„ä¸Šä¸‹æ–‡çª—å£æ˜¯å¤šå°‘ï¼Ÿ"
        chain = step_back_prompt | llm
        result = chain.invoke({"question": question})

        print(f"ğŸ“Œ Step-Back ç¤ºä¾‹ï¼š")
        print(f"  å…·ä½“é—®é¢˜: {question}")
        print(f"  æŠ½è±¡é—®é¢˜: {result.content}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šé›†æˆå®ç° ====================


def integrated_expansion():
    """é›†æˆå®ç°"""
    print("\n" + "=" * 60)
    print("ç¬¬å…­éƒ¨åˆ†ï¼šé›†æˆæŸ¥è¯¢æ‰©å±•å™¨")
    print("=" * 60)

    code_example = '''
class QueryExpander:
    """ç»¼åˆæŸ¥è¯¢æ‰©å±•å™¨"""
    
    def __init__(self, llm, synonyms=None):
        self.llm = llm
        self.synonyms = synonyms or {}
    
    def expand(self, query: str, method: str = "all") -> list:
        """æ‰©å±•æŸ¥è¯¢"""
        queries = [query]
        
        if method in ["synonym", "all"]:
            queries.extend(self._synonym_expand(query))
        
        if method in ["llm", "all"]:
            queries.extend(self._llm_expand(query))
        
        return list(set(queries))
    
    def _synonym_expand(self, query):
        expanded = []
        for term, syns in self.synonyms.items():
            if term in query:
                expanded.extend(query.replace(term, s) for s in syns)
        return expanded
    
    def _llm_expand(self, query):
        prompt = f"ç”Ÿæˆ3ä¸ªä¸'{query}'è¯­ä¹‰ç›¸è¿‘çš„æŸ¥è¯¢å˜ä½“..."
        response = self.llm.predict(prompt)
        return [q.strip() for q in response.split("\\n") if q.strip()]
'''
    print("ğŸ“Œ ç»¼åˆæ‰©å±•å™¨ç¤ºä¾‹ï¼š")
    print(code_example)


# ==================== ç¬¬ä¸ƒéƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šæ„å»ºåŒä¹‰è¯åº“
        ä¸ºä½ çš„é¢†åŸŸæ„å»ºä¸€ä¸ªåŒä¹‰è¯åº“ã€‚

    ç»ƒä¹  2ï¼šå¯¹æ¯”æ‰©å±•æ•ˆæœ
        å¯¹æ¯”æ‰©å±•å‰åæ£€ç´¢å¬å›ç‡çš„å˜åŒ–ã€‚

    ç»ƒä¹  3ï¼šåŠ¨æ€æ‰©å±•
        æ ¹æ®åˆæ¬¡æ£€ç´¢ç»“æœåŠ¨æ€å†³å®šæ˜¯å¦æ‰©å±•ã€‚

    æ€è€ƒé¢˜ï¼š
        1. æ‰©å±•å¤ªå¤šä¼šæœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ
        2. å¦‚ä½•æ§åˆ¶æ‰©å±•çš„è´¨é‡ï¼Ÿ
    """)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æŸ¥è¯¢æ‰©å±•")
    print("=" * 60)

    try:
        query_expansion_concept()
        synonym_expansion()
        llm_query_expansion()
        query_rewriting()
        step_back_prompting()
        integrated_expansion()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        return

    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š05-multi-query-retrieval.py")
    print("=" * 60)


if __name__ == "__main__":
    main()
