"""
RAG è¯„ä¼°æŒ‡æ ‡
===========

å­¦ä¹ ç›®æ ‡ï¼š
    1. æŒæ¡ RAG è¯„ä¼°çš„æ ¸å¿ƒç»´åº¦
    2. å­¦ä¼šæ£€ç´¢è´¨é‡è¯„ä¼°
    3. ç†è§£ç”Ÿæˆè´¨é‡è¯„ä¼°

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install langchain langchain-google-genai python-dotenv
"""

import os
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šè¯„ä¼°ç»´åº¦ ====================


def evaluation_dimensions():
    """RAG è¯„ä¼°ç»´åº¦"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šRAG è¯„ä¼°ç»´åº¦")
    print("=" * 60)

    print("""
    RAG è¯„ä¼°ä½“ç³»ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    1. æ£€ç´¢è´¨é‡
       - Precision@K: æ£€ç´¢ç²¾ç¡®ç‡
       - Recall@K: æ£€ç´¢å¬å›ç‡
       - MRR: å¹³å‡å€’æ•°æ’å
    
    2. ç”Ÿæˆè´¨é‡
       - Faithfulness: å¿ å®åº¦
       - Relevance: ç›¸å…³æ€§
       - Completeness: å®Œæ•´æ€§
    
    3. ç«¯åˆ°ç«¯
       - Answer Correctness: æ­£ç¡®æ€§
       - Latency: å»¶è¿Ÿ
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šæ£€ç´¢è¯„ä¼° ====================


def retrieval_metrics():
    """æ£€ç´¢è¯„ä¼°"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šæ£€ç´¢è¯„ä¼°")
    print("=" * 60)

    def precision_at_k(retrieved, relevant, k):
        hits = sum(1 for d in retrieved[:k] if d in relevant)
        return hits / k

    def recall_at_k(retrieved, relevant, k):
        hits = sum(1 for d in retrieved[:k] if d in relevant)
        return hits / len(relevant) if relevant else 0

    def mrr(retrieved, relevant):
        for i, doc in enumerate(retrieved):
            if doc in relevant:
                return 1 / (i + 1)
        return 0

    retrieved = ["doc1", "doc2", "doc3", "doc4", "doc5"]
    relevant = {"doc2", "doc4", "doc6"}

    print(f"ğŸ“Œ Precision@5: {precision_at_k(retrieved, relevant, 5):.3f}")
    print(f"ğŸ“Œ Recall@5: {recall_at_k(retrieved, relevant, 5):.3f}")
    print(f"ğŸ“Œ MRR: {mrr(retrieved, relevant):.3f}")


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šç”Ÿæˆè¯„ä¼° ====================


def generation_metrics():
    """ç”Ÿæˆè¯„ä¼°"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šç”Ÿæˆè¯„ä¼°")
    print("=" * 60)

    try:
        from langchain_google_genai import ChatGoogleGenerativeAI

        llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)

        context = "Python æ˜¯ä¸€ç§è§£é‡Šå‹ç¼–ç¨‹è¯­è¨€ã€‚"
        answer = "Python æ˜¯ä¸€ç§è§£é‡Šå‹ç¼–ç¨‹è¯­è¨€ã€‚"
        question = "Python æ˜¯ä»€ä¹ˆï¼Ÿ"

        prompt = f"""
è¯„ä¼°å›ç­”æ˜¯å¦å¿ å®äºä¸Šä¸‹æ–‡(1-10åˆ†):
ä¸Šä¸‹æ–‡: {context}
å›ç­”: {answer}
åªè¾“å‡ºåˆ†æ•°:"""

        score = llm.invoke(prompt)
        print(f"ğŸ“Œ å¿ å®åº¦: {score.content}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ä¸»å‡½æ•° ====================


def main():
    print("ğŸš€ RAG è¯„ä¼°æŒ‡æ ‡")
    print("=" * 60)

    evaluation_dimensions()
    retrieval_metrics()
    generation_metrics()

    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š11-project-enterprise-qa.py")


if __name__ == "__main__":
    main()
