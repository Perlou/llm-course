"""
æ‰¹é‡æ¨ç†
========

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£æ‰¹é‡æ¨ç†çš„ä¼˜åŠ¿
    2. å®ç°é™æ€æ‰¹å¤„ç†å’ŒåŠ¨æ€æ‰¹å¤„ç†
    3. ä¼˜åŒ–æ‰¹å¤„ç†å‚æ•°

æ ¸å¿ƒæ¦‚å¿µï¼š
    - é™æ€æ‰¹å¤„ç†ï¼šå›ºå®šå¤§å°æ‰¹æ¬¡ä¸€èµ·å¤„ç†
    - åŠ¨æ€æ‰¹å¤„ç†ï¼šæŒç»­å¡«å……ï¼Œæœ€å¤§åŒ–åˆ©ç”¨ç‡
    - Continuous Batchingï¼švLLM/TGI çš„æ ¸å¿ƒæŠ€æœ¯

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install transformers torch
"""

import asyncio
import time
from typing import List


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šæ‰¹å¤„ç†æ¦‚å¿µ ====================


def introduction():
    """æ‰¹å¤„ç†æ¦‚å¿µ"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šæ‰¹å¤„ç†æ¦‚å¿µ")
    print("=" * 60)

    print("""
    ğŸ“Œ ä¸ºä»€ä¹ˆéœ€è¦æ‰¹å¤„ç†ï¼Ÿ

    å•æ¡å¤„ç†ï¼šæ•ˆç‡ä½
    â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”
    â”‚Req1â”‚â†’â”‚Req2â”‚â†’â”‚Req3â”‚â†’â”‚Req4â”‚  ä¸²è¡Œå¤„ç†
    â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜

    æ‰¹é‡å¤„ç†ï¼šæ•ˆç‡é«˜
    â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”
    â”‚Req1â”‚Req2â”‚Req3â”‚Req4â”‚  å¹¶è¡Œå¤„ç†
    â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”˜

    ğŸ“Œ æ‰¹å¤„ç†ç­–ç•¥å¯¹æ¯”ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  é™æ€æ‰¹å¤„ç†  â”‚ å‡‘å¤Ÿå›ºå®šæ•°é‡å†å¤„ç†ï¼Œç®€å•ä½†æœ‰å»¶è¿Ÿ     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  åŠ¨æ€æ‰¹å¤„ç†  â”‚ è®¾ç½®è¶…æ—¶ï¼Œåˆ°æ—¶é—´æˆ–å‡‘å¤Ÿå³å¤„ç†         â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  Continuous â”‚ å®Œæˆä¸€ä¸ªç«‹å³åŠ å…¥æ–°çš„ï¼ŒæŒç»­å¡«å……       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šé™æ€æ‰¹å¤„ç† ====================


def static_batching():
    """é™æ€æ‰¹å¤„ç†"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šé™æ€æ‰¹å¤„ç†")
    print("=" * 60)

    code = """
class StaticBatcher:
    def __init__(self, model, batch_size=8):
        self.model = model
        self.batch_size = batch_size
        self.queue = []

    def add(self, request):
        self.queue.append(request)
        if len(self.queue) >= self.batch_size:
            return self.process_batch()
        return None

    def process_batch(self):
        batch = self.queue[:self.batch_size]
        self.queue = self.queue[self.batch_size:]

        # æ‰¹é‡æ¨ç†
        inputs = [r["text"] for r in batch]
        outputs = self.model.generate(inputs)

        return list(zip(batch, outputs))

# ä½¿ç”¨
batcher = StaticBatcher(model, batch_size=8)
for request in requests:
    result = batcher.add(request)
    if result:
        print("Batch processed:", len(result))
"""
    print(code)


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šåŠ¨æ€æ‰¹å¤„ç† ====================


def dynamic_batching():
    """åŠ¨æ€æ‰¹å¤„ç†"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šåŠ¨æ€æ‰¹å¤„ç†")
    print("=" * 60)

    code = """
import asyncio
import time

class DynamicBatcher:
    def __init__(self, max_batch=8, max_wait=0.1):
        self.queue = asyncio.Queue()
        self.max_batch = max_batch
        self.max_wait = max_wait  # ç§’

    async def add(self, request):
        future = asyncio.Future()
        await self.queue.put((request, future))
        return await future

    async def process_loop(self):
        while True:
            batch = []
            futures = []
            deadline = time.time() + self.max_wait

            # æ”¶é›†æ‰¹æ¬¡
            while len(batch) < self.max_batch:
                timeout = max(0, deadline - time.time())
                try:
                    item, future = await asyncio.wait_for(
                        self.queue.get(), timeout
                    )
                    batch.append(item)
                    futures.append(future)
                except asyncio.TimeoutError:
                    break

            if batch:
                results = await self.batch_inference(batch)
                for future, result in zip(futures, results):
                    future.set_result(result)

    async def batch_inference(self, batch):
        # å®é™…æ¨ç†é€»è¾‘
        return [f"Result for {b}" for b in batch]
"""
    print(code)


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šå‚æ•°è°ƒä¼˜ ====================


def parameter_tuning():
    """å‚æ•°è°ƒä¼˜"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šå‚æ•°è°ƒä¼˜")
    print("=" * 60)

    print("""
    ğŸ“Œ æ‰¹å¤„ç†å‚æ•°è°ƒä¼˜ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      å‚æ•°        â”‚      è¯´æ˜      â”‚       æƒè¡¡          â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ max_batch_size  â”‚ æœ€å¤§æ‰¹å¤§å°     â”‚ å¤§â†’é«˜ååï¼Œå»¶è¿Ÿå¢åŠ  â”‚
    â”‚ max_waiting_timeâ”‚ æœ€å¤§ç­‰å¾…æ—¶é—´   â”‚ é•¿â†’æ‰¹æ›´å¤§ï¼Œå»¶è¿Ÿå¢åŠ  â”‚
    â”‚ dynamic_batchingâ”‚ åŠ¨æ€æ‰¹å¤„ç†     â”‚ æå‡ 30%+ ååé‡   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    è°ƒä¼˜ç­–ç•¥ï¼š
    1. ä½å»¶è¿Ÿè¦æ±‚ â†’ å‡å° batch_size å’Œ wait_time
    2. é«˜ååè¦æ±‚ â†’ å¢å¤§ batch_sizeï¼Œä½¿ç”¨ Continuous Batching
    3. å®é™…æµ‹è¯•ç¡®å®šæœ€ä¼˜é…ç½®

    å‚è€ƒå€¼ï¼š
    - åœ¨çº¿æœåŠ¡ï¼šbatch_size=4-8, wait_time=50-100ms
    - ç¦»çº¿å¤„ç†ï¼šbatch_size=32-64, wait_time=500ms-1s
    """)


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šç»ƒä¹  ====================


def exercises():
    """ç»ƒä¹ """
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šå®ç°åŠ¨æ€æ‰¹å¤„ç†æœåŠ¡

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        import asyncio
        import time
        from typing import Dict, Any
        import uuid
        
        class DynamicBatchService:
            def __init__(self, model, max_batch=8, max_wait=0.1):
                self.model = model
                self.queue = asyncio.Queue()
                self.max_batch = max_batch
                self.max_wait = max_wait
                self.running = True
            
            async def add_request(self, request: dict) -> str:
                future = asyncio.Future()
                request_id = str(uuid.uuid4())
                await self.queue.put((request_id, request, future))
                result = await future
                return result
            
            async def batch_worker(self):
                while self.running:
                    batch = []
                    futures = []
                    deadline = time.time() + self.max_wait
                    
                    while len(batch) < self.max_batch:
                        timeout = max(0, deadline - time.time())
                        try:
                            req_id, request, future = await asyncio.wait_for(
                                self.queue.get(), timeout
                            )
                            batch.append(request)
                            futures.append(future)
                        except asyncio.TimeoutError:
                            break
                    
                    if batch:
                        results = await self.batch_inference(batch)
                        for future, result in zip(futures, results):
                            future.set_result(result)
            
            async def batch_inference(self, batch):
                # æ‰¹é‡æ¨ç†
                inputs = [r["text"] for r in batch]
                outputs = self.model.generate(inputs)
                return outputs
        
        # ä½¿ç”¨
        service = DynamicBatchService(model, max_batch=8, max_wait=0.1)
        asyncio.create_task(service.batch_worker())
        result = await service.add_request({"text": "Hello"})
        ```
    
    ç»ƒä¹  2ï¼šæµ‹è¯•ä¸åŒæ‰¹å¤„ç†å‚æ•°å¯¹ååé‡å’Œå»¶è¿Ÿçš„å½±å“

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        import asyncio
        import time
        
        async def benchmark_batch_params(service_class, model, params_list):
            results = []
            
            for max_batch, max_wait in params_list:
                service = service_class(model, max_batch, max_wait)
                asyncio.create_task(service.batch_worker())
                
                # ç”Ÿæˆæµ‹è¯•è¯·æ±‚
                requests = [{"text": f"Request {i}"} for i in range(100)]
                
                start = time.time()
                tasks = [service.add_request(r) for r in requests]
                await asyncio.gather(*tasks)
                total_time = time.time() - start
                
                results.append({
                    "max_batch": max_batch,
                    "max_wait": max_wait,
                    "throughput": len(requests) / total_time,
                    "avg_latency": total_time / len(requests),
                })
                
                service.running = False
            
            return results
        
        # æµ‹è¯•å‚æ•°ç»„åˆ
        params = [(4, 0.05), (8, 0.1), (16, 0.2), (32, 0.5)]
        results = await benchmark_batch_params(DynamicBatchService, model, params)
        
        for r in results:
            print(f"batch={r['max_batch']}, wait={r['max_wait']:.2f}s -> "
                  f"throughput={r['throughput']:.1f}/s, latency={r['avg_latency']*1000:.0f}ms")
        ```

    æ€è€ƒé¢˜ï¼šä¸ºä»€ä¹ˆ vLLM çš„ Continuous Batching æ¯”é™æ€æ‰¹å¤„ç†æ›´é«˜æ•ˆï¼Ÿ

        âœ… ç­”ï¼š
        1. é™æ€æ‰¹å¤„ç†éœ€è¦ç­‰å¾…æ‰€æœ‰è¯·æ±‚å®Œæˆæ‰èƒ½å¤„ç†ä¸‹ä¸€æ‰¹
        2. Continuous Batching åœ¨ä»»æ„è¯·æ±‚å®Œæˆæ—¶ç«‹å³åŠ å…¥æ–°è¯·æ±‚
        3. æŒç»­å¡«å…… GPUï¼Œä¿æŒé«˜åˆ©ç”¨ç‡
        4. çŸ­è¯·æ±‚ä¸ä¼šè¢«é•¿è¯·æ±‚é˜»å¡
        5. å®é™…ååé‡å¯æå‡ 2-3 å€
    """)


def main():
    introduction()
    static_batching()
    dynamic_batching()
    parameter_tuning()
    exercises()
    print("\nè¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š07-docker-deployment.py")


if __name__ == "__main__":
    main()
