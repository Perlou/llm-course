"""
vLLM éƒ¨ç½²å®æˆ˜
============

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£ vLLM çš„æ ¸å¿ƒæŠ€æœ¯ï¼ˆPagedAttentionã€Continuous Batchingï¼‰
    2. æŒæ¡ vLLM æœåŠ¡éƒ¨ç½²å’Œå‚æ•°è°ƒä¼˜
    3. ä½¿ç”¨ OpenAI å…¼å®¹ API è°ƒç”¨

æ ¸å¿ƒæ¦‚å¿µï¼š
    - PagedAttentionï¼šé«˜æ•ˆçš„ KV Cache ç®¡ç†
    - Continuous Batchingï¼šåŠ¨æ€æ‰¹å¤„ç†

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install vllm
    - NVIDIA GPU with CUDA 11.8+
"""

import os


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼švLLM æ ¸å¿ƒæŠ€æœ¯ ====================


def introduction():
    """vLLM æ ¸å¿ƒæŠ€æœ¯ä»‹ç»"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼švLLM æ ¸å¿ƒæŠ€æœ¯")
    print("=" * 60)

    print("""
    ğŸ“Œ vLLM æ ¸å¿ƒä¼˜åŠ¿ï¼š
    1. é«˜ååé‡ - æ¯” HuggingFace å¿« 24x
    2. PagedAttention - æ˜¾å­˜åˆ©ç”¨ç‡æå‡ 2-4 å€
    3. Continuous Batching - åŠ¨æ€æ‰¹å¤„ç†
    4. OpenAI å…¼å®¹ API

    PagedAttention åŸç†ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ ç‰©ç†é¡µæ± : [P1][P2][P3][P4][P5][P6]...  â”‚
    â”‚ Seq1 -> [P1, P3, P5]  æŒ‰éœ€åˆ†é…         â”‚
    â”‚ Seq2 -> [P2, P4]      æ— ç¢ç‰‡           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€ä½¿ç”¨ ====================


def basic_usage():
    """vLLM åŸºç¡€ä½¿ç”¨"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€ä½¿ç”¨")
    print("=" * 60)

    print("""
    # å®‰è£…
    pip install vllm

    # ç¦»çº¿æ¨ç†ç¤ºä¾‹
    from vllm import LLM, SamplingParams

    llm = LLM(model="Qwen/Qwen2-7B-Instruct")
    sampling_params = SamplingParams(temperature=0.7, max_tokens=256)

    prompts = ["ä»‹ç»ä¸€ä¸‹ vLLM", "ä»€ä¹ˆæ˜¯ LLMï¼Ÿ"]
    outputs = llm.generate(prompts, sampling_params)

    for output in outputs:
        print(output.outputs[0].text)
    """)


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šæœåŠ¡éƒ¨ç½² ====================


def server_deployment():
    """æœåŠ¡éƒ¨ç½²"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šæœåŠ¡éƒ¨ç½²")
    print("=" * 60)

    print("""
    # å¯åŠ¨ OpenAI å…¼å®¹æœåŠ¡
    python -m vllm.entrypoints.openai.api_server \\
        --model Qwen/Qwen2-7B-Instruct \\
        --port 8000 \\
        --gpu-memory-utilization 0.9 \\
        --max-num-seqs 64

    # Python å®¢æˆ·ç«¯è°ƒç”¨
    from openai import OpenAI

    client = OpenAI(base_url="http://localhost:8000/v1", api_key="x")
    response = client.chat.completions.create(
        model="Qwen/Qwen2-7B-Instruct",
        messages=[{"role": "user", "content": "Hello!"}]
    )
    print(response.choices[0].message.content)
    """)


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šå‚æ•°è°ƒä¼˜ ====================


def parameter_tuning():
    """å‚æ•°è°ƒä¼˜"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šå‚æ•°è°ƒä¼˜")
    print("=" * 60)

    print("""
    å…³é”®å‚æ•°ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        å‚æ•°            â”‚     è¯´æ˜       â”‚   æ¨èå€¼     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ gpu-memory-utilizationâ”‚ æ˜¾å­˜ä½¿ç”¨æ¯”ä¾‹   â”‚ 0.85-0.95   â”‚
    â”‚ max-num-seqs          â”‚ æœ€å¤§å¹¶å‘åºåˆ—   â”‚ 32-128      â”‚
    â”‚ max-model-len         â”‚ æœ€å¤§åºåˆ—é•¿åº¦   â”‚ æŒ‰éœ€è®¾ç½®     â”‚
    â”‚ tensor-parallel-size  â”‚ GPU å¹¶è¡Œæ•°     â”‚ GPU å¡æ•°    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    # é‡åŒ–æ¨¡å‹éƒ¨ç½²
    python -m vllm.entrypoints.openai.api_server \\
        --model Qwen/Qwen2-7B-Instruct-AWQ \\
        --quantization awq
    """)


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šç»ƒä¹  ====================


def exercises():
    """ç»ƒä¹ """
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šéƒ¨ç½² vLLM æœåŠ¡å¹¶æµ‹è¯•
    ç»ƒä¹  2ï¼šå¯¹æ¯”ä¸åŒå‚æ•°é…ç½®çš„æ€§èƒ½å·®å¼‚

    æ€è€ƒé¢˜ï¼švLLM ç›¸æ¯” HuggingFace generate æœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ
    ç­”æ¡ˆï¼šæ›´é«˜ååé‡ã€æ›´å¥½æ˜¾å­˜åˆ©ç”¨ç‡ã€åŸç”Ÿ OpenAI API å…¼å®¹
    """)


def main():
    introduction()
    basic_usage()
    server_deployment()
    parameter_tuning()
    exercises()
    print("\nè¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š03-tgi-deployment.py")


if __name__ == "__main__":
    main()
