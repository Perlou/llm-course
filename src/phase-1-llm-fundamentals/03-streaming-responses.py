"""
æµå¼å“åº”å¤„ç† (Gemini ç‰ˆæœ¬)
==========================

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£æµå¼å“åº”çš„ä¼˜åŠ¿
    2. æŒæ¡ Gemini æµå¼ API çš„ä½¿ç”¨æ–¹æ³•
    3. å­¦ä¼šå¤„ç†æµå¼å“åº”çš„æ•°æ®ç»“æ„
    4. å®ç°æµå¼è¾“å‡ºçš„ç”¨æˆ·ç•Œé¢

æ ¸å¿ƒæ¦‚å¿µï¼š
    - Streamingï¼šé€å—è¿”å›å“åº”ï¼Œè€Œéç­‰å¾…å®Œæ•´ç»“æœ
    - Chunkï¼šæ¯ä¸ªæµå¼å—ä¸­çš„å¢é‡å†…å®¹
    - é¦–å­—å»¶è¿Ÿï¼ˆTTFTï¼‰ï¼šTime To First Token

å‰ç½®çŸ¥è¯†ï¼š
    - å®Œæˆ 01-openai-api-basics.py
    - å®Œæˆ 02-openai-parameters.py

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install google-generativeai python-dotenv
"""

import os
import time
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šæµå¼ vs éæµå¼å¯¹æ¯” ====================


def compare_streaming_modes():
    """å¯¹æ¯”æµå¼å’Œéæµå¼å“åº”"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šæµå¼ vs éæµå¼å¯¹æ¯”")
    print("=" * 60)

    import google.generativeai as genai

    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

    model = genai.GenerativeModel("gemini-2.0-flash")
    prompt = "å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„å››å¥è¯—"

    print("""
æµå¼å“åº”çš„ä¼˜åŠ¿ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç‰¹ç‚¹            â”‚ è¯´æ˜                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ›´å¿«çš„é¦–å­—å“åº”  â”‚ ç”¨æˆ·ç«‹å³çœ‹åˆ°è¾“å‡ºå¼€å§‹                â”‚
â”‚ æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ  â”‚ é€å­—è¾“å‡ºæ›´è‡ªç„¶ï¼Œåƒæ‰“å­—æœºæ•ˆæœ        â”‚
â”‚ èŠ‚çœç­‰å¾…æ—¶é—´    â”‚ æ— éœ€ç­‰å¾…å®Œæ•´å“åº”                    â”‚
â”‚ å¯æå‰ç»ˆæ­¢      â”‚ å¯ä»¥åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å–æ¶ˆ                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)

    # éæµå¼è°ƒç”¨
    print("ğŸ“Œ éæµå¼è°ƒç”¨ï¼ˆéœ€è¦ç­‰å¾…å®Œæ•´å“åº”ï¼‰ï¼š")
    print("-" * 40)

    start_time = time.time()
    response = model.generate_content(prompt, stream=False)
    end_time = time.time()

    print(f"å›å¤: {response.text}")
    print(f"â±ï¸ æ€»è€—æ—¶: {end_time - start_time:.2f} ç§’")

    # æµå¼è°ƒç”¨
    print("\nğŸ“Œ æµå¼è°ƒç”¨ï¼ˆé€å­—è¾“å‡ºï¼‰ï¼š")
    print("-" * 40)

    start_time = time.time()
    first_token_time = None

    response = model.generate_content(prompt, stream=True)

    print("å›å¤: ", end="", flush=True)
    for chunk in response:
        if chunk.text:
            if first_token_time is None:
                first_token_time = time.time()
            print(chunk.text, end="", flush=True)

    print()  # æ¢è¡Œ
    end_time = time.time()

    if first_token_time:
        print(f"â±ï¸ é¦–å­—å»¶è¿Ÿ (TTFT): {first_token_time - start_time:.2f} ç§’")
    print(f"â±ï¸ æ€»è€—æ—¶: {end_time - start_time:.2f} ç§’")
    print("\nğŸ’¡ æ³¨æ„ï¼šæµå¼æ¨¡å¼ä¸‹ï¼Œç”¨æˆ·ç¬¬ä¸€æ—¶é—´å°±èƒ½çœ‹åˆ°è¾“å‡ºå¼€å§‹ï¼")


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šæµå¼å“åº”æ•°æ®ç»“æ„ ====================


def examine_stream_structure():
    """è¯¦ç»†æŸ¥çœ‹æµå¼å“åº”çš„æ•°æ®ç»“æ„"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šæµå¼å“åº”æ•°æ®ç»“æ„")
    print("=" * 60)

    import google.generativeai as genai

    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

    print("""
Gemini æµå¼å“åº”çš„ chunk ç»“æ„ï¼š
- æ¯ä¸ª chunk åŒ…å«éƒ¨åˆ†ç”Ÿæˆçš„æ–‡æœ¬
- chunk.text è·å–å½“å‰å—çš„å†…å®¹
- æœ€åå¯ä»¥æ£€æŸ¥ response.candidates[0].finish_reason
    """)

    model = genai.GenerativeModel("gemini-2.0-flash")
    response = model.generate_content("è¯´3ä¸ªæ•°å­—", stream=True)

    print("ğŸ“¦ å„ä¸ª chunk çš„å†…å®¹ï¼š")
    print("-" * 40)

    chunk_count = 0
    for chunk in response:
        chunk_count += 1
        content = chunk.text if chunk.text else ""
        print(f"Chunk {chunk_count:2d}: content={repr(content)}")

    print(f"\nğŸ“Š å…±æ”¶åˆ° {chunk_count} ä¸ª chunks")


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®Œæ•´çš„æµå¼å¤„ç†å‡½æ•° ====================


def stream_with_full_handling():
    """å¸¦å®Œæ•´å¤„ç†çš„æµå¼å‡½æ•°"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®Œæ•´çš„æµå¼å¤„ç†å‡½æ•°")
    print("=" * 60)

    import google.generativeai as genai

    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

    print("ä¸‹é¢æ˜¯ä¸€ä¸ªç”Ÿäº§çº§çš„æµå¼å¤„ç†å‡½æ•°ç¤ºä¾‹ï¼š\n")

    def stream_chat(prompt, system=None, on_token=None, on_complete=None):
        """
        æµå¼èŠå¤©å‡½æ•° (Gemini ç‰ˆæœ¬)

        Args:
            prompt: ç”¨æˆ·æ¶ˆæ¯
            system: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            on_token: æ¯æ”¶åˆ°ä¸€ä¸ª token æ—¶çš„å›è°ƒå‡½æ•°
            on_complete: å®Œæˆæ—¶çš„å›è°ƒå‡½æ•°

        Returns:
            å®Œæ•´çš„å›å¤å†…å®¹
        """
        if system:
            model = genai.GenerativeModel("gemini-2.0-flash", system_instruction=system)
        else:
            model = genai.GenerativeModel("gemini-2.0-flash")

        response = model.generate_content(prompt, stream=True)

        collected_content = []

        for chunk in response:
            if chunk.text:
                collected_content.append(chunk.text)
                if on_token:
                    on_token(chunk.text)

        full_content = "".join(collected_content)
        if on_complete:
            on_complete(full_content)
        return full_content

    # ä½¿ç”¨ç¤ºä¾‹
    print("ğŸ“ ä½¿ç”¨ç¤ºä¾‹ï¼š")
    print("-" * 40)

    def print_token(token):
        print(token, end="", flush=True)

    def on_done(full_text):
        print(f"\n\nâœ… å®Œæˆï¼å…± {len(full_text)} ä¸ªå­—ç¬¦")

    print("å›å¤: ", end="")
    result = stream_chat(
        prompt="ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ",
        on_token=print_token,
        on_complete=on_done,
    )


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šå¼‚æ­¥æµå¼å¤„ç† ====================


def async_streaming_intro():
    """å¼‚æ­¥æµå¼å¤„ç†ä»‹ç»ï¼ˆä»…å±•ç¤ºæ¦‚å¿µï¼‰"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šå¼‚æ­¥æµå¼å¤„ç†ï¼ˆæ¦‚å¿µä»‹ç»ï¼‰")
    print("=" * 60)

    print("""
åœ¨ Web åº”ç”¨ä¸­ï¼Œé€šå¸¸ä½¿ç”¨å¼‚æ­¥æµå¼å¤„ç†ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ # Gemini å¼‚æ­¥æµå¼ç¤ºä¾‹ (FastAPI + SSE)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ from fastapi import FastAPI                                 â”‚
â”‚ from fastapi.responses import StreamingResponse             â”‚
â”‚ import google.generativeai as genai                         â”‚
â”‚                                                             â”‚
â”‚ app = FastAPI()                                             â”‚
â”‚ genai.configure(api_key="your-key")                         â”‚
â”‚                                                             â”‚
â”‚ @app.post("/chat/stream")                                   â”‚
â”‚ async def chat_stream(message: str):                        â”‚
â”‚     async def generate():                                   â”‚
â”‚         model = genai.GenerativeModel("gemini-2.0-flash")   â”‚
â”‚         response = model.generate_content(message,          â”‚
â”‚                                          stream=True)       â”‚
â”‚         for chunk in response:                              â”‚
â”‚             if chunk.text:                                  â”‚
â”‚                 yield f"data: {chunk.text}\\n\\n"           â”‚
â”‚                                                             â”‚
â”‚     return StreamingResponse(generate(),                    â”‚
â”‚                             media_type="text/event-stream") â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’¡ å…³é”®ç‚¹ï¼š
1. ä½¿ç”¨ stream=True å‚æ•°å¯ç”¨æµå¼
2. éå† response è·å– chunks
3. ä½¿ç”¨ yield ç”Ÿæˆ SSE (Server-Sent Events)
4. å‰ç«¯ä½¿ç”¨ EventSource æˆ– fetch æ¥æ”¶æµ
    """)


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šæ¨¡æ‹Ÿæ‰“å­—æœºæ•ˆæœ ====================


def typewriter_effect():
    """å®ç°æ‰“å­—æœºæ•ˆæœ"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šæ¨¡æ‹Ÿæ‰“å­—æœºæ•ˆæœ")
    print("=" * 60)

    import google.generativeai as genai

    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

    print("ğŸ“ æ‰“å­—æœºæ•ˆæœæ¼”ç¤ºï¼š")
    print("-" * 40)
    print()

    model = genai.GenerativeModel(
        "gemini-2.0-flash",
        system_instruction="ä½ æ˜¯ä¸€ä¸ªè®²æ•…äº‹çš„äººï¼Œç”¨ç®€çŸ­æœ‰è¶£çš„æ–¹å¼è®²æ•…äº‹ã€‚",
    )

    response = model.generate_content(
        "è®²ä¸€ä¸ªå…³äºä¸€åªå‹‡æ•¢çš„å°çŒ«çš„50å­—å°æ•…äº‹", stream=True
    )

    # æ·»åŠ å°‘é‡å»¶è¿Ÿå¢å¼ºæ‰“å­—æœºæ•ˆæœ
    for chunk in response:
        if chunk.text:
            for char in chunk.text:
                print(char, end="", flush=True)
                time.sleep(0.02)  # æ¯ä¸ªå­—ç¬¦å»¶è¿Ÿ 20ms

    print("\n")


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    exercises_text = """
ç»ƒä¹  1ï¼šæµ‹é‡é¦–å­—å»¶è¿Ÿ
    ä¿®æ”¹ compare_streaming_modes() å‡½æ•°ï¼Œ
    è®°å½•å¹¶å¯¹æ¯”ä¸åŒæç¤ºè¯é•¿åº¦ä¸‹çš„é¦–å­—å»¶è¿Ÿ (TTFT)ã€‚

ç»ƒä¹  2ï¼šå®ç°æµå¼èŠå¤©æœºå™¨äºº
    åŸºäº stream_with_full_handling() ä¸­çš„ stream_chat å‡½æ•°ï¼Œ
    å®ç°ä¸€ä¸ªäº¤äº’å¼çš„å‘½ä»¤è¡ŒèŠå¤©æœºå™¨äººã€‚

ç»ƒä¹  3ï¼šç»Ÿè®¡æµå¼ Token
    åœ¨æµå¼è¾“å‡ºæ—¶ï¼Œå®æ—¶æ˜¾ç¤ºå·²ç”Ÿæˆçš„ token æ•°é‡ã€‚
    æç¤ºï¼šå¯ä»¥ç®€å•åœ°ç»Ÿè®¡æ”¶åˆ°çš„ chunk æ•°ã€‚

ç»ƒä¹  4ï¼ˆè¿›é˜¶ï¼‰ï¼šå®ç°ä¸­æ–­åŠŸèƒ½
    å®ç°ä¸€ä¸ªå¯ä»¥é€šè¿‡é”®ç›˜ä¸­æ–­ï¼ˆCtrl+Cï¼‰æ¥åœæ­¢ç”Ÿæˆçš„æµå¼å¯¹è¯ã€‚

æ€è€ƒé¢˜ï¼š
    1. æµå¼è¾“å‡ºæ—¶ï¼ŒAPI æ˜¯å¦‚ä½•çŸ¥é“ä½•æ—¶ç»“æŸçš„ï¼Ÿ
    2. Gemini çš„æµå¼ API å’Œ OpenAI æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ
    3. åœ¨ä»€ä¹ˆæƒ…å†µä¸‹ï¼Œéæµå¼å¯èƒ½æ¯”æµå¼æ›´åˆé€‚ï¼Ÿ
    """
    print(exercises_text)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æµå¼å“åº”å¤„ç† (Gemini ç‰ˆæœ¬)")
    print("=" * 60)
    print("âš ï¸ æ³¨æ„ï¼šæœ¬è¯¾ç¨‹ä¼šå¤šæ¬¡è°ƒç”¨ APIï¼Œé¢„ä¼°æ¶ˆè€—çº¦ 1000-2000 tokens")
    print("=" * 60)

    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ è¯·å…ˆé…ç½® GOOGLE_API_KEY ç¯å¢ƒå˜é‡")
        return

    try:
        compare_streaming_modes()
        examine_stream_structure()
        stream_with_full_handling()
        async_streaming_intro()
        typewriter_effect()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        return

    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼")
    print("ä¸‹ä¸€æ­¥ï¼š04-anthropic-claude.pyï¼ˆClaude API ä½¿ç”¨ï¼‰")
    print("=" * 60)


if __name__ == "__main__":
    main()
