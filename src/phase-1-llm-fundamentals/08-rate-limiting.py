"""
é€Ÿç‡é™åˆ¶ä¸å¹¶å‘æ§åˆ¶
==================

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£ API é€Ÿç‡é™åˆ¶çš„æ¦‚å¿µ
    2. æŒæ¡è¯·æ±‚é™é€Ÿçš„å®ç°æ–¹æ³•
    3. å­¦ä¼šä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘
    4. äº†è§£æ‰¹é‡å¤„ç†çš„æœ€ä½³å®è·µ

æ ¸å¿ƒæ¦‚å¿µï¼š
    - Rate Limitingï¼šAPI æä¾›å•†å¯¹è¯·æ±‚é¢‘ç‡çš„é™åˆ¶
    - RPM/TPMï¼šæ¯åˆ†é’Ÿè¯·æ±‚æ•°/Token æ•°
    - ä»¤ç‰Œæ¡¶/æ¼æ¡¶ï¼šå¸¸ç”¨çš„é™é€Ÿç®—æ³•
    - ä¿¡å·é‡ï¼šæ§åˆ¶å¹¶å‘è¯·æ±‚æ•°

å‰ç½®çŸ¥è¯†ï¼š
    - å®Œæˆ 07-error-handling.py
    - äº†è§£ Python asyncio åŸºç¡€

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install openai aiolimiter python-dotenv
"""

import os
import time
import asyncio
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šç†è§£é€Ÿç‡é™åˆ¶ ====================


def understand_rate_limits():
    """ç†è§£ API é€Ÿç‡é™åˆ¶"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šç†è§£é€Ÿç‡é™åˆ¶")
    print("=" * 60)

    print("""
API é€Ÿç‡é™åˆ¶ç±»å‹ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é™åˆ¶ç±»å‹        â”‚ è¯´æ˜                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RPM             â”‚ Requests Per Minute - æ¯åˆ†é’Ÿè¯·æ±‚æ•°        â”‚
â”‚ RPD             â”‚ Requests Per Day - æ¯å¤©è¯·æ±‚æ•°             â”‚
â”‚ TPM             â”‚ Tokens Per Minute - æ¯åˆ†é’Ÿ Token æ•°       â”‚
â”‚ TPD             â”‚ Tokens Per Day - æ¯å¤© Token æ•°            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

OpenAI é€Ÿç‡é™åˆ¶ç¤ºä¾‹ï¼ˆå¯èƒ½å˜åŒ–ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ è´¦æˆ·ç­‰çº§        â”‚ GPT-4     â”‚ GPT-3.5   â”‚ Embedding         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Free Tier       â”‚ 500 RPM   â”‚ 3,500 RPM â”‚ 3,000 RPM         â”‚
â”‚ Tier 1          â”‚ 500 RPM   â”‚ 3,500 RPM â”‚ 3,000 RPM         â”‚
â”‚ Tier 2          â”‚ 5,000 RPM â”‚ 10K RPM   â”‚ 5,000 RPM         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’¡ æŸ¥çœ‹ä½ çš„é™åˆ¶ï¼šhttps://platform.openai.com/account/rate-limits

è¢«é™é€Ÿæ—¶çš„å“åº”ï¼š
- HTTP 429 Too Many Requests
- å“åº”å¤´åŒ…å« Retry-After æˆ– x-ratelimit-* ä¿¡æ¯
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šç®€å•é™é€Ÿå®ç° ====================


def simple_rate_limiter():
    """ç®€å•çš„é™é€Ÿå®ç°"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šç®€å•é™é€Ÿå®ç°")
    print("=" * 60)

    print("""
æœ€ç®€å•çš„é™é€Ÿï¼šåœ¨è¯·æ±‚ä¹‹é—´æ·»åŠ å»¶è¿Ÿ
    """)

    class SimpleRateLimiter:
        """ç®€å•çš„é™é€Ÿå™¨"""

        def __init__(self, requests_per_minute: int):
            self.min_interval = 60.0 / requests_per_minute
            self.last_request_time = 0.0

        def wait(self):
            """ç­‰å¾…ç›´åˆ°å¯ä»¥å‘é€ä¸‹ä¸€ä¸ªè¯·æ±‚"""
            current_time = time.time()
            time_since_last = current_time - self.last_request_time

            if time_since_last < self.min_interval:
                wait_time = self.min_interval - time_since_last
                print(f"   â³ ç­‰å¾… {wait_time:.2f} ç§’...")
                time.sleep(wait_time)

            self.last_request_time = time.time()

    # æ¼”ç¤º
    print("\nğŸ“ æ¼”ç¤ºï¼šé™åˆ¶ä¸º 30 RPMï¼ˆæ¯ 2 ç§’ä¸€ä¸ªè¯·æ±‚ï¼‰")
    print("-" * 40)

    limiter = SimpleRateLimiter(requests_per_minute=30)

    for i in range(3):
        limiter.wait()
        print(f"   è¯·æ±‚ {i + 1} å‘é€äº {time.strftime('%H:%M:%S')}")

    print("""
ä»£ç ç¤ºä¾‹ï¼š
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
limiter = SimpleRateLimiter(requests_per_minute=60)

for prompt in prompts:
    limiter.wait()  # é™é€Ÿç­‰å¾…
    response = client.chat.completions.create(...)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    """)


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šä»¤ç‰Œæ¡¶ç®—æ³• ====================


def token_bucket_implementation():
    """ä»¤ç‰Œæ¡¶ç®—æ³•å®ç°"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šä»¤ç‰Œæ¡¶ç®—æ³•")
    print("=" * 60)

    print("""
ä»¤ç‰Œæ¡¶ç®—æ³•åŸç†ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ä»¤ç‰Œæ¡¶                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  ğŸª™ ğŸª™ ğŸª™ ğŸª™ ğŸª™ ğŸª™ ğŸª™ â† æŒ‰å›ºå®šé€Ÿç‡æ·»åŠ ä»¤ç‰Œ            â”‚  â”‚
â”‚  â”‚  (æ¡¶å®¹é‡é™åˆ¶æœ€å¤§ä»¤ç‰Œæ•°)                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†“                                 â”‚
â”‚                    æ¯æ¬¡è¯·æ±‚æ¶ˆè€—ä¸€ä¸ªä»¤ç‰Œ                    â”‚
â”‚                    æ²¡æœ‰ä»¤ç‰Œæ—¶éœ€è¦ç­‰å¾…                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ä¼˜åŠ¿ï¼š
- æ”¯æŒçªå‘æµé‡ï¼ˆæ¡¶ä¸­æœ‰å¤šä¸ªä»¤ç‰Œæ—¶å¯ä»¥å¿«é€Ÿå‘é€ï¼‰
- é•¿æœŸå¹³å‡é€Ÿç‡ç¨³å®š
    """)

    class TokenBucket:
        """ä»¤ç‰Œæ¡¶é™é€Ÿå™¨"""

        def __init__(self, rate: float, capacity: int):
            """
            Args:
                rate: æ¯ç§’æ·»åŠ çš„ä»¤ç‰Œæ•°
                capacity: æ¡¶çš„æœ€å¤§å®¹é‡
            """
            self.rate = rate
            self.capacity = capacity
            self.tokens = capacity  # åˆå§‹æ»¡æ¡¶
            self.last_refill = time.time()

        def _refill(self):
            """è¡¥å……ä»¤ç‰Œ"""
            now = time.time()
            elapsed = now - self.last_refill
            new_tokens = elapsed * self.rate
            self.tokens = min(self.capacity, self.tokens + new_tokens)
            self.last_refill = now

        def acquire(self, tokens: int = 1) -> float:
            """
            è·å–ä»¤ç‰Œï¼Œè¿”å›éœ€è¦ç­‰å¾…çš„æ—¶é—´

            Returns:
                éœ€è¦ç­‰å¾…çš„ç§’æ•°ï¼ˆ0 è¡¨ç¤ºæ— éœ€ç­‰å¾…ï¼‰
            """
            self._refill()

            if self.tokens >= tokens:
                self.tokens -= tokens
                return 0.0

            # è®¡ç®—éœ€è¦ç­‰å¾…çš„æ—¶é—´
            needed = tokens - self.tokens
            wait_time = needed / self.rate
            return wait_time

        def wait_and_acquire(self, tokens: int = 1):
            """ç­‰å¾…å¹¶è·å–ä»¤ç‰Œ"""
            wait_time = self.acquire(tokens)
            if wait_time > 0:
                time.sleep(wait_time)
                self._refill()
                self.tokens -= tokens

    # æ¼”ç¤º
    print("\nğŸ“ æ¼”ç¤ºï¼šæ¯ç§’ 2 ä¸ªè¯·æ±‚ï¼Œæœ€å¤šçªå‘ 5 ä¸ª")
    print("-" * 40)

    bucket = TokenBucket(rate=2.0, capacity=5)

    for i in range(7):
        wait = bucket.acquire()
        if wait > 0:
            print(f"   è¯·æ±‚ {i + 1}: éœ€è¦ç­‰å¾… {wait:.2f} ç§’")
            time.sleep(wait)
            bucket.tokens -= 1
        else:
            print(f"   è¯·æ±‚ {i + 1}: ç«‹å³å‘é€ âœ“")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šå¹¶å‘æ§åˆ¶ ====================


def concurrency_control():
    """å¹¶å‘æ§åˆ¶"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šå¹¶å‘æ§åˆ¶ï¼ˆä½¿ç”¨ä¿¡å·é‡ï¼‰")
    print("=" * 60)

    print("""
ä½¿ç”¨ä¿¡å·é‡ (Semaphore) é™åˆ¶å¹¶å‘è¯·æ±‚æ•°ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å¹¶å‘é™åˆ¶ = 5                                              â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â” â”Œâ”€â”€â” â”Œâ”€â”€â” â”Œâ”€â”€â” â”Œâ”€â”€â”  â† æœ€å¤š 5 ä¸ªå¹¶å‘è¯·æ±‚            â”‚
â”‚  â”‚1 â”‚ â”‚2 â”‚ â”‚3 â”‚ â”‚4 â”‚ â”‚5 â”‚                                  â”‚
â”‚  â””â”€â”€â”˜ â””â”€â”€â”˜ â””â”€â”€â”˜ â””â”€â”€â”˜ â””â”€â”€â”˜                                  â”‚
â”‚                                                            â”‚
â”‚  ç­‰å¾…é˜Ÿåˆ—: [6] [7] [8] ...  â† è¶…å‡ºçš„è¯·æ±‚éœ€è¦ç­‰å¾…           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å¼‚æ­¥å¹¶å‘ç¤ºä¾‹ï¼š
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import asyncio
from openai import AsyncOpenAI

async def main():
    client = AsyncOpenAI()
    semaphore = asyncio.Semaphore(5)  # æœ€å¤š 5 ä¸ªå¹¶å‘
    
    async def call_with_limit(prompt):
        async with semaphore:  # è·å–ä¿¡å·é‡
            response = await client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content
    
    prompts = ["é—®é¢˜1", "é—®é¢˜2", "é—®é¢˜3", ...]
    tasks = [call_with_limit(p) for p in prompts]
    results = await asyncio.gather(*tasks)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    """)

    # åŒæ­¥æ¼”ç¤º
    print("\nğŸ“ åŒæ­¥ç‰ˆæœ¬æ¼”ç¤ºï¼ˆä½¿ç”¨çº¿ç¨‹ä¿¡å·é‡ï¼‰ï¼š")
    print("-" * 40)

    import threading

    semaphore = threading.Semaphore(2)  # æœ€å¤š 2 ä¸ªå¹¶å‘

    def worker(name):
        print(f"   {name} ç­‰å¾…è·å–ä¿¡å·é‡...")
        with semaphore:
            print(f"   {name} æ­£åœ¨æ‰§è¡Œ")
            time.sleep(1)  # æ¨¡æ‹Ÿ API è°ƒç”¨
            print(f"   {name} å®Œæˆ")

    threads = []
    for i in range(4):
        t = threading.Thread(target=worker, args=(f"è¯·æ±‚{i + 1}",))
        threads.append(t)
        t.start()

    for t in threads:
        t.join()


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šæ‰¹é‡å¤„ç† ====================


def batch_processing():
    """æ‰¹é‡å¤„ç†æœ€ä½³å®è·µ"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šæ‰¹é‡å¤„ç†æœ€ä½³å®è·µ")
    print("=" * 60)

    print("""
æ‰¹é‡å¤„ç†ç­–ç•¥ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. ä½¿ç”¨ asyncio.gather å¹¶å‘å¤„ç†                            â”‚
â”‚ 2. ç»“åˆä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°                                    â”‚
â”‚ 3. æ·»åŠ é‡è¯•æœºåˆ¶å¤„ç†å¤±è´¥                                    â”‚
â”‚ 4. ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºè¿›åº¦                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å®Œæ•´çš„æ‰¹é‡å¤„ç†ç¤ºä¾‹ï¼š
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import asyncio
from openai import AsyncOpenAI
from tqdm.asyncio import tqdm
from tenacity import retry, stop_after_attempt, wait_exponential

async def batch_call_llm(
    prompts: list[str],
    model: str = "gpt-3.5-turbo",
    max_concurrent: int = 5,
    max_retries: int = 3,
) -> list[str]:
    '''æ‰¹é‡è°ƒç”¨ LLM'''
    
    client = AsyncOpenAI()
    semaphore = asyncio.Semaphore(max_concurrent)
    
    @retry(
        stop=stop_after_attempt(max_retries),
        wait=wait_exponential(min=1, max=60)
    )
    async def call_single(prompt: str) -> str:
        async with semaphore:
            response = await client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content
    
    # åˆ›å»ºä»»åŠ¡å¹¶æ˜¾ç¤ºè¿›åº¦
    tasks = [call_single(p) for p in prompts]
    results = []
    
    for coro in tqdm.as_completed(tasks, total=len(tasks)):
        result = await coro
        results.append(result)
    
    return results

# ä½¿ç”¨
prompts = ["é—®é¢˜1", "é—®é¢˜2", ..., "é—®é¢˜100"]
results = asyncio.run(batch_call_llm(prompts, max_concurrent=10))
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ’¡ å°è´´å£«ï¼š
- æ ¹æ® API é™åˆ¶è®¾ç½®åˆç†çš„å¹¶å‘æ•°
- å¯¹äº GPT-3.5ï¼Œé€šå¸¸å¯ä»¥è®¾ç½® 10-20 å¹¶å‘
- å¯¹äº GPT-4ï¼Œå»ºè®® 5-10 å¹¶å‘
- æ³¨æ„ç›‘æ§é”™è¯¯ç‡ï¼ŒåŠ¨æ€è°ƒæ•´å¹¶å‘æ•°
    """)


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šä½¿ç”¨ aiolimiter ====================


def aiolimiter_usage():
    """ä½¿ç”¨ aiolimiter åº“"""
    print("\n" + "=" * 60)
    print("ç¬¬å…­éƒ¨åˆ†ï¼šä½¿ç”¨ aiolimiter åº“")
    print("=" * 60)

    print("""
aiolimiter æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºå¼‚æ­¥é™é€Ÿçš„åº“ï¼š

å®‰è£…ï¼špip install aiolimiter

ä½¿ç”¨ç¤ºä¾‹ï¼š
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from aiolimiter import AsyncLimiter
import asyncio

# æ¯ç§’æœ€å¤š 10 ä¸ªè¯·æ±‚
rate_limiter = AsyncLimiter(10, 1)  # (max_rate, time_period)

async def call_api():
    async with rate_limiter:
        # è¿™é‡Œçš„è°ƒç”¨ä¼šè¢«é™é€Ÿ
        response = await client.chat.completions.create(...)
        return response

# æ‰¹é‡è°ƒç”¨æ—¶è‡ªåŠ¨é™é€Ÿ
async def main():
    tasks = [call_api() for _ in range(100)]
    results = await asyncio.gather(*tasks)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ç»„åˆä½¿ç”¨é™é€Ÿå’Œå¹¶å‘æ§åˆ¶ï¼š
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from aiolimiter import AsyncLimiter
import asyncio

rate_limiter = AsyncLimiter(60, 60)  # 60 RPM
semaphore = asyncio.Semaphore(10)    # æœ€å¤š 10 å¹¶å‘

async def call_with_limits():
    async with semaphore:            # é™åˆ¶å¹¶å‘
        async with rate_limiter:     # é™åˆ¶é€Ÿç‡
            response = await client.chat.completions.create(...)
            return response
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    """)


# ==================== ç¬¬ä¸ƒéƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    exercises_text = """
ç»ƒä¹  1ï¼šå®ç°ä»¤ç‰Œæ¡¶é™é€Ÿå™¨
    å®Œå–„ TokenBucket ç±»ï¼Œæ·»åŠ ï¼š
    - å¼‚æ­¥ç‰ˆæœ¬ (async wait_and_acquire)
    - æ”¯æŒ Token çº§åˆ«çš„é™é€Ÿï¼ˆTPMï¼‰

ç»ƒä¹  2ï¼šæ‰¹é‡ç¿»è¯‘ä»»åŠ¡
    å®ç°ä¸€ä¸ªæ‰¹é‡ç¿»è¯‘å‡½æ•°ï¼Œå¤„ç† 100 ä¸ªå¥å­ï¼š
    - å¹¶å‘é™åˆ¶ 10
    - é€Ÿç‡é™åˆ¶ 60 RPM
    - å¤±è´¥é‡è¯• 3 æ¬¡
    - æ˜¾ç¤ºè¿›åº¦æ¡

ç»ƒä¹  3ï¼šè‡ªé€‚åº”é™é€Ÿ
    å®ç°ä¸€ä¸ªè‡ªé€‚åº”é™é€Ÿå™¨ï¼š
    - æ­£å¸¸æƒ…å†µä¸‹ä½¿ç”¨é»˜è®¤é€Ÿç‡
    - æ”¶åˆ° 429 åè‡ªåŠ¨é™ä½é€Ÿç‡
    - ä¸€æ®µæ—¶é—´æ— é”™è¯¯åé€æ¸æ¢å¤

ç»ƒä¹  4ï¼šå¤š API è´Ÿè½½å‡è¡¡
    åˆ›å»ºä¸€ä¸ªæœåŠ¡ï¼Œåœ¨å¤šä¸ª API Key ä¹‹é—´è½®æ¢ï¼š
    - æ¯ä¸ª Key æœ‰ç‹¬ç«‹çš„é™é€Ÿ
    - æŸä¸ª Key è¾¾åˆ°é™åˆ¶æ—¶åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª

æ€è€ƒé¢˜ï¼š
    1. ä¸ºä»€ä¹ˆéœ€è¦åŒæ—¶ä½¿ç”¨ä¿¡å·é‡å’Œé™é€Ÿå™¨ï¼Ÿ
    2. ä»¤ç‰Œæ¡¶å’Œæ¼æ¡¶ç®—æ³•çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ
    3. å¦‚ä½•ä¼°ç®—ä¸€ä¸ªæ‰¹é‡ä»»åŠ¡éœ€è¦çš„æ—¶é—´ï¼Ÿ
    """
    print(exercises_text)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ é€Ÿç‡é™åˆ¶ä¸å¹¶å‘æ§åˆ¶")
    print("=" * 60)
    print("ğŸ’¡ æœ¬è¯¾ç¨‹ä»‹ç»å¦‚ä½•ä¼˜é›…åœ°å¤„ç† API é€Ÿç‡é™åˆ¶")
    print("=" * 60)

    try:
        understand_rate_limits()
        simple_rate_limiter()
        token_bucket_implementation()
        concurrency_control()
        batch_processing()
        aiolimiter_usage()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        return

    print("\n" + "=" * 60)
    print("âœ… Phase 1 å…¨éƒ¨è¯¾ç¨‹å®Œæˆï¼")
    print("=" * 60)
    print("""
ğŸ‰ æ­å–œï¼ä½ å·²å®Œæˆ Phase 1 çš„æ‰€æœ‰è¯¾ç¨‹ï¼š
   
   âœ… 01-openai-api-basics.py      - API åŸºç¡€
   âœ… 02-openai-parameters.py      - å‚æ•°è¯¦è§£
   âœ… 03-streaming-responses.py    - æµå¼å“åº”
   âœ… 04-anthropic-claude.py       - Claude API
   âœ… 05-google-gemini.py          - Gemini API
   âœ… 06-local-llm-ollama.py       - æœ¬åœ°éƒ¨ç½²
   âœ… 07-error-handling.py         - é”™è¯¯å¤„ç†
   âœ… 08-rate-limiting.py          - é€Ÿç‡é™åˆ¶

ğŸ“Œ ä¸‹ä¸€æ­¥ï¼šPhase 2 - æç¤ºå·¥ç¨‹ (Prompt Engineering)
    """)
    print("=" * 60)


if __name__ == "__main__":
    main()
