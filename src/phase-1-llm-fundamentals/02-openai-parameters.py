"""
OpenAI API å‚æ•°è¯¦è§£
==================

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£ temperature å‚æ•°å¯¹è¾“å‡ºçš„å½±å“
    2. æŒæ¡ top_p æ ¸é‡‡æ ·çš„åŸç†
    3. å­¦ä¼šä½¿ç”¨ max_tokens æ§åˆ¶è¾“å‡ºé•¿åº¦
    4. äº†è§£ frequency_penalty å’Œ presence_penalty

æ ¸å¿ƒæ¦‚å¿µï¼š
    - Temperatureï¼šæ§åˆ¶è¾“å‡ºçš„éšæœºæ€§/åˆ›é€ æ€§
    - Top_pï¼šæ ¸é‡‡æ ·ï¼Œå¦ä¸€ç§æ§åˆ¶éšæœºæ€§çš„æ–¹å¼
    - Max_tokensï¼šé™åˆ¶è¾“å‡ºçš„æœ€å¤§ token æ•°
    - Penalty å‚æ•°ï¼šæ§åˆ¶è¯æ±‡é‡å¤

å‰ç½®çŸ¥è¯†ï¼š
    - å®Œæˆ 01-openai-api-basics.py

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install openai python-dotenv
"""

import os
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šTemperature å‚æ•° ====================


def explore_temperature():
    """æ¢ç´¢ temperature å‚æ•°çš„å½±å“"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šTemperature å‚æ•°")
    print("=" * 60)

    client = OpenAI()

    print("""
Temperature å‚æ•°è¯´æ˜ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å€¼             â”‚ æ•ˆæœ                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0.0            â”‚ ç¡®å®šæ€§è¾“å‡ºï¼Œæ¯æ¬¡ç»“æœç›¸åŒ             â”‚
â”‚ 0.5 - 0.7      â”‚ å¹³è¡¡åˆ›é€ æ€§å’Œä¸€è‡´æ€§ï¼ˆæ¨èé»˜è®¤å€¼ï¼‰     â”‚
â”‚ 1.0            â”‚ æ›´å…·åˆ›é€ æ€§ï¼Œè¾“å‡ºå¤šæ ·                 â”‚
â”‚ 1.5 - 2.0      â”‚ é«˜åº¦éšæœºï¼Œå¯èƒ½ä¸è¿è´¯                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)

    prompt = "ç”¨ä¸€ä¸ªè¯æè¿°å¤ªé˜³"
    temperatures = [0.0, 0.5, 1.0, 1.5]

    print(f"ğŸ“ æµ‹è¯•æç¤ºè¯: '{prompt}'")
    print("-" * 40)

    for temp in temperatures:
        print(f"\nğŸŒ¡ï¸ Temperature = {temp}")

        # åŒä¸€ä¸ª temperature è°ƒç”¨ 3 æ¬¡ï¼Œè§‚å¯Ÿä¸€è‡´æ€§
        results = []
        for i in range(3):
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=temp,
                max_tokens=20,
            )
            results.append(response.choices[0].message.content.strip())

        for i, result in enumerate(results, 1):
            print(f"   ç¬¬{i}æ¬¡: {result}")

    print("\nğŸ’¡ è§‚å¯Ÿï¼štemperature=0 æ—¶ï¼Œè¾“å‡ºå®Œå…¨ä¸€è‡´ï¼›å€¼è¶Šé«˜ï¼Œå˜åŒ–è¶Šå¤§")


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šTop_p æ ¸é‡‡æ · ====================


def explore_top_p():
    """æ¢ç´¢ top_p å‚æ•°"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šTop_p æ ¸é‡‡æ ·")
    print("=" * 60)

    client = OpenAI()

    print("""
Top_p å‚æ•°è¯´æ˜ï¼š
- ä¹Ÿç§°ä¸º"æ ¸é‡‡æ ·"(nucleus sampling)
- æ§åˆ¶ä»æ¦‚ç‡æœ€é«˜çš„ tokens ä¸­é‡‡æ ·
- top_p=0.1: åªä»ç´¯è®¡æ¦‚ç‡å‰ 10% çš„ tokens é‡‡æ ·
- top_p=1.0: è€ƒè™‘æ‰€æœ‰ tokens

âš ï¸ æ³¨æ„ï¼šä¸€èˆ¬åªè°ƒæ•´ temperature æˆ– top_p å…¶ä¸­ä¹‹ä¸€
    """)

    prompt = "å†™ä¸€ä¸ªå…³äºæœˆäº®çš„çŸ­å¥"
    top_p_values = [0.1, 0.5, 0.9]

    print(f"ğŸ“ æµ‹è¯•æç¤ºè¯: '{prompt}'")
    print("-" * 40)

    for top_p in top_p_values:
        print(f"\nğŸ¯ Top_p = {top_p}")

        for i in range(2):
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=1.0,  # å›ºå®š temperature
                top_p=top_p,
                max_tokens=30,
            )
            print(f"   ç¬¬{i + 1}æ¬¡: {response.choices[0].message.content.strip()}")

    print("\nğŸ’¡ top_p è¶Šå°ï¼Œè¾“å‡ºè¶Šä¿å®ˆï¼›è¶Šå¤§ï¼Œè¶Šå¤šæ ·")


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šMax_tokens å‚æ•° ====================


def explore_max_tokens():
    """æ¢ç´¢ max_tokens å‚æ•°"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šMax_tokens å‚æ•°")
    print("=" * 60)

    client = OpenAI()

    print("""
Max_tokens å‚æ•°è¯´æ˜ï¼š
- é™åˆ¶ AI å›å¤çš„æœ€å¤§ token æ•°
- å¦‚æœå›å¤è¢«æˆªæ–­ï¼Œfinish_reason ä¼šæ˜¯ 'length'
- 1 ä¸ªä¸­æ–‡å­—ç¬¦çº¦ 1-2 tokens
- 1 ä¸ªè‹±æ–‡å•è¯çº¦ 1-2 tokens
    """)

    prompt = "è¯·è¯¦ç»†è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼ŒåŒ…æ‹¬å…¶å†å²ã€åº”ç”¨å’Œæœªæ¥å‘å±•ã€‚"
    max_tokens_values = [20, 50, 200]

    print(f"ğŸ“ æµ‹è¯•æç¤ºè¯: '{prompt}'")
    print("-" * 40)

    for max_tokens in max_tokens_values:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=max_tokens,
        )

        content = response.choices[0].message.content
        finish_reason = response.choices[0].finish_reason

        print(f"\nğŸ“ Max_tokens = {max_tokens}")
        print(f"   å›å¤: {content[:100]}{'...' if len(content) > 100 else ''}")
        print(f"   å®é™… tokens: {response.usage.completion_tokens}")
        print(f"   ç»“æŸåŸå› : {finish_reason}")

        if finish_reason == "length":
            print("   âš ï¸ å›å¤è¢«æˆªæ–­!")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šPenalty å‚æ•° ====================


def explore_penalty_params():
    """æ¢ç´¢ frequency_penalty å’Œ presence_penalty"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šPenalty å‚æ•°")
    print("=" * 60)

    client = OpenAI()

    print("""
Penalty å‚æ•°è¯´æ˜ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å‚æ•°               â”‚ ä½œç”¨                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ frequency_penalty  â”‚ é™ä½é‡å¤å‡ºç°çš„è¯çš„æ¦‚ç‡               â”‚
â”‚                    â”‚ å€¼è¶Šé«˜ï¼Œè¶Šä¸å®¹æ˜“é‡å¤ç›¸åŒçš„è¯         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ presence_penalty   â”‚ é¼“åŠ±æ¨¡å‹è°ˆè®ºæ–°è¯é¢˜                   â”‚
â”‚                    â”‚ å€¼è¶Šé«˜ï¼Œè¶Šå€¾å‘ä½¿ç”¨æ–°è¯æ±‡             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å–å€¼èŒƒå›´ï¼š-2.0 åˆ° 2.0
    """)

    prompt = "åˆ—å‡º 10 ç§ä½ å–œæ¬¢çš„é¢œè‰²"

    configs = [
        {"frequency_penalty": 0.0, "presence_penalty": 0.0, "desc": "é»˜è®¤ (æ— æƒ©ç½š)"},
        {"frequency_penalty": 2.0, "presence_penalty": 0.0, "desc": "é«˜é¢‘ç‡æƒ©ç½š"},
        {"frequency_penalty": 0.0, "presence_penalty": 2.0, "desc": "é«˜å­˜åœ¨æƒ©ç½š"},
    ]

    print(f"ğŸ“ æµ‹è¯•æç¤ºè¯: '{prompt}'")
    print("-" * 40)

    for config in configs:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            frequency_penalty=config["frequency_penalty"],
            presence_penalty=config["presence_penalty"],
        )

        print(f"\nğŸ”§ {config['desc']}")
        print(
            f"   frequency_penalty={config['frequency_penalty']}, presence_penalty={config['presence_penalty']}"
        )
        print(f"   å›å¤: {response.choices[0].message.content}")


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šå‚æ•°ç»„åˆå»ºè®® ====================


def parameter_recommendations():
    """ä¸åŒåœºæ™¯ä¸‹çš„å‚æ•°ç»„åˆå»ºè®®"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šå‚æ•°ç»„åˆå»ºè®®")
    print("=" * 60)

    print("""
ğŸ“‹ ä¸åŒåœºæ™¯æ¨èå‚æ•°ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ åœºæ™¯             â”‚ temperature â”‚ top_p  â”‚ è¯´æ˜                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ä»£ç ç”Ÿæˆ         â”‚ 0.0 - 0.2   â”‚ 1.0    â”‚ éœ€è¦ç²¾ç¡®æ€§          â”‚
â”‚ æ•°æ®æå–/è§£æ    â”‚ 0.0         â”‚ 1.0    â”‚ éœ€è¦ç¡®å®šæ€§ç»“æœ      â”‚
â”‚ ç¿»è¯‘             â”‚ 0.2 - 0.4   â”‚ 1.0    â”‚ ä¿æŒå‡†ç¡®ä½†æœ‰çµæ´»    â”‚
â”‚ å®¢æœå¯¹è¯         â”‚ 0.5 - 0.7   â”‚ 1.0    â”‚ è‡ªç„¶ä½†å¯æ§          â”‚
â”‚ åˆ›æ„å†™ä½œ         â”‚ 0.8 - 1.2   â”‚ 0.9    â”‚ éœ€è¦å¤šæ ·æ€§          â”‚
â”‚ å¤´è„‘é£æš´         â”‚ 1.0 - 1.5   â”‚ 0.8    â”‚ æœ€å¤§åˆ›é€ æ€§          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’¡ å°è´´å£«ï¼š
1. å…ˆä»é»˜è®¤å€¼å¼€å§‹ï¼ˆtemperature=1.0, top_p=1.0ï¼‰
2. æ ¹æ®éœ€è¦è°ƒæ•´ä¸€ä¸ªå‚æ•°ï¼Œä¸è¦åŒæ—¶è°ƒæ•´å¤šä¸ª
3. ä»£ç å’Œæ•°æ®ä»»åŠ¡ç”¨ä½ temperature
4. åˆ›æ„ä»»åŠ¡å¯ä»¥æé«˜ temperature
5. ä½¿ç”¨ max_tokens é˜²æ­¢è¾“å‡ºè¿‡é•¿
    """)


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    exercises_text = """
ç»ƒä¹  1ï¼šå‚æ•°å¯¹æ¯”å®éªŒ
    é€‰æ‹©ä¸€ä¸ªä»»åŠ¡ï¼ˆå¦‚å†™è¯—ã€å†™ä»£ç ã€å›ç­”é—®é¢˜ï¼‰ï¼Œ
    åˆ†åˆ«ä½¿ç”¨ä¸åŒçš„ temperature å€¼ï¼ˆ0, 0.5, 1.0, 1.5ï¼‰ï¼Œ
    è®°å½•è¾“å‡ºè´¨é‡å’Œä¸€è‡´æ€§çš„å˜åŒ–ã€‚

ç»ƒä¹  2ï¼šæ‰¾åˆ°æœ€ä½³å‚æ•°
    å‡è®¾ä½ è¦æ„å»ºä¸€ä¸ªä»£ç ç”ŸæˆåŠ©æ‰‹ï¼Œ
    å®éªŒæ‰¾å‡ºæœ€é€‚åˆç”Ÿæˆ Python ä»£ç çš„å‚æ•°ç»„åˆã€‚

ç»ƒä¹  3ï¼šé¿å…é‡å¤
    è®© AI å†™ä¸€ç¯‡ 200 å­—çš„æ•…äº‹ï¼Œ
    ä½¿ç”¨ frequency_penalty å‡å°‘è¯æ±‡é‡å¤ã€‚

æ€è€ƒé¢˜ï¼š
    1. ä¸ºä»€ä¹ˆ temperature=0 æ—¶ä»ç„¶å«"é‡‡æ ·"ï¼Ÿå®ƒå’Œ argmax æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ
    2. åœ¨ä»€ä¹ˆæƒ…å†µä¸‹ï¼Œä½ ä¼šé€‰æ‹©è°ƒæ•´ top_p è€Œä¸æ˜¯ temperatureï¼Ÿ
    """
    print(exercises_text)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ OpenAI API å‚æ•°è¯¦è§£")
    print("=" * 60)
    print("âš ï¸ æ³¨æ„ï¼šæœ¬è¯¾ç¨‹å°†å¤šæ¬¡è°ƒç”¨ APIï¼Œé¢„ä¼°æ¶ˆè€—çº¦ 2000-3000 tokens")
    print("=" * 60)

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ è¯·å…ˆé…ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        return

    try:
        explore_temperature()
        explore_top_p()
        explore_max_tokens()
        explore_penalty_params()
        parameter_recommendations()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        return

    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼")
    print("ä¸‹ä¸€æ­¥ï¼š03-streaming-responses.pyï¼ˆæµå¼å“åº”ï¼‰")
    print("=" * 60)


if __name__ == "__main__":
    main()
