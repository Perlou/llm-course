"""
LLM API åŸºç¡€ (Gemini ç‰ˆæœ¬)
===========================

å­¦ä¹ ç›®æ ‡ï¼š
    1. äº†è§£ LLM API çš„åŸºæœ¬ç»“æ„
    2. æŒæ¡ Google Gemini API çš„ä½¿ç”¨æ–¹æ³•
    3. ç†è§£æ¶ˆæ¯è§’è‰²ï¼ˆsystemã€userã€assistantï¼‰çš„ä½œç”¨
    4. å­¦ä¼šæ„å»ºå¤šè½®å¯¹è¯

æ ¸å¿ƒæ¦‚å¿µï¼š
    - Gemini APIï¼šGoogle çš„å¤šæ¨¡æ€ AI æ¥å£
    - Messagesï¼šæ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«è§’è‰²å’Œå†…å®¹
    - Responseï¼šAPI è¿”å›çš„å“åº”ç»“æ„

å‰ç½®çŸ¥è¯†ï¼š
    - Python åŸºç¡€
    - å·²é…ç½® GOOGLE_API_KEY ç¯å¢ƒå˜é‡

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install google-generativeai python-dotenv
    - é…ç½® GOOGLE_API_KEY
"""

import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šç¯å¢ƒæ£€æŸ¥ ====================


def check_environment():
    """æ£€æŸ¥ API Key æ˜¯å¦é…ç½®"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šç¯å¢ƒæ£€æŸ¥")
    print("=" * 60)

    api_key = os.getenv("GOOGLE_API_KEY")

    if not api_key:
        print("âŒ é”™è¯¯ï¼šæœªè®¾ç½® GOOGLE_API_KEY ç¯å¢ƒå˜é‡")
        print("\nè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤é…ç½®ï¼š")
        print("1. å¤åˆ¶ .env.example ä¸º .env")
        print("2. åœ¨ .env ä¸­å¡«å…¥ä½ çš„ Google API Key")
        print("3. è·å–åœ°å€ï¼šhttps://aistudio.google.com/apikey")
        print("4. é‡æ–°è¿è¡Œæ­¤è„šæœ¬")
        return False

    # ä»…æ˜¾ç¤ºå‰å‡ ä½ï¼Œä¿æŠ¤éšç§
    masked_key = api_key[:8] + "..." + api_key[-4:]
    print(f"âœ… Google API Key å·²é…ç½®: {masked_key}")
    return True


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€ API è°ƒç”¨ ====================


def basic_api_call():
    """æœ€ç®€å•çš„ API è°ƒç”¨ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€ API è°ƒç”¨")
    print("=" * 60)

    import google.generativeai as genai

    # é…ç½® API Key
    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    model = genai.GenerativeModel("gemini-2.0-flash")

    print("\nğŸ“¤ å‘é€è¯·æ±‚...")
    print("æ¶ˆæ¯: 'ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚'")

    # æœ€ç®€å•çš„ API è°ƒç”¨
    response = model.generate_content("ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚")

    # è·å–å›å¤å†…å®¹
    reply = response.text

    print(f"\nğŸ“¥ æ”¶åˆ°å›å¤:")
    print(f"   {reply}")

    # æ˜¾ç¤º token ä½¿ç”¨æƒ…å†µ
    if hasattr(response, "usage_metadata"):
        print(f"\nğŸ“Š Token ä½¿ç”¨æƒ…å†µ:")
        print(f"   è¾“å…¥ tokens: {response.usage_metadata.prompt_token_count}")
        print(f"   è¾“å‡º tokens: {response.usage_metadata.candidates_token_count}")
        print(f"   æ€»è®¡ tokens: {response.usage_metadata.total_token_count}")

    return response


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šç†è§£æ¶ˆæ¯è§’è‰² ====================


def understand_message_roles():
    """ç†è§£ systemã€user è§’è‰²çš„ä½œç”¨"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šç†è§£æ¶ˆæ¯è§’è‰²")
    print("=" * 60)

    import google.generativeai as genai

    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

    print("""
æ¶ˆæ¯è§’è‰²è¯´æ˜ï¼ˆGemini ç‰ˆæœ¬ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ è§’è‰²            â”‚ ä½œç”¨                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ system_instruction â”‚ è®¾å®š AI çš„è§’è‰²ã€æ€§æ ¼å’Œè¡Œä¸ºè§„åˆ™  â”‚
â”‚ user            â”‚ ç”¨æˆ·çš„è¾“å…¥                         â”‚
â”‚ model           â”‚ AI çš„å†å²å›å¤ï¼ˆç”¨äºå¤šè½®å¯¹è¯ï¼‰      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)

    # ç¤ºä¾‹ï¼šä½¿ç”¨ system_instruction è®¾å®š AI èº«ä»½
    print("\nğŸ“Œ ç¤ºä¾‹ï¼šä½¿ç”¨ system_instruction è®¾å®š AI ä¸ºç¿»è¯‘å®˜")

    # Gemini åœ¨åˆ›å»ºæ¨¡å‹æ—¶è®¾ç½®ç³»ç»ŸæŒ‡ä»¤
    model = genai.GenerativeModel(
        "gemini-2.0-flash",
        system_instruction="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­è‹±ç¿»è¯‘å®˜ã€‚ç”¨æˆ·è¾“å…¥ä¸­æ–‡æ—¶ç¿»è¯‘æˆè‹±æ–‡ï¼Œè¾“å…¥è‹±æ–‡æ—¶ç¿»è¯‘æˆä¸­æ–‡ã€‚åªè¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦è§£é‡Šã€‚",
    )

    response = model.generate_content("ä»Šå¤©å¤©æ°”å¾ˆå¥½")

    print(f"   è¾“å…¥: ä»Šå¤©å¤©æ°”å¾ˆå¥½")
    print(f"   ç¿»è¯‘: {response.text}")

    # å¯¹æ¯”ï¼šä¸ä½¿ç”¨ system_instruction
    print("\nğŸ“Œ å¯¹æ¯”ï¼šä¸ä½¿ç”¨ system_instruction çš„æƒ…å†µ")

    model2 = genai.GenerativeModel("gemini-2.0-flash")
    response2 = model2.generate_content("ä»Šå¤©å¤©æ°”å¾ˆå¥½")

    print(f"   è¾“å…¥: ä»Šå¤©å¤©æ°”å¾ˆå¥½")
    print(f"   å›å¤: {response2.text}")

    print("\nğŸ’¡ ç»“è®ºï¼šsystem_instruction å¯ä»¥æœ‰æ•ˆåœ°æ§åˆ¶ AI çš„è¡Œä¸ºæ¨¡å¼")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šå¤šè½®å¯¹è¯ ====================


def multi_turn_conversation():
    """å®ç°å¤šè½®å¯¹è¯"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šå¤šè½®å¯¹è¯")
    print("=" * 60)

    import google.generativeai as genai

    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

    print("""
å¤šè½®å¯¹è¯åŸç†ï¼š
- Gemini ä½¿ç”¨ start_chat() åˆ›å»ºå¯¹è¯ä¼šè¯
- ä¼šè¯ä¼šè‡ªåŠ¨ç»´æŠ¤å¯¹è¯å†å²
- æ— éœ€æ‰‹åŠ¨ç®¡ç†æ¶ˆæ¯åˆ—è¡¨
    """)

    # åˆ›å»ºæ¨¡å‹å’Œå¯¹è¯
    model = genai.GenerativeModel(
        "gemini-2.0-flash", system_instruction="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ï¼Œå›ç­”ç®€æ´æ˜äº†ã€‚"
    )
    chat = model.start_chat(history=[])

    # æ¨¡æ‹Ÿå¤šè½®å¯¹è¯
    conversations = ["æˆ‘å«å°æ˜", "æˆ‘å–œæ¬¢ç¼–ç¨‹", "ä½ è¿˜è®°å¾—æˆ‘å«ä»€ä¹ˆåå­—å—ï¼Ÿ"]

    print("ğŸ“ å¤šè½®å¯¹è¯æ¼”ç¤ºï¼š")
    print("-" * 40)

    for user_input in conversations:
        response = chat.send_message(user_input)
        print(f"\nğŸ‘¤ ç”¨æˆ·: {user_input}")
        print(f"ğŸ¤– åŠ©æ‰‹: {response.text}")

    print("\n" + "-" * 40)
    print(f"ğŸ“Š å¯¹è¯å†å²å…±æœ‰ {len(chat.history)} æ¡æ¶ˆæ¯")
    print("ğŸ’¡ Gemini çš„ chat å¯¹è±¡ä¼šè‡ªåŠ¨ç®¡ç†å¯¹è¯å†å²")


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šå“åº”ç»“æ„è§£æ ====================


def parse_response_structure():
    """è¯¦ç»†è§£æ API å“åº”ç»“æ„"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šå“åº”ç»“æ„è§£æ")
    print("=" * 60)

    import google.generativeai as genai

    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

    model = genai.GenerativeModel("gemini-2.0-flash")
    response = model.generate_content("è¯´ hello")

    print("\nğŸ“¦ Gemini å“åº”ç»“æ„ï¼š")
    print(f"""
response.text            = {response.text}
response.candidates      = å€™é€‰å›å¤åˆ—è¡¨

response.candidates[0]:
  .content.parts[0].text = {response.candidates[0].content.parts[0].text}
  .finish_reason         = {response.candidates[0].finish_reason}
  .safety_ratings        = å®‰å…¨è¯„åˆ†åˆ—è¡¨

response.usage_metadata:
  .prompt_token_count    = {response.usage_metadata.prompt_token_count if hasattr(response, "usage_metadata") else "N/A"}
  .candidates_token_count = {response.usage_metadata.candidates_token_count if hasattr(response, "usage_metadata") else "N/A"}
    """)

    print("ğŸ’¡ finish_reason è¯´æ˜ï¼š")
    print("   - 'STOP': æ­£å¸¸å®Œæˆ")
    print("   - 'MAX_TOKENS': è¾¾åˆ° token é™åˆ¶")
    print("   - 'SAFETY': è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢")


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    exercises_text = """
ç»ƒä¹  1ï¼šä¿®æ”¹ system_instruction
    å°è¯•å°† AI è®¾å®šä¸ºä¸åŒçš„è§’è‰²ï¼ˆå¦‚ï¼šè¯—äººã€ç¨‹åºå‘˜ã€å¨å¸ˆï¼‰ï¼Œ
    è§‚å¯Ÿç›¸åŒé—®é¢˜ä¸‹å›å¤çš„å·®å¼‚ã€‚

ç»ƒä¹  2ï¼šå®ç°ä¸€ä¸ªç®€å•çš„å‘½ä»¤è¡ŒèŠå¤©æœºå™¨äºº
    ä½¿ç”¨ while å¾ªç¯å’Œ input() å®ç°çœŸæ­£çš„äº¤äº’å¼å¯¹è¯ã€‚
    æç¤ºï¼šå‚è€ƒ multi_turn_conversation() çš„å®ç°ã€‚

ç»ƒä¹  3ï¼šå¯¹æ¯” OpenAI å’Œ Gemini çš„å·®å¼‚
    å¦‚æœæœ‰ OpenAI API Keyï¼Œå¯¹æ¯”ä¸¤è€…çš„ï¼š
    - API è°ƒç”¨æ–¹å¼
    - å“åº”æ ¼å¼
    - é€Ÿåº¦å’Œè´¨é‡

æ€è€ƒé¢˜ï¼š
    1. Gemini çš„ chat å¯¹è±¡è‡ªåŠ¨ç®¡ç†å†å²ï¼Œè¿™ä¸æ‰‹åŠ¨ç®¡ç†ç›¸æ¯”æœ‰ä»€ä¹ˆä¼˜ç¼ºç‚¹ï¼Ÿ
    2. system_instruction å’Œ chat history ä¸­çš„ system æ¶ˆæ¯æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ
    """
    print(exercises_text)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•° - æŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰éƒ¨åˆ†"""
    print("ğŸš€ LLM API åŸºç¡€è¯¾ç¨‹ (Gemini ç‰ˆæœ¬)")
    print("=" * 60)
    print("ğŸ’¡ æœ¬è¯¾ç¨‹ä½¿ç”¨ Google Gemini APIï¼ˆå…è´¹é¢åº¦è¾ƒå¤šï¼‰")
    print("é¢„ä¼°æ¶ˆè€—ï¼šçº¦ 500-1000 tokens")
    print("=" * 60)

    # æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        return

    # æŒ‰é¡ºåºæ‰§è¡Œå„éƒ¨åˆ†
    try:
        basic_api_call()
        understand_message_roles()
        multi_turn_conversation()
        parse_response_structure()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œ API Key æ˜¯å¦æ­£ç¡®")
        return

    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼")
    print("ä¸‹ä¸€æ­¥ï¼š02-openai-parameters.pyï¼ˆAPI å‚æ•°è¯¦è§£ï¼‰")
    print("=" * 60)


if __name__ == "__main__":
    main()
