"""
OpenAI API åŸºç¡€
===============

å­¦ä¹ ç›®æ ‡ï¼š
    1. äº†è§£ OpenAI API çš„åŸºæœ¬ç»“æ„
    2. æŒæ¡ Chat Completions API çš„ä½¿ç”¨æ–¹æ³•
    3. ç†è§£æ¶ˆæ¯è§’è‰²ï¼ˆsystemã€userã€assistantï¼‰çš„ä½œç”¨
    4. å­¦ä¼šæ„å»ºå¤šè½®å¯¹è¯

æ ¸å¿ƒæ¦‚å¿µï¼š
    - Chat Completions APIï¼šOpenAI çš„å¯¹è¯æ¥å£
    - Messagesï¼šæ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«è§’è‰²å’Œå†…å®¹
    - Responseï¼šAPI è¿”å›çš„å“åº”ç»“æ„

å‰ç½®çŸ¥è¯†ï¼š
    - Python åŸºç¡€
    - å·²é…ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install openai python-dotenv
    - é…ç½® OPENAI_API_KEY
"""

import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šç¯å¢ƒæ£€æŸ¥ ====================

def check_environment():
    """æ£€æŸ¥ API Key æ˜¯å¦é…ç½®"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šç¯å¢ƒæ£€æŸ¥")
    print("=" * 60)
    
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        print("âŒ é”™è¯¯ï¼šæœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        print("\nè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤é…ç½®ï¼š")
        print("1. å¤åˆ¶ .env.example ä¸º .env")
        print("2. åœ¨ .env ä¸­å¡«å…¥ä½ çš„ API Key")
        print("3. é‡æ–°è¿è¡Œæ­¤è„šæœ¬")
        return False
    
    # ä»…æ˜¾ç¤ºå‰å‡ ä½ï¼Œä¿æŠ¤éšç§
    masked_key = api_key[:8] + "..." + api_key[-4:]
    print(f"âœ… API Key å·²é…ç½®: {masked_key}")
    return True


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€ API è°ƒç”¨ ====================

def basic_api_call():
    """æœ€ç®€å•çš„ API è°ƒç”¨ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€ API è°ƒç”¨")
    print("=" * 60)
    
    from openai import OpenAI
    
    # åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆè‡ªåŠ¨è¯»å– OPENAI_API_KEY ç¯å¢ƒå˜é‡ï¼‰
    client = OpenAI()
    
    print("\nğŸ“¤ å‘é€è¯·æ±‚...")
    print("æ¶ˆæ¯: 'ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚'")
    
    # æœ€ç®€å•çš„ API è°ƒç”¨
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",  # ä½¿ç”¨è¾ƒä¾¿å®œçš„æ¨¡å‹è¿›è¡Œæµ‹è¯•
        messages=[
            {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"}
        ]
    )
    
    # è·å–å›å¤å†…å®¹
    reply = response.choices[0].message.content
    
    print(f"\nğŸ“¥ æ”¶åˆ°å›å¤:")
    print(f"   {reply}")
    
    # æ˜¾ç¤º token ä½¿ç”¨æƒ…å†µ
    print(f"\nğŸ“Š Token ä½¿ç”¨æƒ…å†µ:")
    print(f"   è¾“å…¥ tokens: {response.usage.prompt_tokens}")
    print(f"   è¾“å‡º tokens: {response.usage.completion_tokens}")
    print(f"   æ€»è®¡ tokens: {response.usage.total_tokens}")
    
    return response


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šç†è§£æ¶ˆæ¯è§’è‰² ====================

def understand_message_roles():
    """ç†è§£ systemã€userã€assistant ä¸‰ç§è§’è‰²"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šç†è§£æ¶ˆæ¯è§’è‰²")
    print("=" * 60)
    
    from openai import OpenAI
    client = OpenAI()
    
    print("""
æ¶ˆæ¯è§’è‰²è¯´æ˜ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ è§’è‰²        â”‚ ä½œç”¨                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ system      â”‚ è®¾å®š AI çš„è§’è‰²ã€æ€§æ ¼å’Œè¡Œä¸ºè§„åˆ™     â”‚
â”‚ user        â”‚ ç”¨æˆ·çš„è¾“å…¥                         â”‚
â”‚ assistant   â”‚ AI çš„å†å²å›å¤ï¼ˆç”¨äºå¤šè½®å¯¹è¯ï¼‰      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)
    
    # ç¤ºä¾‹ï¼šä½¿ç”¨ system è§’è‰²è®¾å®š AI èº«ä»½
    print("\nğŸ“Œ ç¤ºä¾‹ï¼šä½¿ç”¨ system è®¾å®š AI ä¸ºç¿»è¯‘å®˜")
    
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­è‹±ç¿»è¯‘å®˜ã€‚ç”¨æˆ·è¾“å…¥ä¸­æ–‡æ—¶ç¿»è¯‘æˆè‹±æ–‡ï¼Œè¾“å…¥è‹±æ–‡æ—¶ç¿»è¯‘æˆä¸­æ–‡ã€‚åªè¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦è§£é‡Šã€‚"
            },
            {
                "role": "user",
                "content": "ä»Šå¤©å¤©æ°”å¾ˆå¥½"
            }
        ]
    )
    
    print(f"   è¾“å…¥: ä»Šå¤©å¤©æ°”å¾ˆå¥½")
    print(f"   ç¿»è¯‘: {response.choices[0].message.content}")
    
    # å¯¹æ¯”ï¼šä¸ä½¿ç”¨ system
    print("\nğŸ“Œ å¯¹æ¯”ï¼šä¸ä½¿ç”¨ system çš„æƒ…å†µ")
    
    response2 = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "user", "content": "ä»Šå¤©å¤©æ°”å¾ˆå¥½"}
        ]
    )
    
    print(f"   è¾“å…¥: ä»Šå¤©å¤©æ°”å¾ˆå¥½")
    print(f"   å›å¤: {response2.choices[0].message.content}")
    
    print("\nğŸ’¡ ç»“è®ºï¼šsystem è§’è‰²å¯ä»¥æœ‰æ•ˆåœ°æ§åˆ¶ AI çš„è¡Œä¸ºæ¨¡å¼")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šå¤šè½®å¯¹è¯ ====================

def multi_turn_conversation():
    """å®ç°å¤šè½®å¯¹è¯"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šå¤šè½®å¯¹è¯")
    print("=" * 60)
    
    from openai import OpenAI
    client = OpenAI()
    
    print("""
å¤šè½®å¯¹è¯åŸç†ï¼š
- API æœ¬èº«æ˜¯æ— çŠ¶æ€çš„ï¼Œæ¯æ¬¡è°ƒç”¨éƒ½æ˜¯ç‹¬ç«‹çš„
- è¦å®ç°å¤šè½®å¯¹è¯ï¼Œéœ€è¦å°†å†å²æ¶ˆæ¯ä¸€èµ·å‘é€
- æ¶ˆæ¯åˆ—è¡¨æŒ‰æ—¶é—´é¡ºåºæ’åˆ—
    """)
    
    # åˆå§‹åŒ–å¯¹è¯å†å²
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ï¼Œå›ç­”ç®€æ´æ˜äº†ã€‚"}
    ]
    
    # æ¨¡æ‹Ÿå¤šè½®å¯¹è¯
    conversations = [
        "æˆ‘å«å°æ˜",
        "æˆ‘å–œæ¬¢ç¼–ç¨‹",
        "ä½ è¿˜è®°å¾—æˆ‘å«ä»€ä¹ˆåå­—å—ï¼Ÿ"
    ]
    
    print("ğŸ“ å¤šè½®å¯¹è¯æ¼”ç¤ºï¼š")
    print("-" * 40)
    
    for user_input in conversations:
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": user_input})
        
        # è°ƒç”¨ API
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages
        )
        
        # è·å–å›å¤å¹¶æ·»åŠ åˆ°å†å²
        assistant_reply = response.choices[0].message.content
        messages.append({"role": "assistant", "content": assistant_reply})
        
        print(f"\nğŸ‘¤ ç”¨æˆ·: {user_input}")
        print(f"ğŸ¤– åŠ©æ‰‹: {assistant_reply}")
    
    print("\n" + "-" * 40)
    print(f"ğŸ“Š å¯¹è¯å†å²å…±æœ‰ {len(messages)} æ¡æ¶ˆæ¯")
    print("ğŸ’¡ AI èƒ½è®°ä½ä¸Šä¸‹æ–‡ï¼Œæ˜¯å› ä¸ºæˆ‘ä»¬å‘é€äº†å®Œæ•´çš„å¯¹è¯å†å²")


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šå“åº”ç»“æ„è§£æ ====================

def parse_response_structure():
    """è¯¦ç»†è§£æ API å“åº”ç»“æ„"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šå“åº”ç»“æ„è§£æ")
    print("=" * 60)
    
    from openai import OpenAI
    client = OpenAI()
    
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": "è¯´ hello"}]
    )
    
    print("\nğŸ“¦ å®Œæ•´å“åº”ç»“æ„ï¼š")
    print(f"""
response.id          = {response.id}
response.model       = {response.model}
response.created     = {response.created}
response.object      = {response.object}

response.choices[0]:
  .index             = {response.choices[0].index}
  .message.role      = {response.choices[0].message.role}
  .message.content   = {response.choices[0].message.content}
  .finish_reason     = {response.choices[0].finish_reason}

response.usage:
  .prompt_tokens     = {response.usage.prompt_tokens}
  .completion_tokens = {response.usage.completion_tokens}
  .total_tokens      = {response.usage.total_tokens}
    """)
    
    print("ğŸ’¡ finish_reason è¯´æ˜ï¼š")
    print("   - 'stop': æ­£å¸¸å®Œæˆ")
    print("   - 'length': è¾¾åˆ° max_tokens é™åˆ¶")
    print("   - 'tool_calls': æ¨¡å‹è¯·æ±‚è°ƒç”¨å·¥å…·")


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================

def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    exercises_text = """
ç»ƒä¹  1ï¼šä¿®æ”¹ system æç¤ºè¯
    å°è¯•å°† AI è®¾å®šä¸ºä¸åŒçš„è§’è‰²ï¼ˆå¦‚ï¼šè¯—äººã€ç¨‹åºå‘˜ã€å¨å¸ˆï¼‰ï¼Œ
    è§‚å¯Ÿç›¸åŒé—®é¢˜ä¸‹å›å¤çš„å·®å¼‚ã€‚

ç»ƒä¹  2ï¼šå®ç°ä¸€ä¸ªç®€å•çš„å‘½ä»¤è¡ŒèŠå¤©æœºå™¨äºº
    ä½¿ç”¨ while å¾ªç¯å’Œ input() å®ç°çœŸæ­£çš„äº¤äº’å¼å¯¹è¯ã€‚
    æç¤ºï¼šå‚è€ƒ multi_turn_conversation() çš„å®ç°ã€‚

ç»ƒä¹  3ï¼šè®¡ç®—å¯¹è¯æˆæœ¬
    GPT-3.5 Turbo çš„ä»·æ ¼çº¦ä¸º $0.0005/1K è¾“å…¥ tokens å’Œ $0.0015/1K è¾“å‡º tokensã€‚
    ä¿®æ”¹ä»£ç ï¼Œåœ¨æ¯æ¬¡å¯¹è¯åæ˜¾ç¤ºé¢„ä¼°æˆæœ¬ã€‚

æ€è€ƒé¢˜ï¼š
    1. ä¸ºä»€ä¹ˆ API éœ€è¦å‘é€å®Œæ•´çš„å¯¹è¯å†å²ï¼Ÿè¿™æœ‰ä»€ä¹ˆä¼˜ç¼ºç‚¹ï¼Ÿ
    2. å¦‚æœå¯¹è¯å†å²å¤ªé•¿ï¼Œå¯èƒ½ä¼šé‡åˆ°ä»€ä¹ˆé—®é¢˜ï¼Ÿå¦‚ä½•è§£å†³ï¼Ÿ
    """
    print(exercises_text)


# ==================== ä¸»å‡½æ•° ====================

def main():
    """ä¸»å‡½æ•° - æŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰éƒ¨åˆ†"""
    print("ğŸš€ OpenAI API åŸºç¡€è¯¾ç¨‹")
    print("=" * 60)
    print("âš ï¸ æ³¨æ„ï¼šæœ¬è¯¾ç¨‹å°†è°ƒç”¨ OpenAI APIï¼Œä¼šäº§ç”Ÿå°‘é‡è´¹ç”¨")
    print("é¢„ä¼°æ¶ˆè€—ï¼šçº¦ 500-1000 tokens")
    print("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        return
    
    # æŒ‰é¡ºåºæ‰§è¡Œå„éƒ¨åˆ†
    try:
        basic_api_call()
        understand_message_roles()
        multi_turn_conversation()
        parse_response_structure()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œ API Key æ˜¯å¦æ­£ç¡®")
        return
    
    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼")
    print("ä¸‹ä¸€æ­¥ï¼š02-openai-parameters.pyï¼ˆAPI å‚æ•°è¯¦è§£ï¼‰")
    print("=" * 60)


if __name__ == "__main__":
    main()
