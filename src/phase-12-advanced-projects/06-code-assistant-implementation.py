"""
ä»£ç åŠ©æ‰‹ - å®Œæ•´å®ç°
==================

å­¦ä¹ ç›®æ ‡ï¼š
    1. å®ç°ä»£ç è¡¥å…¨å’Œç”ŸæˆæœåŠ¡
    2. æ„å»ºä»£ç ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    3. é›†æˆä»£ç åˆ†æå·¥å…·

æœ¬æ–‡ä»¶åŒ…å«æ ¸å¿ƒå®ç°ä»£ç å‚è€ƒ
"""


# ==================== é¡¹ç›®ç»“æ„ ====================

PROJECT_STRUCTURE = """
code-assistant/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ completion.py       # ä»£ç è¡¥å…¨
â”‚   â”‚   â”œâ”€â”€ generation.py       # ä»£ç ç”Ÿæˆ
â”‚   â”‚   â”œâ”€â”€ explanation.py      # ä»£ç è§£é‡Š
â”‚   â”‚   â””â”€â”€ review.py           # ä»£ç è¯„å®¡
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ context_service.py  # ä¸Šä¸‹æ–‡ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ code_analyzer.py    # ä»£ç åˆ†æ
â”‚   â”‚   â”œâ”€â”€ llm_service.py      # LLM è°ƒç”¨
â”‚   â”‚   â””â”€â”€ cache_service.py    # ç¼“å­˜æœåŠ¡
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ request.py          # è¯·æ±‚æ¨¡å‹
â”‚   â”‚
â”‚   â””â”€â”€ prompts/                # Prompt æ¨¡æ¿
â”‚       â”œâ”€â”€ completion.py
â”‚       â”œâ”€â”€ generation.py
â”‚       â””â”€â”€ review.py
â”‚
â”œâ”€â”€ extensions/
â”‚   â””â”€â”€ vscode/                 # VSCode æ’ä»¶
â”‚
â””â”€â”€ tests/
"""

print("=" * 60)
print("ç¬¬ä¸€éƒ¨åˆ†ï¼šé¡¹ç›®ç»“æ„")
print("=" * 60)
print(PROJECT_STRUCTURE)


# ==================== ä¸Šä¸‹æ–‡æœåŠ¡ ====================

CONTEXT_SERVICE = '''
# app/services/context_service.py
from dataclasses import dataclass
from typing import List, Optional, Dict
import os

@dataclass
class CodeContext:
    """ä»£ç ä¸Šä¸‹æ–‡"""
    file_path: str
    language: str
    cursor_line: int
    cursor_column: int

    # å½“å‰æ–‡ä»¶
    file_content: str
    prefix: str  # å…‰æ ‡å‰çš„ä»£ç 
    suffix: str  # å…‰æ ‡åçš„ä»£ç 

    # ç»“æ„ä¿¡æ¯
    imports: List[str] = None
    current_function: Optional[str] = None
    current_class: Optional[str] = None

    # ç›¸å…³ä¸Šä¸‹æ–‡
    related_files: List[Dict] = None

class ContextService:
    """ä¸Šä¸‹æ–‡ç®¡ç†æœåŠ¡"""

    MAX_CONTEXT_TOKENS = 6000

    def __init__(self, code_analyzer, index_service):
        self.analyzer = code_analyzer
        self.index_service = index_service

    async def build_context(
        self,
        file_path: str,
        file_content: str,
        cursor_line: int,
        cursor_column: int,
        language: str
    ) -> CodeContext:
        """æ„å»ºå®Œæ•´çš„ä»£ç ä¸Šä¸‹æ–‡"""

        # åˆ†å‰² prefix å’Œ suffix
        lines = file_content.split("\\n")
        prefix_lines = lines[:cursor_line]
        suffix_lines = lines[cursor_line:]

        if cursor_line < len(lines):
            current_line = lines[cursor_line]
            prefix_lines[-1] = current_line[:cursor_column] if cursor_line > 0 else ""
            suffix_lines[0] = current_line[cursor_column:]

        prefix = "\\n".join(prefix_lines)
        suffix = "\\n".join(suffix_lines)

        # åˆ†æä»£ç ç»“æ„
        analysis = self.analyzer.get_cursor_context(
            file_content, cursor_line, cursor_column
        )

        # æå–å¯¼å…¥
        imports = self.analyzer.get_imports(file_content)

        # æ£€ç´¢ç›¸å…³æ–‡ä»¶
        related = await self._get_related_files(file_path, file_content, language)

        return CodeContext(
            file_path=file_path,
            language=language,
            cursor_line=cursor_line,
            cursor_column=cursor_column,
            file_content=file_content,
            prefix=prefix,
            suffix=suffix,
            imports=[str(imp) for imp in imports],
            current_function=analysis.get("parent_function"),
            current_class=analysis.get("parent_class"),
            related_files=related
        )

    async def _get_related_files(
        self,
        file_path: str,
        content: str,
        language: str
    ) -> List[Dict]:
        """è·å–ç›¸å…³æ–‡ä»¶"""
        related = []

        # åŸºäºå¯¼å…¥å…³ç³»
        imports = self.analyzer.get_imports(content)
        for imp in imports[:5]:  # é™åˆ¶æ•°é‡
            # è§£æå¯¼å…¥è·¯å¾„ï¼ŒæŸ¥æ‰¾å¯¹åº”æ–‡ä»¶
            pass

        # åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆå¯é€‰ï¼‰
        # similar_files = await self.index_service.search_similar(content)

        return related
'''

print("\n" + "=" * 60)
print("ç¬¬äºŒéƒ¨åˆ†ï¼šä¸Šä¸‹æ–‡æœåŠ¡")
print("=" * 60)
print(CONTEXT_SERVICE)


# ==================== ä»£ç åˆ†æå™¨ ====================

CODE_ANALYZER = '''
# app/services/code_analyzer.py
from tree_sitter_languages import get_language, get_parser
from typing import List, Dict, Optional

class CodeAnalyzer:
    """ä»£ç åˆ†æå™¨ - ä½¿ç”¨ tree-sitter"""

    SUPPORTED_LANGUAGES = {
        "python": "python",
        "javascript": "javascript",
        "typescript": "typescript",
        "java": "java",
        "go": "go",
        "rust": "rust",
    }

    def __init__(self):
        self.parsers = {}
        self.languages = {}

    def _get_parser(self, language: str):
        """è·å–è§£æå™¨"""
        if language not in self.parsers:
            lang_id = self.SUPPORTED_LANGUAGES.get(language, language)
            self.parsers[language] = get_parser(lang_id)
            self.languages[language] = get_language(lang_id)
        return self.parsers[language], self.languages[language]

    def parse(self, code: str, language: str):
        """è§£æä»£ç """
        parser, _ = self._get_parser(language)
        return parser.parse(bytes(code, "utf8"))

    def get_functions(self, code: str, language: str = "python") -> List[Dict]:
        """æå–å‡½æ•°å®šä¹‰"""
        parser, lang = self._get_parser(language)
        tree = parser.parse(bytes(code, "utf8"))

        # Python å‡½æ•°æŸ¥è¯¢
        if language == "python":
            query = lang.query("""
                (function_definition
                    name: (identifier) @func_name
                    parameters: (parameters) @params
                ) @func
            """)
        elif language in ["javascript", "typescript"]:
            query = lang.query("""
                (function_declaration
                    name: (identifier) @func_name
                    parameters: (formal_parameters) @params
                ) @func
            """)
        else:
            return []

        captures = query.captures(tree.root_node)
        functions = []
        for node, name in captures:
            if name == "func":
                functions.append({
                    "name": self._get_text(node, code),
                    "start_line": node.start_point[0],
                    "end_line": node.end_point[0],
                })
        return functions

    def get_imports(self, code: str, language: str = "python") -> List[str]:
        """æå–å¯¼å…¥è¯­å¥"""
        parser, lang = self._get_parser(language)
        tree = parser.parse(bytes(code, "utf8"))

        imports = []
        if language == "python":
            query = lang.query("""
                (import_statement) @import
                (import_from_statement) @import_from
            """)
            for node, _ in query.captures(tree.root_node):
                imports.append(self._get_text(node, code))

        return imports

    def get_cursor_context(
        self,
        code: str,
        line: int,
        column: int,
        language: str = "python"
    ) -> Dict:
        """è·å–å…‰æ ‡ä½ç½®ä¸Šä¸‹æ–‡"""
        parser, _ = self._get_parser(language)
        tree = parser.parse(bytes(code, "utf8"))

        point = (line, column)
        node = tree.root_node.descendant_for_point_range(point, point)

        # æŸ¥æ‰¾çˆ¶çº§å‡½æ•°å’Œç±»
        parent_func = None
        parent_class = None
        current = node

        while current:
            if current.type in ["function_definition", "function_declaration"]:
                parent_func = self._get_text(current, code)
            elif current.type in ["class_definition", "class_declaration"]:
                parent_class = self._get_text(current, code)
            current = current.parent

        return {
            "node_type": node.type if node else None,
            "parent_function": parent_func,
            "parent_class": parent_class,
        }

    def _get_text(self, node, code: str) -> str:
        """è·å–èŠ‚ç‚¹æ–‡æœ¬"""
        return code[node.start_byte:node.end_byte]
'''

print("\n" + "=" * 60)
print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šä»£ç åˆ†æå™¨")
print("=" * 60)
print(CODE_ANALYZER)


# ==================== LLM æœåŠ¡ ====================

LLM_SERVICE = '''
# app/services/llm_service.py
import google.generativeai as genai
from typing import AsyncGenerator
from app.config import get_settings

settings = get_settings()

class LLMService:
    """LLM è°ƒç”¨æœåŠ¡"""

    def __init__(self):
        genai.configure(api_key=settings.GOOGLE_API_KEY)
        self.model = genai.GenerativeModel('gemini-1.5-flash')

    async def complete(
        self,
        prompt: str,
        model: str = None,
        max_tokens: int = 500,
        temperature: float = 0.2,
        stop: list = None
    ) -> str:
        """å¸¸è§„è¡¥å…¨"""
        response = await self.model.generate_content_async(prompt)
        return response.text

    async def stream_complete(
        self,
        prompt: str,
        model: str = None,
        max_tokens: int = 1000
    ) -> AsyncGenerator[str, None]:
        """æµå¼è¡¥å…¨"""
        response = self.model.generate_content(
            prompt,
            stream=True
        )
        
        for chunk in response:
            if hasattr(chunk, 'text'):
                yield chunk.text
'''

print("\n" + "=" * 60)
print("ç¬¬å››éƒ¨åˆ†ï¼šLLM æœåŠ¡")
print("=" * 60)
print(LLM_SERVICE)


# ==================== è¡¥å…¨æœåŠ¡ ====================

COMPLETION_SERVICE = '''
# app/services/completion_service.py
from app.services.context_service import ContextService, CodeContext
from app.services.llm_service import LLMService

class CompletionService:
    """ä»£ç è¡¥å…¨æœåŠ¡"""

    PROMPT_TEMPLATE = """# ä»£ç è¡¥å…¨ä»»åŠ¡
è¯­è¨€: {language}

## å½“å‰æ–‡ä»¶ä¸Šä¸‹æ–‡
```{language}
{file_context}
```

## è¡¥å…¨ä½ç½®
è¯·è¡¥å…¨ <CURSOR> ä½ç½®çš„ä»£ç ï¼š

```{language}
{prefix}<CURSOR>{suffix}
```

## è¦æ±‚
- åªè¾“å‡ºéœ€è¦æ’å…¥çš„ä»£ç ï¼Œä¸è¦åŒ…å«å·²æœ‰ä»£ç 
- ä¿æŒä»£ç é£æ ¼ä¸€è‡´
- è€ƒè™‘ä¸Šä¸‹æ–‡çš„å˜é‡å’Œå‡½æ•°å‘½å
- ä»£ç åº”è¯¥è¯­æ³•æ­£ç¡®ä¸”å¯æ‰§è¡Œ

è¡¥å…¨ä»£ç ï¼š"""

    def __init__(self, context_service: ContextService, llm_service: LLMService):
        self.context_service = context_service
        self.llm_service = llm_service

    async def complete(
        self,
        file_path: str,
        file_content: str,
        cursor_line: int,
        cursor_column: int,
        language: str = "python"
    ) -> str:
        """æ‰§è¡Œä»£ç è¡¥å…¨"""
        # 1. æ„å»ºä¸Šä¸‹æ–‡
        context = await self.context_service.build_context(
            file_path, file_content, cursor_line, cursor_column, language
        )

        # 2. æˆªå–ç›¸å…³ä¸Šä¸‹æ–‡ï¼ˆé¿å…è¶…å‡º token é™åˆ¶ï¼‰
        prefix = context.prefix[-2000:] if len(context.prefix) > 2000 else context.prefix
        suffix = context.suffix[:500] if len(context.suffix) > 500 else context.suffix

        # 3. æ„å»º prompt
        prompt = self.PROMPT_TEMPLATE.format(
            language=language,
            file_context=self._get_file_context(context),
            prefix=prefix,
            suffix=suffix
        )

        # 4. è°ƒç”¨ LLM
        completion = await self.llm_service.complete(
            prompt=prompt,
            temperature=0.2,
            max_tokens=200,
            stop=["```", "\\n\\n"]
        )

        return completion.strip()

    def _get_file_context(self, context: CodeContext) -> str:
        """è·å–æ–‡ä»¶ä¸Šä¸‹æ–‡æ‘˜è¦"""
        parts = []

        # å¯¼å…¥è¯­å¥
        if context.imports:
            parts.append("# Imports")
            parts.extend(context.imports[:10])

        # å½“å‰å‡½æ•°/ç±»
        if context.current_function:
            parts.append(f"\\n# In function: {context.current_function}")
        if context.current_class:
            parts.append(f"# In class: {context.current_class}")

        return "\\n".join(parts)
'''

print("\n" + "=" * 60)
print("ç¬¬äº”éƒ¨åˆ†ï¼šè¡¥å…¨æœåŠ¡")
print("=" * 60)
print(COMPLETION_SERVICE)


# ==================== API æ¥å£ ====================

API_CODE = '''
# app/api/completion.py
from fastapi import APIRouter, Depends
from pydantic import BaseModel
from typing import Optional
from app.services.completion_service import CompletionService
from app.dependencies import get_completion_service

router = APIRouter(prefix="/completion", tags=["completion"])

class CompletionRequest(BaseModel):
    file_path: str
    file_content: str
    cursor_line: int
    cursor_column: int
    language: str = "python"

class CompletionResponse(BaseModel):
    completion: str
    confidence: Optional[float] = None

@router.post("", response_model=CompletionResponse)
async def get_completion(
    request: CompletionRequest,
    service: CompletionService = Depends(get_completion_service)
):
    """è·å–ä»£ç è¡¥å…¨"""
    completion = await service.complete(
        file_path=request.file_path,
        file_content=request.file_content,
        cursor_line=request.cursor_line,
        cursor_column=request.cursor_column,
        language=request.language
    )
    return CompletionResponse(completion=completion)


# app/api/generation.py
from fastapi import APIRouter
from fastapi.responses import StreamingResponse
from pydantic import BaseModel

router = APIRouter(prefix="/generate", tags=["generation"])

class GenerationRequest(BaseModel):
    instruction: str
    context: str = ""
    language: str = "python"

@router.post("/stream")
async def generate_code_stream(request: GenerationRequest):
    """æµå¼ç”Ÿæˆä»£ç """
    async def generate():
        prompt = f"""æ ¹æ®ä»¥ä¸‹æŒ‡ä»¤ç”Ÿæˆ {request.language} ä»£ç ï¼š

æŒ‡ä»¤ï¼š{request.instruction}

ä¸Šä¸‹æ–‡ï¼š
{request.context}

ç”Ÿæˆä»£ç ï¼š"""

        async for chunk in llm_service.stream_complete(prompt):
            yield f"data: {chunk}\\n\\n"
        yield "data: [DONE]\\n\\n"

    return StreamingResponse(generate(), media_type="text/event-stream")


# app/api/review.py
from fastapi import APIRouter
from pydantic import BaseModel
from typing import List

router = APIRouter(prefix="/review", tags=["review"])

class ReviewRequest(BaseModel):
    code: str
    language: str = "python"

class ReviewItem(BaseModel):
    severity: str  # "error", "warning", "info"
    line: int
    message: str
    suggestion: str

class ReviewResponse(BaseModel):
    issues: List[ReviewItem]
    summary: str
    score: float

@router.post("", response_model=ReviewResponse)
async def review_code(request: ReviewRequest):
    """ä»£ç è¯„å®¡"""
    prompt = f"""è¯·è¯„å®¡ä»¥ä¸‹ {request.language} ä»£ç ï¼š

```{request.language}
{request.code}
```

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼š
{{
    "issues": [
        {{"severity": "error/warning/info", "line": è¡Œå·, "message": "é—®é¢˜æè¿°", "suggestion": "ä¿®å¤å»ºè®®"}}
    ],
    "summary": "æ€»ä½“è¯„ä»·",
    "score": 0-100çš„è¯„åˆ†
}}"""

    result = await llm_service.complete(prompt)
    import json
    return ReviewResponse(**json.loads(result))
'''

print("\n" + "=" * 60)
print("ç¬¬å…­éƒ¨åˆ†ï¼šAPI æ¥å£")
print("=" * 60)
print(API_CODE)


# ==================== VSCode æ’ä»¶ ====================

VSCODE_EXTENSION = """
// extensions/vscode/src/extension.ts
import * as vscode from 'vscode';

export function activate(context: vscode.ExtensionContext) {
    // æ³¨å†Œè¡¥å…¨æä¾›è€…
    const provider = vscode.languages.registerCompletionItemProvider(
        ['python', 'javascript', 'typescript'],
        new AICompletionProvider(),
        '.'  // è§¦å‘å­—ç¬¦
    );

    // æ³¨å†Œå‘½ä»¤
    const explainCmd = vscode.commands.registerCommand(
        'codeAssistant.explain',
        async () => {
            const editor = vscode.window.activeTextEditor;
            if (!editor) return;

            const selection = editor.selection;
            const code = editor.document.getText(selection);

            const explanation = await callAPI('/explain', { code });
            vscode.window.showInformationMessage(explanation);
        }
    );

    context.subscriptions.push(provider, explainCmd);
}

class AICompletionProvider implements vscode.CompletionItemProvider {
    async provideCompletionItems(
        document: vscode.TextDocument,
        position: vscode.Position
    ): Promise<vscode.CompletionItem[]> {

        const response = await callAPI('/completion', {
            file_path: document.fileName,
            file_content: document.getText(),
            cursor_line: position.line,
            cursor_column: position.character,
            language: document.languageId
        });

        const item = new vscode.CompletionItem(
            response.completion,
            vscode.CompletionItemKind.Snippet
        );
        item.insertText = response.completion;

        return [item];
    }
}

async function callAPI(endpoint: string, data: any): Promise<any> {
    const config = vscode.workspace.getConfiguration('codeAssistant');
    const baseUrl = config.get('apiUrl', 'http://localhost:8000');

    const response = await fetch(`${baseUrl}${endpoint}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(data)
    });

    return response.json();
}
"""

print("\n" + "=" * 60)
print("ç¬¬ä¸ƒéƒ¨åˆ†ï¼šVSCode æ’ä»¶")
print("=" * 60)
print(VSCODE_EXTENSION)


print("\n" + "=" * 60)
print("ğŸ‰ Phase 12 è¯¾ç¨‹å®Œæˆï¼")
print("=" * 60)
print("""
æ­å–œå®Œæˆæ‰€æœ‰ç»¼åˆé¡¹ç›®å­¦ä¹ ï¼

å›é¡¾å·²å­¦ä¹ çš„é¡¹ç›®ï¼š
1. ä¼ä¸šçº§çŸ¥è¯†åº“ç³»ç»Ÿ - RAG + æƒé™ç®¡ç†
2. AI å®¢æœç³»ç»Ÿ - å¯¹è¯ç®¡ç† + äººå·¥æ¥å…¥
3. ä»£ç åŠ©æ‰‹ - ä»£ç åˆ†æ + LLM ç”Ÿæˆ

ä¸‹ä¸€æ­¥å»ºè®®ï¼š
- é€‰æ‹©ä¸€ä¸ªé¡¹ç›®æ·±å…¥å®ç°
- åŠ å…¥æ›´å¤šé«˜çº§åŠŸèƒ½
- éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
""")
