"""
é—®ç­”é“¾
======

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£ RAG é—®ç­”çš„å®Œæ•´æµç¨‹
    2. æŒæ¡é—®ç­”é“¾çš„æ„å»ºæ–¹æ³•
    3. å­¦ä¼šè‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿

æ ¸å¿ƒæ¦‚å¿µï¼š
    - RAG Chainï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆé“¾
    - Contextï¼šæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
    - Prompt Templateï¼šé—®ç­”æç¤ºè¯æ¨¡æ¿

å‰ç½®çŸ¥è¯†ï¼š
    - 08-retrieval-basics.py

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install langchain langchain-google-genai chromadb python-dotenv
"""

import os
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šRAG æµç¨‹ ====================


def rag_overview():
    """RAG æµç¨‹æ¦‚è¿°"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šRAG æµç¨‹")
    print("=" * 60)

    print("""
    RAG (Retrieval-Augmented Generation)ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Query  â”‚ â”€â–¶ â”‚ Retrieverâ”‚ â”€â–¶ â”‚  Context  â”‚ â”€â–¶ â”‚  LLM   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚              â”‚
                                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                â–¼
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚  Answer  â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    æ ¸å¿ƒæ­¥éª¤ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€
    1. ç”¨æˆ·æé—®
    2. æ£€ç´¢ç›¸å…³æ–‡æ¡£
    3. å°†é—®é¢˜å’Œæ–‡æ¡£ç»„åˆæˆæç¤ºè¯
    4. LLM ç”Ÿæˆå›ç­”
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€ QA é“¾ ====================


def basic_qa_chain():
    """åŸºç¡€ QA é“¾"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€ QA é“¾")
    print("=" * 60)

    try:
        from langchain_google_genai import (
            ChatGoogleGenerativeAI,
            GoogleGenerativeAIEmbeddings,
        )
        from langchain_chroma import Chroma
        from langchain_core.documents import Document
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser
        from langchain_core.runnables import RunnablePassthrough

        # å‡†å¤‡çŸ¥è¯†åº“
        docs = [
            Document(
                page_content="Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œç”± Guido van Rossum äº 1991 å¹´åˆ›å»ºã€‚"
            ),
            Document(
                page_content="Python çš„è®¾è®¡å“²å­¦å¼ºè°ƒä»£ç å¯è¯»æ€§ï¼Œä½¿ç”¨ç©ºç™½ç¼©è¿›æ¥å®šä¹‰ä»£ç å—ã€‚"
            ),
            Document(
                page_content="Python æ”¯æŒå¤šç§ç¼–ç¨‹èŒƒå¼ï¼ŒåŒ…æ‹¬é¢å‘å¯¹è±¡ã€å‘½ä»¤å¼ã€å‡½æ•°å¼ç¼–ç¨‹ã€‚"
            ),
        ]

        embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")
        vectorstore = Chroma.from_documents(docs, embeddings)
        retriever = vectorstore.as_retriever(search_kwargs={"k": 2})

        # æ„å»º QA é“¾
        llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash")

        prompt = ChatPromptTemplate.from_template("""
åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ã€‚å¦‚æœä¿¡æ¯ä¸­æ²¡æœ‰ç›¸å…³å†…å®¹ï¼Œè¯·è¯´æ˜æ— æ³•å›ç­”ã€‚

ç›¸å…³ä¿¡æ¯ï¼š
{context}

é—®é¢˜ï¼š{question}

å›ç­”ï¼š""")

        def format_docs(docs):
            return "\n".join(doc.page_content for doc in docs)

        chain = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )

        # æµ‹è¯•
        question = "Python æ˜¯è°åˆ›å»ºçš„ï¼Ÿ"
        answer = chain.invoke(question)

        print(f"ğŸ“Œ é—®é¢˜: {question}")
        print(f"ğŸ“Œ å›ç­”: {answer}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šå¸¦æºå¼•ç”¨çš„ QA ====================


def qa_with_sources():
    """å¸¦æºå¼•ç”¨çš„ QA"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šå¸¦æºå¼•ç”¨çš„ QA")
    print("=" * 60)

    try:
        from langchain_google_genai import (
            ChatGoogleGenerativeAI,
            GoogleGenerativeAIEmbeddings,
        )
        from langchain_chroma import Chroma
        from langchain_core.documents import Document
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser

        docs = [
            Document(
                page_content="AI å¯ä»¥è‡ªåŠ¨é©¾é©¶æ±½è½¦", metadata={"source": "tech-news.txt"}
            ),
            Document(
                page_content="æœºå™¨å­¦ä¹ ç”¨äºåŒ»ç–—è¯Šæ–­",
                metadata={"source": "health-report.pdf"},
            ),
        ]

        embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")
        vectorstore = Chroma.from_documents(docs, embeddings)
        retriever = vectorstore.as_retriever()

        llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash")

        prompt = ChatPromptTemplate.from_template("""
åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ï¼Œå¹¶å¼•ç”¨æ¥æºã€‚

{context}

é—®é¢˜ï¼š{question}

è¯·ä»¥"å›ç­”ï¼š...ï¼ˆæ¥æºï¼š...ï¼‰"çš„æ ¼å¼å›å¤ã€‚""")

        def format_docs_with_source(docs):
            return "\n".join(
                f"å†…å®¹: {d.page_content}\næ¥æº: {d.metadata.get('source', 'unknown')}"
                for d in docs
            )

        # æ£€ç´¢å¹¶å›ç­”
        question = "AI æœ‰ä»€ä¹ˆåº”ç”¨ï¼Ÿ"
        docs = retriever.invoke(question)
        context = format_docs_with_source(docs)

        chain = prompt | llm | StrOutputParser()
        answer = chain.invoke({"context": context, "question": question})

        print(f"ğŸ“Œ é—®é¢˜: {question}")
        print(f"ğŸ“Œ å›ç­”: {answer}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šè‡ªå®šä¹‰æç¤ºè¯ ====================


def custom_prompts():
    """è‡ªå®šä¹‰æç¤ºè¯"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šè‡ªå®šä¹‰æç¤ºè¯")
    print("=" * 60)

    print("""
    å¸¸ç”¨ QA æç¤ºè¯æ¨¡æ¿ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    """)

    templates = {
        "æ ‡å‡†é—®ç­”": """
åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ï¼š
{context}

é—®é¢˜ï¼š{question}
å›ç­”ï¼š""",
        "ä¸¥æ ¼æ¨¡å¼": """
ä»…åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”ã€‚å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œå›å¤"æ ¹æ®æä¾›çš„èµ„æ–™æ— æ³•å›ç­”"ã€‚

èµ„æ–™ï¼š
{context}

é—®é¢˜ï¼š{question}
å›ç­”ï¼š""",
        "ä¸“ä¸šæ¨¡å¼": """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šé¡¾é—®ã€‚åŸºäºä»¥ä¸‹èµ„æ–™ï¼Œç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€å›ç­”ã€‚

å‚è€ƒèµ„æ–™ï¼š
{context}

å®¢æˆ·é—®é¢˜ï¼š{question}
ä¸“ä¸šè§£ç­”ï¼š""",
    }

    for name, template in templates.items():
        print(f"ğŸ“Œ {name}:")
        print(template[:100] + "...")
        print()


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šStuff vs Map-Reduce ====================


def chain_types():
    """ä¸åŒé“¾ç±»å‹"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šé“¾ç±»å‹å¯¹æ¯”")
    print("=" * 60)

    print("""
    QA é“¾çš„ä¸åŒç­–ç•¥ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    1. Stuffï¼ˆå¡«å……ï¼‰
       - å°†æ‰€æœ‰æ–‡æ¡£å¡å…¥ä¸€ä¸ªæç¤ºè¯
       - ç®€å•å¿«é€Ÿ
       - å—ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶
    
    2. Map-Reduce
       - å…ˆå¯¹æ¯ä¸ªæ–‡æ¡£å•ç‹¬å›ç­”
       - å†åˆå¹¶æ‰€æœ‰å›ç­”
       - é€‚åˆå¤§é‡æ–‡æ¡£
    
    3. Refineï¼ˆç²¾ç‚¼ï¼‰
       - é€ä¸ªæ–‡æ¡£è¿­ä»£æ›´æ–°ç­”æ¡ˆ
       - è´¨é‡è¾ƒé«˜
       - é€Ÿåº¦è¾ƒæ…¢
    
    4. Map-Rerank
       - å¯¹æ¯ä¸ªæ–‡æ¡£ç”Ÿæˆç­”æ¡ˆå’Œåˆ†æ•°
       - è¿”å›æœ€é«˜åˆ†ç­”æ¡ˆ
       - é€‚åˆæœ‰å”¯ä¸€ç­”æ¡ˆçš„é—®é¢˜
    
    æ¨èï¼š
    - æ–‡æ¡£å°‘äº 4 ä¸ªï¼šStuff
    - æ–‡æ¡£å¤šï¼šMap-Reduce æˆ– Refine
    """)


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šæ„å»ºçŸ¥è¯†é—®ç­”
        ç”¨è‡ªå·±çš„æ–‡æ¡£æ„å»º QA ç³»ç»Ÿã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
        from langchain_chroma import Chroma
        from langchain_core.documents import Document
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser
        from langchain_core.runnables import RunnablePassthrough

        # åŠ è½½æ–‡æ¡£
        docs = [
            Document(page_content="å…¬å¸äº§å“Aæ”¯æŒ...", metadata={"source": "product.txt"}),
            Document(page_content="é€€æ¬¾æ”¿ç­–ï¼š7å¤©å†…...", metadata={"source": "policy.txt"}),
        ]

        # æ„å»ºå‘é‡åº“
        embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")
        vectorstore = Chroma.from_documents(docs, embeddings)
        retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

        # æ„å»º QA é“¾
        llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash")
        prompt = ChatPromptTemplate.from_template('''
        åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ï¼š
        {context}
        é—®é¢˜ï¼š{question}
        ''')

        def format_docs(docs):
            return "\\n".join(d.page_content for d in docs)

        chain = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | prompt | llm | StrOutputParser()
        )

        answer = chain.invoke("é€€æ¬¾æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿ")
        ```

    ç»ƒä¹  2ï¼šä¼˜åŒ–æç¤ºè¯
        æµ‹è¯•ä¸åŒæç¤ºè¯å¯¹å›ç­”è´¨é‡çš„å½±å“ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        prompts = {
            "ç®€æ´": "åŸºäºä¿¡æ¯å›ç­”ï¼š{context}\\né—®é¢˜ï¼š{question}",
            "ä¸¥æ ¼": "ä»…åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”ï¼Œæ— å…³ä¿¡æ¯å›å¤'æ— æ³•å›ç­”'ï¼š\\n{context}\\né—®é¢˜ï¼š{question}",
            "ä¸“ä¸š": "ä½œä¸ºä¸“ä¸šå®¢æœï¼Œå‹å¥½ä¸“ä¸šåœ°å›ç­”ï¼š\\nå‚è€ƒèµ„æ–™ï¼š{context}\\né—®é¢˜ï¼š{question}",
        }

        for name, template in prompts.items():
            prompt = ChatPromptTemplate.from_template(template)
            chain = (
                {"context": retriever | format_docs, "question": RunnablePassthrough()}
                | prompt | llm | StrOutputParser()
            )
            answer = chain.invoke("é€€æ¬¾æ”¿ç­–ï¼Ÿ")
            print(f"{name}: {answer[:100]}...")
        ```

    ç»ƒä¹  3ï¼šæ·»åŠ æ¥æºè¿½æº¯
        åœ¨å›ç­”ä¸­æ˜¾ç¤ºå¼•ç”¨çš„æ–‡æ¡£æ¥æºã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        def qa_with_sources(question: str):
            # æ£€ç´¢
            docs = retriever.invoke(question)
            
            # æ ¼å¼åŒ–ï¼ˆå¸¦æ¥æºï¼‰
            context = "\\n".join([
                f"[{d.metadata.get('source', 'unknown')}] {d.page_content}"
                for d in docs
            ])
            
            prompt = ChatPromptTemplate.from_template('''
            åŸºäºä»¥ä¸‹èµ„æ–™å›ç­”é—®é¢˜ï¼Œå¹¶åœ¨å›ç­”æœ«å°¾æ ‡æ³¨å¼•ç”¨æ¥æºã€‚
            
            èµ„æ–™ï¼š
            {context}
            
            é—®é¢˜ï¼š{question}
            ''')
            
            answer = (prompt | llm | StrOutputParser()).invoke({
                "context": context, "question": question
            })
            
            return {
                "answer": answer,
                "sources": [d.metadata.get("source") for d in docs]
            }
        ```

    æ€è€ƒé¢˜ï¼š
        1. å¦‚ä½•å¤„ç†æ£€ç´¢åˆ°æ— å…³æ–‡æ¡£çš„æƒ…å†µï¼Ÿ
           
           âœ… ç­”æ¡ˆï¼š
           - æç¤ºè¯ä¸­æ˜ç¡®è¯´æ˜"å¦‚æ— ç›¸å…³ä¿¡æ¯åˆ™å›å¤æ— æ³•å›ç­”"
           - ä½¿ç”¨ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤ä½åˆ†æ–‡æ¡£
           - æ£€ç´¢åç”¨ LLM åˆ¤æ–­æ–‡æ¡£æ˜¯å¦ç›¸å…³
           - ç»“åˆå¤šç§æ£€ç´¢ç­–ç•¥ï¼ˆå…³é”®è¯+å‘é‡ï¼‰

        2. å¦‚ä½•æé«˜å›ç­”çš„å‡†ç¡®æ€§ï¼Ÿ
           
           âœ… ç­”æ¡ˆï¼š
           - æ”¹è¿›æ–‡æ¡£åˆ†å—ç­–ç•¥
           - ä¼˜åŒ– Embedding æ¨¡å‹é€‰æ‹©
           - ä½¿ç”¨ MMR å¢åŠ å¤šæ ·æ€§
           - æç¤ºè¯ä¸­å¼ºè°ƒ"åŸºäºè¯æ®å›ç­”"
           - å®ç°ç­”æ¡ˆéªŒè¯/è‡ªæˆ‘ä¿®æ­£æœºåˆ¶
    """)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ é—®ç­”é“¾")
    print("=" * 60)

    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯ï¼šæœªè®¾ç½® GOOGLE_API_KEY")
        return

    try:
        rag_overview()
        basic_qa_chain()
        qa_with_sources()
        custom_prompts()
        chain_types()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        return

    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š10-conversational-rag.py")
    print("=" * 60)


if __name__ == "__main__":
    main()
