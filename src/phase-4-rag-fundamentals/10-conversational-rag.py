"""
å¯¹è¯å¼ RAG
==========

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£å¯¹è¯å¼ RAG çš„ç‰¹ç‚¹
    2. æŒæ¡å†å²æ„ŸçŸ¥æ£€ç´¢
    3. æ„å»ºå¤šè½®å¯¹è¯é—®ç­”ç³»ç»Ÿ

æ ¸å¿ƒæ¦‚å¿µï¼š
    - å¯¹è¯å†å²ï¼šä¿æŒå¤šè½®ä¸Šä¸‹æ–‡
    - é—®é¢˜æ”¹å†™ï¼šç»“åˆå†å²æ”¹å†™å½“å‰é—®é¢˜
    - å†å²æ„ŸçŸ¥æ£€ç´¢ï¼šç”¨æ”¹å†™åçš„é—®é¢˜æ£€ç´¢

å‰ç½®çŸ¥è¯†ï¼š
    - 09-qa-chains.py

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install langchain langchain-google-genai chromadb python-dotenv
"""

import os
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šå¯¹è¯å¼ RAG æ¦‚å¿µ ====================


def conversational_rag_concept():
    """å¯¹è¯å¼ RAG æ¦‚å¿µ"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šå¯¹è¯å¼ RAG æ¦‚å¿µ")
    print("=" * 60)

    print("""
    æ™®é€š RAG vs å¯¹è¯å¼ RAGï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    æ™®é€š RAGï¼š
    ç”¨æˆ·: Python æ˜¯ä»€ä¹ˆ?
    AI: Python æ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€...
    
    ç”¨æˆ·: å®ƒçš„ä¼˜ç‚¹æ˜¯ä»€ä¹ˆ?  â† é—®é¢˜æŒ‡ä»£ä¸æ¸…
    AI: ä»€ä¹ˆçš„ä¼˜ç‚¹ï¼Ÿï¼ˆæ— æ³•ç†è§£"å®ƒ"æŒ‡ä»€ä¹ˆï¼‰
    
    å¯¹è¯å¼ RAGï¼š
    ç”¨æˆ·: Python æ˜¯ä»€ä¹ˆ?
    AI: Python æ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€...
    
    ç”¨æˆ·: å®ƒçš„ä¼˜ç‚¹æ˜¯ä»€ä¹ˆ?
    ç³»ç»Ÿæ”¹å†™: "Python çš„ä¼˜ç‚¹æ˜¯ä»€ä¹ˆ?"  â† è‡ªåŠ¨è¡¥å…¨ä¸Šä¸‹æ–‡
    AI: Python çš„ä¼˜ç‚¹åŒ…æ‹¬ç®€æ´æ˜“è¯»...
    
    æ ¸å¿ƒèƒ½åŠ›ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€
    1. è®°ä½å¯¹è¯å†å²
    2. ç†è§£ä»£è¯æŒ‡ä»£
    3. ç”¨å®Œæ•´é—®é¢˜æ£€ç´¢
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šé—®é¢˜æ”¹å†™ ====================


def question_rewriting():
    """é—®é¢˜æ”¹å†™"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šé—®é¢˜æ”¹å†™")
    print("=" * 60)

    try:
        from langchain_google_genai import ChatGoogleGenerativeAI
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser

        llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")

        rewrite_prompt = ChatPromptTemplate.from_template("""
åŸºäºå¯¹è¯å†å²ï¼Œå°†ç”¨æˆ·çš„åç»­é—®é¢˜æ”¹å†™ä¸ºç‹¬ç«‹çš„å®Œæ•´é—®é¢˜ã€‚

å¯¹è¯å†å²:
{history}

åç»­é—®é¢˜: {question}

æ”¹å†™åçš„ç‹¬ç«‹é—®é¢˜:""")

        rewrite_chain = rewrite_prompt | llm | StrOutputParser()

        # æµ‹è¯•
        history = "ç”¨æˆ·: Python æ˜¯ä»€ä¹ˆ?\nAI: Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ã€‚"
        question = "å®ƒæœ‰ä»€ä¹ˆä¼˜ç‚¹ï¼Ÿ"

        rewritten = rewrite_chain.invoke({"history": history, "question": question})

        print(f"ğŸ“Œ åŸå§‹é—®é¢˜: {question}")
        print(f"ğŸ“Œ æ”¹å†™å: {rewritten}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®Œæ•´å¯¹è¯å¼ RAG ====================


def conversational_rag_chain():
    """å®Œæ•´å¯¹è¯å¼ RAG"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®Œæ•´å¯¹è¯å¼ RAG")
    print("=" * 60)

    try:
        from langchain_google_genai import (
            ChatGoogleGenerativeAI,
            GoogleGenerativeAIEmbeddings,
        )
        from langchain_chroma import Chroma
        from langchain_core.documents import Document
        from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
        from langchain_core.output_parsers import StrOutputParser
        from langchain_core.messages import HumanMessage, AIMessage

        # å‡†å¤‡çŸ¥è¯†åº“
        docs = [
            Document(page_content="Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œäº 1991 å¹´å‘å¸ƒã€‚"),
            Document(
                page_content="Python çš„ä¼˜ç‚¹åŒ…æ‹¬è¯­æ³•ç®€æ´ã€æ˜“äºå­¦ä¹ ã€æ‹¥æœ‰ä¸°å¯Œçš„åº“ã€‚"
            ),
            Document(
                page_content="Python å¹¿æ³›ç”¨äºæ•°æ®ç§‘å­¦ã€æœºå™¨å­¦ä¹ ã€Web å¼€å‘ç­‰é¢†åŸŸã€‚"
            ),
        ]

        embeddings = GoogleGenerativeAIEmbeddings(model="gemini-embedding-001")
        vectorstore = Chroma.from_documents(docs, embeddings)
        retriever = vectorstore.as_retriever(search_kwargs={"k": 2})

        llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")

        # é—®é¢˜æ”¹å†™é“¾
        rewrite_prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    "å°†ç”¨æˆ·é—®é¢˜æ”¹å†™ä¸ºç‹¬ç«‹çš„å®Œæ•´é—®é¢˜ã€‚å¦‚æœé—®é¢˜å·²ç»å®Œæ•´ï¼Œç›´æ¥è¿”å›åŸé—®é¢˜ã€‚",
                ),
                MessagesPlaceholder(variable_name="history"),
                ("human", "{question}"),
            ]
        )

        # é—®ç­”é“¾
        qa_prompt = ChatPromptTemplate.from_template("""
åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ï¼š

{context}

é—®é¢˜ï¼š{question}
å›ç­”ï¼š""")

        def format_docs(docs):
            return "\n".join(d.page_content for d in docs)

        # æ¨¡æ‹Ÿå¤šè½®å¯¹è¯
        history = []

        def chat(question):
            # æ”¹å†™é—®é¢˜
            if history:
                rewrite_chain = rewrite_prompt | llm | StrOutputParser()
                standalone = rewrite_chain.invoke(
                    {"history": history, "question": question}
                )
            else:
                standalone = question

            # æ£€ç´¢
            docs = retriever.invoke(standalone)
            context = format_docs(docs)

            # ç”Ÿæˆå›ç­”
            qa_chain = qa_prompt | llm | StrOutputParser()
            answer = qa_chain.invoke({"context": context, "question": standalone})

            # æ›´æ–°å†å²
            history.append(HumanMessage(content=question))
            history.append(AIMessage(content=answer))

            return answer

        # æµ‹è¯•å¤šè½®å¯¹è¯
        questions = ["Python æ˜¯ä»€ä¹ˆï¼Ÿ", "å®ƒæœ‰ä»€ä¹ˆä¼˜ç‚¹ï¼Ÿ", "å¯ä»¥ç”¨æ¥åšä»€ä¹ˆï¼Ÿ"]

        print("ğŸ“Œ å¤šè½®å¯¹è¯æµ‹è¯•ï¼š")
        for q in questions:
            answer = chat(q)
            print(f"\nç”¨æˆ·: {q}")
            print(f"AI: {answer}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šä½¿ç”¨ LangChain å†…ç½®æ–¹æ¡ˆ ====================


def langchain_solution():
    """LangChain å†…ç½®æ–¹æ¡ˆ"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šLangChain å†…ç½®æ–¹æ¡ˆ")
    print("=" * 60)

    code_example = """
    from langchain.chains import create_history_aware_retriever
    from langchain.chains import create_retrieval_chain
    from langchain.chains.combine_documents import create_stuff_documents_chain
    
    # åˆ›å»ºå†å²æ„ŸçŸ¥æ£€ç´¢å™¨
    history_aware_retriever = create_history_aware_retriever(
        llm, retriever, contextualize_q_prompt
    )
    
    # åˆ›å»ºé—®ç­”é“¾
    question_answer_chain = create_stuff_documents_chain(
        llm, qa_prompt
    )
    
    # ç»„åˆæˆ RAG é“¾
    rag_chain = create_retrieval_chain(
        history_aware_retriever,
        question_answer_chain
    )
    
    # ä½¿ç”¨
    response = rag_chain.invoke({
        "input": "å®ƒæœ‰ä»€ä¹ˆä¼˜ç‚¹?",
        "chat_history": [
            HumanMessage("Python æ˜¯ä»€ä¹ˆ?"),
            AIMessage("Python æ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€...")
        ]
    })
    """
    print("ğŸ“Œ ä½¿ç”¨ LangChain å†…ç½®å‡½æ•°ï¼š")
    print(code_example)


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šå®Œæ•´å®ç°
        å®ç°ä¸€ä¸ªå®Œæ•´çš„å¤šè½®å¯¹è¯çŸ¥è¯†é—®ç­”ç³»ç»Ÿã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
        from langchain_chroma import Chroma
        from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
        from langchain_core.output_parsers import StrOutputParser
        from langchain_core.messages import HumanMessage, AIMessage

        class ConversationalRAG:
            def __init__(self, docs, embedding_model, llm_model):
                embeddings = GoogleGenerativeAIEmbeddings(model=embedding_model)
                self.vectorstore = Chroma.from_documents(docs, embeddings)
                self.retriever = self.vectorstore.as_retriever(search_kwargs={"k": 3})
                self.llm = ChatGoogleGenerativeAI(model=llm_model)
                self.history = []

            def chat(self, question: str) -> str:
                # æ”¹å†™é—®é¢˜ï¼ˆå¦‚æœæœ‰å†å²ï¼‰
                if self.history:
                    standalone = self._rewrite_question(question)
                else:
                    standalone = question

                # æ£€ç´¢å’Œå›ç­”
                docs = self.retriever.invoke(standalone)
                context = "\\n".join(d.page_content for d in docs)
                answer = self._generate_answer(context, question)

                # æ›´æ–°å†å²
                self.history.append(HumanMessage(content=question))
                self.history.append(AIMessage(content=answer))
                
                return answer

            def _rewrite_question(self, q):
                # ä½¿ç”¨ LLM æ”¹å†™é—®é¢˜
                ...

            def _generate_answer(self, context, question):
                # ç”Ÿæˆå›ç­”
                ...
        ```

    ç»ƒä¹  2ï¼šå†å²ç®¡ç†
        é™åˆ¶å†å²é•¿åº¦ï¼Œé¿å…ä¸Šä¸‹æ–‡è¿‡é•¿ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        class HistoryManager:
            def __init__(self, max_turns: int = 5):
                self.max_turns = max_turns
                self.history = []

            def add(self, user_msg: str, ai_msg: str):
                self.history.append(HumanMessage(content=user_msg))
                self.history.append(AIMessage(content=ai_msg))
                # ä¿æŒæœ€è¿‘ N è½®
                if len(self.history) > self.max_turns * 2:
                    self.history = self.history[-self.max_turns * 2:]

            def get_history(self):
                return self.history

            def clear(self):
                self.history = []

            def summarize(self, llm):
                # å¯¹å†å²è¿›è¡Œæ‘˜è¦å‹ç¼©
                if len(self.history) > 6:
                    old_history = self.history[:-4]
                    summary = llm.invoke(f"æ€»ç»“ä»¥ä¸‹å¯¹è¯è¦ç‚¹ï¼š{old_history}")
                    self.history = [AIMessage(content=f"[ä¹‹å‰çš„å¯¹è¯æ‘˜è¦]{summary}")] + self.history[-4:]
        ```

    ç»ƒä¹  3ï¼šäº¤äº’ç•Œé¢
        æ·»åŠ å‘½ä»¤è¡Œäº¤äº’ï¼Œæ”¯æŒæŒç»­å¯¹è¯ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        def interactive_chat(rag_system):
            print("æ¬¢è¿ä½¿ç”¨çŸ¥è¯†é—®ç­”ç³»ç»Ÿï¼è¾“å…¥ 'quit' é€€å‡º, 'clear' æ¸…ç©ºå†å²")
            
            while True:
                user_input = input("\\nä½ : ").strip()
                
                if user_input.lower() == 'quit':
                    print("å†è§ï¼")
                    break
                elif user_input.lower() == 'clear':
                    rag_system.clear_history()
                    print("å†å²å·²æ¸…ç©º")
                    continue
                elif not user_input:
                    continue
                
                answer = rag_system.chat(user_input)
                print(f"AI: {answer}")

        # ä½¿ç”¨
        interactive_chat(my_rag)
        ```

    æ€è€ƒé¢˜ï¼š
        1. å†å²å¤ªé•¿æ—¶å¦‚ä½•å¤„ç†ï¼Ÿ
           
           âœ… ç­”æ¡ˆï¼š
           - æ»‘åŠ¨çª—å£ï¼šåªä¿ç•™æœ€è¿‘ N è½®
           - æ‘˜è¦å‹ç¼©ï¼šç”¨ LLM å‹ç¼©æ—§å†å²
           - Token é™åˆ¶ï¼šæŒ‰ token æ•°æˆªæ–­
           - åˆ†å±‚å­˜å‚¨ï¼šé‡è¦ä¿¡æ¯æŒä¹…åŒ–

        2. å¦‚ä½•è¯„ä¼°å¯¹è¯å¼ RAG çš„æ•ˆæœï¼Ÿ
           
           âœ… ç­”æ¡ˆï¼š
           - å›ç­”å‡†ç¡®æ€§ï¼šäººå·¥æ ‡æ³¨è¯„åˆ†
           - ä¸Šä¸‹æ–‡ç†è§£ï¼šä»£è¯è§£ææ­£ç¡®ç‡
           - æ£€ç´¢ç›¸å…³æ€§ï¼šRecall@K
           - å¯¹è¯è¿è´¯æ€§ï¼šäººå·¥è¯„ä¼°æµç•…åº¦
           - ç”¨æˆ·æ»¡æ„åº¦ï¼šA/B æµ‹è¯•
    """)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯¹è¯å¼ RAG")
    print("=" * 60)

    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯ï¼šæœªè®¾ç½® GOOGLE_API_KEY")
        return

    try:
        conversational_rag_concept()
        question_rewriting()
        conversational_rag_chain()
        langchain_solution()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        return

    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š11-project-knowledge-base.py")
    print("=" * 60)


if __name__ == "__main__":
    main()
