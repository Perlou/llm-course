"""
æ–‡æ¡£åŠ è½½å™¨
==========

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£æ–‡æ¡£åŠ è½½å™¨çš„ä½œç”¨
    2. æŒæ¡å¸¸è§æ–‡æ¡£æ ¼å¼çš„åŠ è½½æ–¹æ³•
    3. å­¦ä¼šå¤„ç†ä¸åŒç±»å‹çš„æ•°æ®æº

æ ¸å¿ƒæ¦‚å¿µï¼š
    - Documentï¼šLangChain çš„æ–‡æ¡£å¯¹è±¡
    - DocumentLoaderï¼šæ–‡æ¡£åŠ è½½å™¨åŸºç±»
    - å…ƒæ•°æ®ï¼šæ–‡æ¡£çš„é™„åŠ ä¿¡æ¯

å‰ç½®çŸ¥è¯†ï¼š
    - Phase 3 LangChain åŸºç¡€

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install langchain langchain-community python-dotenv
    - pip install pypdf docx2txt unstructured
"""

import os
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šDocument å¯¹è±¡ ====================


def document_basics():
    """Document å¯¹è±¡åŸºç¡€"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šDocument å¯¹è±¡")
    print("=" * 60)

    from langchain_core.documents import Document

    print("""
    Document æ˜¯ LangChain ä¸­çš„æ ¸å¿ƒæ•°æ®ç»“æ„ï¼š
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               Document                       â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  page_content: str    # æ–‡æ¡£å†…å®¹             â”‚
    â”‚  metadata: dict       # å…ƒæ•°æ®ï¼ˆæ¥æºã€é¡µç ç­‰ï¼‰â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)

    # åˆ›å»º Document
    doc = Document(
        page_content="è¿™æ˜¯ä¸€æ®µç¤ºä¾‹æ–‡æœ¬å†…å®¹ã€‚",
        metadata={"source": "example.txt", "page": 1},
    )

    print("ğŸ“Œ åˆ›å»º Documentï¼š")
    print(f"  å†…å®¹: {doc.page_content}")
    print(f"  å…ƒæ•°æ®: {doc.metadata}")


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šæ–‡æœ¬æ–‡ä»¶åŠ è½½ ====================


def text_loader_demo():
    """æ–‡æœ¬æ–‡ä»¶åŠ è½½"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šæ–‡æœ¬æ–‡ä»¶åŠ è½½")
    print("=" * 60)

    from langchain_community.document_loaders import TextLoader

    # åˆ›å»ºç¤ºä¾‹æ–‡ä»¶
    sample_file = "/tmp/sample.txt"
    with open(sample_file, "w", encoding="utf-8") as f:
        f.write("è¿™æ˜¯ç¬¬ä¸€è¡Œå†…å®¹ã€‚\n")
        f.write("è¿™æ˜¯ç¬¬äºŒè¡Œå†…å®¹ã€‚\n")
        f.write("è¿™æ˜¯ç¬¬ä¸‰è¡Œå†…å®¹ã€‚")

    # åŠ è½½æ–‡ä»¶
    loader = TextLoader(sample_file, encoding="utf-8")
    docs = loader.load()

    print(f"ğŸ“Œ åŠ è½½ç»“æœï¼š")
    print(f"  æ–‡æ¡£æ•°é‡: {len(docs)}")
    print(f"  å†…å®¹: {docs[0].page_content[:50]}...")
    print(f"  å…ƒæ•°æ®: {docs[0].metadata}")

    # æ¸…ç†
    os.remove(sample_file)


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šç›®å½•æ‰¹é‡åŠ è½½ ====================


def directory_loader_demo():
    """ç›®å½•æ‰¹é‡åŠ è½½"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šç›®å½•æ‰¹é‡åŠ è½½")
    print("=" * 60)

    from langchain_community.document_loaders import DirectoryLoader, TextLoader
    import tempfile

    # åˆ›å»ºä¸´æ—¶ç›®å½•å’Œæ–‡ä»¶
    temp_dir = tempfile.mkdtemp()
    for i in range(3):
        with open(f"{temp_dir}/file{i}.txt", "w") as f:
            f.write(f"è¿™æ˜¯æ–‡ä»¶ {i} çš„å†…å®¹ã€‚")

    # åŠ è½½ç›®å½•
    loader = DirectoryLoader(temp_dir, glob="*.txt", loader_cls=TextLoader)
    docs = loader.load()

    print(f"ğŸ“Œ æ‰¹é‡åŠ è½½ç»“æœï¼š")
    print(f"  åŠ è½½æ–‡ä»¶æ•°: {len(docs)}")
    for doc in docs:
        print(f"  - {doc.metadata.get('source', 'unknown')}")

    # æ¸…ç†
    import shutil

    shutil.rmtree(temp_dir)


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šPDF åŠ è½½ ====================


def pdf_loader_demo():
    """PDF åŠ è½½æ¼”ç¤º"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šPDF åŠ è½½")
    print("=" * 60)

    print("""
    å¸¸ç”¨ PDF åŠ è½½å™¨ï¼š
    
    1. PyPDFLoader - åŸºç¡€ PDF åŠ è½½
       pip install pypdf
       
    2. PyMuPDFLoader - æ›´å¿«é€Ÿçš„åŠ è½½
       pip install pymupdf
       
    3. PDFPlumberLoader - ä¿ç•™å¸ƒå±€ä¿¡æ¯
       pip install pdfplumber
    """)

    code_example = """
    from langchain_community.document_loaders import PyPDFLoader
    
    # åŠ è½½ PDF
    loader = PyPDFLoader("document.pdf")
    pages = loader.load()
    
    # æ¯é¡µä¸€ä¸ª Document
    for i, page in enumerate(pages):
        print(f"ç¬¬ {i+1} é¡µ: {len(page.page_content)} å­—ç¬¦")
    """
    print("ğŸ“Œ PDF åŠ è½½ç¤ºä¾‹ä»£ç ï¼š")
    print(code_example)


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šWeb å†…å®¹åŠ è½½ ====================


def web_loader_demo():
    """Web å†…å®¹åŠ è½½"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šWeb å†…å®¹åŠ è½½")
    print("=" * 60)

    print("""
    å¸¸ç”¨ Web åŠ è½½å™¨ï¼š
    
    1. WebBaseLoader - åŸºç¡€ç½‘é¡µåŠ è½½
    2. UnstructuredURLLoader - ç»“æ„åŒ–æå–
    3. RecursiveUrlLoader - é€’å½’çˆ¬å–
    """)

    try:
        from langchain_community.document_loaders import WebBaseLoader

        loader = WebBaseLoader("https://example.com")
        docs = loader.load()

        print(f"ğŸ“Œ ç½‘é¡µåŠ è½½ç»“æœï¼š")
        print(f"  æ–‡æ¡£æ•°: {len(docs)}")
        print(f"  å†…å®¹é¢„è§ˆ: {docs[0].page_content[:100]}...")

    except Exception as e:
        print(f"âš ï¸ ç½‘é¡µåŠ è½½éœ€è¦ç½‘ç»œ: {e}")


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šå…¶ä»–åŠ è½½å™¨ ====================


def other_loaders():
    """å…¶ä»–å¸¸ç”¨åŠ è½½å™¨"""
    print("\n" + "=" * 60)
    print("ç¬¬å…­éƒ¨åˆ†ï¼šå…¶ä»–å¸¸ç”¨åŠ è½½å™¨")
    print("=" * 60)

    print("""
    æ–‡æ¡£ç±»å‹               åŠ è½½å™¨                    ä¾èµ–
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Word (.docx)          Docx2txtLoader          docx2txt
    Markdown              UnstructuredMarkdownLoader unstructured
    CSV                   CSVLoader               -
    JSON                  JSONLoader              -
    HTML                  UnstructuredHTMLLoader  unstructured
    Excel                 UnstructuredExcelLoader openpyxl
    PowerPoint            UnstructuredPPTLoader   python-pptx
    
    æ•°æ®åº“
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    SQLite/MySQL          SQLDatabaseLoader       sqlalchemy
    
    äº‘å­˜å‚¨
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    S3                    S3FileLoader            boto3
    Google Drive          GoogleDriveLoader       google-api-python-client
    """)


# ==================== ç¬¬ä¸ƒéƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šåŠ è½½æœ¬åœ°æ–‡ä»¶
        åˆ›å»ºå‡ ä¸ª txt æ–‡ä»¶ï¼Œä½¿ç”¨ DirectoryLoader æ‰¹é‡åŠ è½½ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        from langchain_community.document_loaders import DirectoryLoader, TextLoader
        import os
        import tempfile

        # åˆ›å»ºæµ‹è¯•ç›®å½•å’Œæ–‡ä»¶
        temp_dir = tempfile.mkdtemp()
        for i in range(3):
            with open(f"{temp_dir}/note{i}.txt", "w") as f:
                f.write(f"è¿™æ˜¯ç¬”è®°æ–‡ä»¶ {i} çš„å†…å®¹ã€‚\\nåŒ…å«å¤šè¡Œæ–‡æœ¬ã€‚")

        # æ‰¹é‡åŠ è½½
        loader = DirectoryLoader(
            temp_dir,
            glob="*.txt",
            loader_cls=TextLoader,
            loader_kwargs={"encoding": "utf-8"}
        )
        docs = loader.load()

        print(f"åŠ è½½äº† {len(docs)} ä¸ªæ–‡æ¡£")
        for doc in docs:
            print(f"- {doc.metadata['source']}: {len(doc.page_content)} å­—ç¬¦")
        ```

    ç»ƒä¹  2ï¼šå¤„ç† PDF
        ä¸‹è½½ä¸€ä¸ª PDF æ–‡æ¡£ï¼Œç”¨ PyPDFLoader åŠ è½½å¹¶ç»Ÿè®¡é¡µæ•°ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        from langchain_community.document_loaders import PyPDFLoader

        # åŠ è½½ PDF
        loader = PyPDFLoader("document.pdf")
        pages = loader.load()

        print(f"æ€»é¡µæ•°: {len(pages)}")
        for i, page in enumerate(pages):
            print(f"ç¬¬ {i+1} é¡µ: {len(page.page_content)} å­—ç¬¦")
            print(f"  å…ƒæ•°æ®: {page.metadata}")
        ```

    ç»ƒä¹  3ï¼šç½‘é¡µæŠ“å–
        ä½¿ç”¨ WebBaseLoader æŠ“å–ä¸€ä¸ªæ–°é—»é¡µé¢çš„å†…å®¹ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        from langchain_community.document_loaders import WebBaseLoader

        # å•ä¸ªç½‘é¡µ
        loader = WebBaseLoader("https://example.com/news")
        docs = loader.load()

        print(f"å†…å®¹é•¿åº¦: {len(docs[0].page_content)} å­—ç¬¦")
        print(f"å…ƒæ•°æ®: {docs[0].metadata}")

        # å¤šä¸ªç½‘é¡µ
        loader = WebBaseLoader([
            "https://example.com/page1",
            "https://example.com/page2"
        ])
        docs = loader.load()
        ```

    æ€è€ƒé¢˜ï¼š
        1. åŠ è½½å™¨å¦‚ä½•å¤„ç†ç¼–ç é—®é¢˜ï¼Ÿ
           
           âœ… ç­”æ¡ˆï¼š
           - TextLoader æ”¯æŒ encoding å‚æ•°ï¼š`TextLoader(file, encoding="utf-8")`
           - å¯ä»¥ä½¿ç”¨ autodetect_encoding=True è‡ªåŠ¨æ£€æµ‹
           - PDF åŠ è½½å™¨é€šå¸¸å†…ç½®ç¼–ç å¤„ç†
           - ç½‘é¡µåŠ è½½å™¨ä» HTTP å¤´æˆ– meta æ ‡ç­¾è·å–ç¼–ç 

        2. å¤§æ–‡ä»¶åŠ è½½æ—¶çš„å†…å­˜é—®é¢˜å¦‚ä½•è§£å†³ï¼Ÿ
           
           âœ… ç­”æ¡ˆï¼š
           - ä½¿ç”¨ lazy_load() å»¶è¿ŸåŠ è½½
           - åˆ†å—å¤„ç†ï¼šç»“åˆ TextSplitter è¾¹åŠ è½½è¾¹åˆ†å—
           - æµå¼å¤„ç†ï¼šä½¿ç”¨ç”Ÿæˆå™¨æ¨¡å¼
           - å¯¹äº PDFï¼šä½¿ç”¨ load_and_split() ç›´æ¥åˆ†å—
    """)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ–‡æ¡£åŠ è½½å™¨")
    print("=" * 60)

    try:
        document_basics()
        text_loader_demo()
        directory_loader_demo()
        pdf_loader_demo()
        web_loader_demo()
        other_loaders()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        return

    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š02-text-splitters.py")
    print("=" * 60)


if __name__ == "__main__":
    main()
