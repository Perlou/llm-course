"""
å‘é‡æ•°æ®åº“æ¦‚è¿°
==============

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£å‘é‡æ•°æ®åº“çš„ä½œç”¨
    2. äº†è§£ä¸»æµå‘é‡æ•°æ®åº“
    3. æŒæ¡å‘é‡æ£€ç´¢çš„åŸºæœ¬æ¦‚å¿µ

æ ¸å¿ƒæ¦‚å¿µï¼š
    - å‘é‡å­˜å‚¨ï¼šä¿å­˜å’Œæ£€ç´¢å‘é‡
    - ANN æœç´¢ï¼šè¿‘ä¼¼æœ€è¿‘é‚»æœç´¢
    - ç´¢å¼•ç±»å‹ï¼šHNSWã€IVF ç­‰

å‰ç½®çŸ¥è¯†ï¼š
    - 04-embeddings-basics.py

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install langchain langchain-google-genai python-dotenv
"""

import os
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šå‘é‡æ•°æ®åº“æ¦‚å¿µ ====================


def vector_db_concept():
    """å‘é‡æ•°æ®åº“æ¦‚å¿µ"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šå‘é‡æ•°æ®åº“æ¦‚å¿µ")
    print("=" * 60)

    print("""
    ä¸ºä»€ä¹ˆéœ€è¦å‘é‡æ•°æ®åº“ï¼Ÿ
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    ä¼ ç»Ÿæ•°æ®åº“ï¼šç²¾ç¡®åŒ¹é…
    SELECT * FROM docs WHERE title = 'AI'
    
    å‘é‡æ•°æ®åº“ï¼šè¯­ä¹‰ç›¸ä¼¼
    æ‰¾å‡ºä¸ [0.1, 0.2, ...] æœ€ç›¸ä¼¼çš„å‘é‡
    
    å‘é‡æ•°æ®åº“çš„æ ¸å¿ƒåŠŸèƒ½ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    1. å­˜å‚¨
       - é«˜ç»´å‘é‡ï¼ˆ512-4096ç»´ï¼‰
       - å…³è”çš„å…ƒæ•°æ®
    
    2. ç´¢å¼•
       - æ„å»ºé«˜æ•ˆæœç´¢ç´¢å¼•
       - æ”¯æŒå¿«é€Ÿç›¸ä¼¼åº¦æŸ¥è¯¢
    
    3. æ£€ç´¢
       - Top-K ç›¸ä¼¼æœç´¢
       - è¿‡æ»¤æ¡ä»¶æ”¯æŒ
    
    RAG ä¸­çš„è§’è‰²ï¼š
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  æ–‡æ¡£   â”‚ â”€â–¶ â”‚  å‘é‡æ•°æ®åº“   â”‚ â”€â–¶ â”‚  æ£€ç´¢   â”‚
    â”‚ Embeddingâ”‚    â”‚   å­˜å‚¨ç´¢å¼•    â”‚    â”‚  Top-K  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šä¸»æµå‘é‡æ•°æ®åº“ ====================


def vector_db_comparison():
    """ä¸»æµå‘é‡æ•°æ®åº“å¯¹æ¯”"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šä¸»æµå‘é‡æ•°æ®åº“")
    print("=" * 60)

    print("""
    å‘é‡æ•°æ®åº“å¯¹æ¯”ï¼š
    
    | æ•°æ®åº“      | ç±»å‹     | ç‰¹ç‚¹                      | é€‚ç”¨åœºæ™¯   |
    |------------|---------|--------------------------|-----------|
    | Chroma     | åµŒå…¥å¼   | è½»é‡ã€æ˜“ç”¨ã€PythonåŸç”Ÿ     | å¼€å‘æµ‹è¯•   |
    | FAISS      | åµŒå…¥å¼   | Metaå‡ºå“ã€æ€§èƒ½å¼º           | ç¦»çº¿å¤„ç†   |
    | Pinecone   | äº‘æœåŠ¡   | å…¨æ‰˜ç®¡ã€æ˜“æ‰©å±•             | ç”Ÿäº§ç¯å¢ƒ   |
    | Weaviate   | è‡ªæ‰˜ç®¡   | åŠŸèƒ½ä¸°å¯Œã€æ”¯æŒå¤šæ¨¡æ€        | ä¼ä¸šåº”ç”¨   |
    | Milvus     | è‡ªæ‰˜ç®¡   | é«˜æ€§èƒ½ã€åˆ†å¸ƒå¼             | å¤§è§„æ¨¡åº”ç”¨ |
    | Qdrant     | è‡ªæ‰˜ç®¡   | ç°ä»£åŒ–ã€Rustç¼–å†™           | é«˜æ€§èƒ½éœ€æ±‚ |
    | pgvector   | æ‰©å±•     | PostgreSQLæ‰©å±•            | å·²æœ‰PGç¯å¢ƒ |
    
    é€‰æ‹©å»ºè®®ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    ğŸŸ¢ å¼€å‘æµ‹è¯•ï¼šChromaï¼ˆæœ¬åœ°ï¼‰
    ğŸŸ¡ å¿«é€Ÿä¸Šçº¿ï¼šPineconeï¼ˆäº‘æœåŠ¡ï¼‰
    ğŸ”´ ä¼ä¸šéƒ¨ç½²ï¼šMilvus / Weaviateï¼ˆè‡ªæ‰˜ç®¡ï¼‰
    """)


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šç´¢å¼•ç±»å‹ ====================


def index_types():
    """ç´¢å¼•ç±»å‹ä»‹ç»"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šç´¢å¼•ç±»å‹")
    print("=" * 60)

    print("""
    å¸¸è§ç´¢å¼•ç®—æ³•ï¼š
    
    1. Flatï¼ˆæš´åŠ›æœç´¢ï¼‰
       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       - ç²¾ç¡®æœç´¢ï¼Œæ— ç´¢å¼•
       - é€‚åˆå°æ•°æ®é‡
    
    2. IVFï¼ˆå€’æ’æ–‡ä»¶ç´¢å¼•ï¼‰
       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       - å°†å‘é‡åˆ†ç»„åˆ°èšç±»ä¸­
       - æœç´¢æ—¶åªæŸ¥ç›¸å…³èšç±»
       - nlistï¼šèšç±»æ•°é‡
       - nprobeï¼šæœç´¢çš„èšç±»æ•°
    
    3. HNSWï¼ˆåˆ†å±‚å¯å¯¼èˆªå°ä¸–ç•Œå›¾ï¼‰
       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       - æ„å»ºå¤šå±‚å›¾ç»“æ„
       - æ•ˆç‡é«˜ï¼Œå¬å›ç‡å¥½
       - Mï¼šè¿æ¥æ•°
       - efConstructionï¼šæ„å»ºå‚æ•°
    
    4. PQï¼ˆä¹˜ç§¯é‡åŒ–ï¼‰
       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       - å‹ç¼©å‘é‡å‡å°‘å†…å­˜
       - é€‚åˆè¶…å¤§è§„æ¨¡
    
    æƒè¡¡ï¼š
    â”€â”€â”€â”€â”€â”€
    ç²¾åº¦ â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ é€Ÿåº¦
    å†…å­˜ â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ æ€§èƒ½
    """)


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šLangChain VectorStore æ¥å£ ====================


def vectorstore_interface():
    """LangChain VectorStore æ¥å£"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šLangChain VectorStore æ¥å£")
    print("=" * 60)

    print("""
    VectorStore ç»Ÿä¸€æ¥å£ï¼š
    
    from langchain_core.vectorstores import VectorStore
    
    ä¸»è¦æ–¹æ³•ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    # æ·»åŠ æ–‡æ¡£
    vs.add_documents(documents)
    vs.add_texts(texts, metadatas)
    
    # ç›¸ä¼¼æœç´¢
    vs.similarity_search(query, k=4)
    vs.similarity_search_with_score(query, k=4)
    
    # å¸¦è¿‡æ»¤çš„æœç´¢
    vs.similarity_search(query, filter={"type": "article"})
    
    # MMR æœç´¢ï¼ˆæœ€å¤§è¾¹é™…ç›¸å…³æ€§ï¼‰
    vs.max_marginal_relevance_search(query, k=4)
    
    # è½¬æ¢ä¸º Retriever
    retriever = vs.as_retriever()
    """)


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šå†…å­˜å‘é‡å­˜å‚¨ ====================


def in_memory_store():
    """å†…å­˜å‘é‡å­˜å‚¨æ¼”ç¤º"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šå†…å­˜å‘é‡å­˜å‚¨")
    print("=" * 60)

    try:
        from langchain_google_genai import GoogleGenerativeAIEmbeddings
        from langchain_core.documents import Document
        from langchain_community.vectorstores import DocArrayInMemorySearch

        # åˆ›å»ºæ–‡æ¡£
        docs = [
            Document(page_content="Python æ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€", metadata={"type": "tech"}),
            Document(page_content="æœºå™¨å­¦ä¹ ç”¨äºé¢„æµ‹", metadata={"type": "tech"}),
            Document(page_content="ä»Šå¤©å¤©æ°”æ™´æœ—", metadata={"type": "other"}),
        ]

        # åˆ›å»ºå‘é‡å­˜å‚¨
        embeddings = GoogleGenerativeAIEmbeddings(model="models/gemini-embedding-001")
        vectorstore = DocArrayInMemorySearch.from_documents(docs, embeddings)

        # æœç´¢
        results = vectorstore.similarity_search("AI æŠ€æœ¯", k=2)

        print("ğŸ“Œ æœç´¢ç»“æœï¼š")
        for doc in results:
            print(f"  - {doc.page_content} [{doc.metadata}]")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        print("  æç¤º: pip install docarray")


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šå¯¹æ¯”æœç´¢ç»“æœ
        ä½¿ç”¨ä¸åŒ k å€¼ï¼Œè§‚å¯Ÿæœç´¢ç»“æœå˜åŒ–ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        from langchain_google_genai import GoogleGenerativeAIEmbeddings
        from langchain_community.vectorstores import DocArrayInMemorySearch
        from langchain_core.documents import Document

        docs = [
            Document(page_content="Python ç¼–ç¨‹åŸºç¡€"),
            Document(page_content="æœºå™¨å­¦ä¹ å…¥é—¨"),
            Document(page_content="æ·±åº¦å­¦ä¹ å®æˆ˜"),
            Document(page_content="æ•°æ®ç§‘å­¦æŒ‡å—"),
            Document(page_content="Web å¼€å‘æ•™ç¨‹"),
        ]

        embeddings = GoogleGenerativeAIEmbeddings(model="models/gemini-embedding-001")
        vectorstore = DocArrayInMemorySearch.from_documents(docs, embeddings)

        query = "AI å­¦ä¹ "
        for k in [1, 2, 3, 5]:
            results = vectorstore.similarity_search(query, k=k)
            print(f"k={k}: {[d.page_content for d in results]}")
        ```

    ç»ƒä¹  2ï¼šå…ƒæ•°æ®è¿‡æ»¤
        æ·»åŠ å…ƒæ•°æ®ï¼Œæµ‹è¯•è¿‡æ»¤æœç´¢ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        docs = [
            Document(page_content="Python åŸºç¡€", metadata={"level": "beginner", "year": 2023}),
            Document(page_content="é«˜çº§ Python", metadata={"level": "advanced", "year": 2024}),
            Document(page_content="ML å…¥é—¨", metadata={"level": "beginner", "year": 2024}),
        ]

        vectorstore = DocArrayInMemorySearch.from_documents(docs, embeddings)

        # è¿‡æ»¤åˆå­¦è€…å†…å®¹
        results = vectorstore.similarity_search(
            "ç¼–ç¨‹", k=5, filter={"level": "beginner"}
        )
        print(f"åˆå­¦è€…å†…å®¹: {[d.page_content for d in results]}")
        ```

    ç»ƒä¹  3ï¼šè¯„ä¼°å¬å›
        æ„å»ºæµ‹è¯•é›†ï¼Œè¯„ä¼°æ£€ç´¢å‡†ç¡®ç‡ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        # æ„å»ºæµ‹è¯•é›†
        test_cases = [
            {"query": "Python è¯­è¨€", "expected": "Python ç¼–ç¨‹åŸºç¡€"},
            {"query": "ç¥ç»ç½‘ç»œ", "expected": "æ·±åº¦å­¦ä¹ å®æˆ˜"},
            {"query": "æ•°æ®åˆ†æ", "expected": "æ•°æ®ç§‘å­¦æŒ‡å—"},
        ]

        # è¯„ä¼°
        correct = 0
        for case in test_cases:
            results = vectorstore.similarity_search(case["query"], k=1)
            if results[0].page_content == case["expected"]:
                correct += 1
        
        accuracy = correct / len(test_cases)
        print(f"å‡†ç¡®ç‡: {accuracy:.2%}")
        ```

    æ€è€ƒé¢˜ï¼š
        1. å¦‚ä½•é€‰æ‹©åˆé€‚çš„ k å€¼ï¼Ÿ
           
           âœ… ç­”æ¡ˆï¼š
           - å¤ªå° (k=1)ï¼šå¯èƒ½é”™è¿‡ç›¸å…³æ–‡æ¡£
           - å¤ªå¤§ (k=10+)ï¼šå¢åŠ å™ªå£°ï¼Œå¢åŠ æˆæœ¬
           - æ¨èï¼šk=3-5 èµ·æ­¥ï¼Œæ ¹æ®æ•ˆæœè°ƒæ•´
           - è€ƒè™‘ LLM ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶

        2. ç´¢å¼•æ„å»ºåå¯ä»¥æ›´æ–°å—ï¼Ÿ
           
           âœ… ç­”æ¡ˆï¼š
           - å¤§å¤šæ•°å‘é‡æ•°æ®åº“æ”¯æŒå¢é‡æ›´æ–°
           - add_documents() æ·»åŠ æ–°æ–‡æ¡£
           - delete() åˆ é™¤æ–‡æ¡£
           - éƒ¨åˆ†æ•°æ®åº“éœ€è¦é‡å»ºç´¢å¼•æ‰èƒ½åæ˜ æ›´æ–°
           - Chroma/Pinecone æ”¯æŒå®æ—¶æ›´æ–°
    """)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å‘é‡æ•°æ®åº“æ¦‚è¿°")
    print("=" * 60)

    try:
        vector_db_concept()
        vector_db_comparison()
        index_types()
        vectorstore_interface()
        in_memory_store()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        return

    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š06-chroma-basics.py")
    print("=" * 60)


if __name__ == "__main__":
    main()
