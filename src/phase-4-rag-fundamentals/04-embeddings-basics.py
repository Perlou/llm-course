"""
Embedding æ¨¡å‹
==============

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£ Embedding çš„åŸç†
    2. æŒæ¡ Google Gemini Embedding ä½¿ç”¨
    3. äº†è§£å…¶ä»– Embedding é€‰é¡¹

æ ¸å¿ƒæ¦‚å¿µï¼š
    - Embeddingï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
    - å‘é‡ç›¸ä¼¼åº¦ï¼šä½™å¼¦ç›¸ä¼¼åº¦
    - è¯­ä¹‰æœç´¢ï¼šåŸºäºå‘é‡çš„æ£€ç´¢

å‰ç½®çŸ¥è¯†ï¼š
    - 03-document-transformers.py

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install langchain langchain-google-genai numpy python-dotenv
"""

import os
from dotenv import load_dotenv

load_dotenv()


# ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šEmbedding æ¦‚å¿µ ====================


def embedding_concept():
    """Embedding æ¦‚å¿µ"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šEmbedding æ¦‚å¿µ")
    print("=" * 60)

    print("""
    ä»€ä¹ˆæ˜¯ Embeddingï¼Ÿ
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Embedding å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼å‘é‡ï¼Œä½¿æ–‡æœ¬å¯ä»¥è¿›è¡Œæ•°å­¦è®¡ç®—ã€‚
    
    "äººå·¥æ™ºèƒ½" â†’ [0.12, -0.34, 0.56, ..., 0.78]  (1536ç»´)
    
    å‘é‡ç‰¹ç‚¹ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - è¯­ä¹‰ç›¸ä¼¼çš„æ–‡æœ¬ï¼Œå‘é‡è·ç¦»è¿‘
    - å¯ä»¥ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è¡¡é‡ç›¸å…³æ€§
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        "çŒ«"  â—                              â”‚
    â”‚              â•²                              â”‚
    â”‚               â•² è¿‘                          â”‚
    â”‚                â—  "å°çŒ«"                    â”‚
    â”‚                                             â”‚
    â”‚        "æ±½è½¦" â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â— "é£æœº"         â”‚
    â”‚                     è¿œ                      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)


# ==================== ç¬¬äºŒéƒ¨åˆ†ï¼šGoogle Gemini Embedding ====================


def gemini_embedding():
    """Google Gemini Embedding"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šGoogle Gemini Embedding")
    print("=" * 60)

    try:
        from langchain_google_genai import GoogleGenerativeAIEmbeddings

        embeddings = GoogleGenerativeAIEmbeddings(model="models/gemini-embedding-001")

        # å•æ–‡æœ¬åµŒå…¥
        text = "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ"
        vector = embeddings.embed_query(text)

        print(f"ğŸ“Œ å•æ–‡æœ¬åµŒå…¥ï¼š")
        print(f"  æ–‡æœ¬: {text}")
        print(f"  å‘é‡ç»´åº¦: {len(vector)}")
        print(f"  å‘é‡å‰5ç»´: {vector[:5]}")

        # æ‰¹é‡åµŒå…¥
        texts = ["æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "è‡ªç„¶è¯­è¨€å¤„ç†"]
        vectors = embeddings.embed_documents(texts)

        print(f"\nğŸ“Œ æ‰¹é‡åµŒå…¥ï¼š")
        print(f"  æ–‡æœ¬æ•°: {len(texts)}")
        print(f"  å‘é‡æ•°: {len(vectors)}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šå‘é‡ç›¸ä¼¼åº¦ ====================


def vector_similarity():
    """å‘é‡ç›¸ä¼¼åº¦è®¡ç®—"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šå‘é‡ç›¸ä¼¼åº¦")
    print("=" * 60)

    try:
        import numpy as np
        from langchain_google_genai import GoogleGenerativeAIEmbeddings

        embeddings = GoogleGenerativeAIEmbeddings(model="models/gemini-embedding-001")

        # è®¡ç®—ç›¸ä¼¼åº¦
        def cosine_similarity(v1, v2):
            return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

        texts = [
            "æˆ‘å–œæ¬¢åƒè‹¹æœ",
            "è‹¹æœæ˜¯æˆ‘æœ€çˆ±çš„æ°´æœ",
            "ä»Šå¤©å¤©æ°”çœŸå¥½",
        ]

        vectors = embeddings.embed_documents(texts)

        print("ğŸ“Œ ç›¸ä¼¼åº¦çŸ©é˜µï¼š")
        for i, t1 in enumerate(texts):
            for j, t2 in enumerate(texts):
                if i < j:
                    sim = cosine_similarity(vectors[i], vectors[j])
                    print(f"  '{t1[:10]}...' vs '{t2[:10]}...': {sim:.4f}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬å››éƒ¨åˆ†ï¼šè¯­ä¹‰æœç´¢ ====================


def semantic_search():
    """è¯­ä¹‰æœç´¢æ¼”ç¤º"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šè¯­ä¹‰æœç´¢")
    print("=" * 60)

    try:
        import numpy as np
        from langchain_google_genai import GoogleGenerativeAIEmbeddings

        embeddings = GoogleGenerativeAIEmbeddings(model="models/gemini-embedding-001")

        # æ–‡æ¡£åº“
        documents = [
            "Python æ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€",
            "æœºå™¨å­¦ä¹ éœ€è¦å¤§é‡æ•°æ®",
            "æ·±åº¦å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯",
            "è‡ªç„¶è¯­è¨€å¤„ç†ç”¨äºç†è§£æ–‡æœ¬",
        ]

        # æŸ¥è¯¢
        query = "AI æŠ€æœ¯"

        # åµŒå…¥
        doc_vectors = embeddings.embed_documents(documents)
        query_vector = embeddings.embed_query(query)

        # è®¡ç®—ç›¸ä¼¼åº¦
        def cosine_similarity(v1, v2):
            return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

        similarities = [cosine_similarity(query_vector, dv) for dv in doc_vectors]

        # æ’åº
        ranked = sorted(zip(documents, similarities), key=lambda x: x[1], reverse=True)

        print(f"ğŸ“Œ æŸ¥è¯¢: '{query}'")
        print("\næœç´¢ç»“æœï¼ˆæŒ‰ç›¸ä¼¼åº¦æ’åºï¼‰ï¼š")
        for doc, sim in ranked:
            print(f"  [{sim:.4f}] {doc}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


# ==================== ç¬¬äº”éƒ¨åˆ†ï¼šå…¶ä»– Embedding æ¨¡å‹ ====================


def other_embeddings():
    """å…¶ä»– Embedding æ¨¡å‹"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šå…¶ä»– Embedding æ¨¡å‹")
    print("=" * 60)

    print("""
    å¸¸ç”¨ Embedding æ¨¡å‹ï¼š
    
    | æ¨¡å‹               | ç»´åº¦   | ç‰¹ç‚¹                    |
    |-------------------|-------|------------------------|
    | Gemini embedding  | 768   | å…è´¹ï¼Œæ•ˆæœå¥½             |
    | OpenAI ada-002    | 1536  | æ•ˆæœå¥½ï¼Œä»˜è´¹             |
    | HuggingFace BGE   | 1024  | å¼€æºï¼Œä¸­æ–‡æ•ˆæœå¥½          |
    | Sentence-BERT     | 768   | å¼€æºï¼Œé€šç”¨               |
    | Cohere            | 1024  | ä»˜è´¹ï¼Œå¤šè¯­è¨€             |
    
    ä½¿ç”¨ HuggingFace æ¨¡å‹ç¤ºä¾‹ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    from langchain_community.embeddings import HuggingFaceEmbeddings
    
    # ä½¿ç”¨ BGE ä¸­æ–‡æ¨¡å‹
    embeddings = HuggingFaceEmbeddings(
        model_name="BAAI/bge-small-zh"
    )
    
    vector = embeddings.embed_query("ä½ å¥½ä¸–ç•Œ")
    """)


# ==================== ç¬¬å…­éƒ¨åˆ†ï¼šç»ƒä¹ ä¸æ€è€ƒ ====================


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šç›¸ä¼¼åº¦å®éªŒ
        æµ‹è¯•åŒä¹‰è¯ã€åä¹‰è¯çš„å‘é‡ç›¸ä¼¼åº¦ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        import numpy as np
        from langchain_google_genai import GoogleGenerativeAIEmbeddings

        embeddings = GoogleGenerativeAIEmbeddings(model="models/gemini-embedding-001")

        def cosine_similarity(v1, v2):
            return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

        # åŒä¹‰è¯æµ‹è¯•
        synonyms = [("é«˜å…´", "å¼€å¿ƒ"), ("å¿«é€Ÿ", "è¿…é€Ÿ"), ("ç¾ä¸½", "æ¼‚äº®")]
        # åä¹‰è¯æµ‹è¯•
        antonyms = [("é«˜å…´", "æ‚²ä¼¤"), ("å¿«é€Ÿ", "ç¼“æ…¢"), ("ç¾ä¸½", "ä¸‘é™‹")]

        for word1, word2 in synonyms + antonyms:
            v1 = embeddings.embed_query(word1)
            v2 = embeddings.embed_query(word2)
            sim = cosine_similarity(v1, v2)
            print(f"{word1} vs {word2}: {sim:.4f}")
        # åŒä¹‰è¯ç›¸ä¼¼åº¦é€šå¸¸ > 0.8ï¼Œåä¹‰è¯ç›¸ä¼¼åº¦è¾ƒä½
        ```

    ç»ƒä¹  2ï¼šå¤šè¯­è¨€æµ‹è¯•
        æµ‹è¯•ä¸­è‹±æ–‡ç›¸åŒå«ä¹‰æ–‡æœ¬çš„ç›¸ä¼¼åº¦ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        pairs = [
            ("äººå·¥æ™ºèƒ½", "artificial intelligence"),
            ("æˆ‘çˆ±ç¼–ç¨‹", "I love programming"),
            ("ä»Šå¤©å¤©æ°”å¾ˆå¥½", "The weather is nice today"),
        ]

        for zh, en in pairs:
            v_zh = embeddings.embed_query(zh)
            v_en = embeddings.embed_query(en)
            sim = cosine_similarity(v_zh, v_en)
            print(f"{zh} vs {en}: {sim:.4f}")
        # å¤šè¯­è¨€æ¨¡å‹é€šå¸¸èƒ½è¾¾åˆ° 0.7+ çš„ç›¸ä¼¼åº¦
        ```

    ç»ƒä¹  3ï¼šæœ¬åœ°æ¨¡å‹
        ä½¿ç”¨ HuggingFaceEmbeddings è¿è¡Œæœ¬åœ°æ¨¡å‹ã€‚

        âœ… å‚è€ƒç­”æ¡ˆï¼š
        ```python
        from langchain_community.embeddings import HuggingFaceEmbeddings

        # ä½¿ç”¨ BGE ä¸­æ–‡æ¨¡å‹
        local_embeddings = HuggingFaceEmbeddings(
            model_name="BAAI/bge-small-zh-v1.5",
            model_kwargs={"device": "cpu"},  # æˆ– "cuda"
            encode_kwargs={"normalize_embeddings": True}
        )

        text = "äººå·¥æ™ºèƒ½æ”¹å˜ä¸–ç•Œ"
        vector = local_embeddings.embed_query(text)
        print(f"å‘é‡ç»´åº¦: {len(vector)}")
        ```

    æ€è€ƒé¢˜ï¼š
        1. Embedding ç»´åº¦è¶Šé«˜è¶Šå¥½å—ï¼Ÿ
           
           âœ… ç­”æ¡ˆï¼š
           - ä¸ä¸€å®šï¼éœ€è¦æƒè¡¡ï¼š
           - é«˜ç»´åº¦ï¼šè¡¨è¾¾èƒ½åŠ›å¼ºï¼Œä½†å­˜å‚¨å’Œè®¡ç®—æˆæœ¬é«˜
           - ä½ç»´åº¦ï¼šæ•ˆç‡é«˜ï¼Œä½†å¯èƒ½æŸå¤±ä¿¡æ¯
           - 768-1536 ç»´æ˜¯å¸¸è§é€‰æ‹©
           - å…³é”®æ˜¯æ¨¡å‹è®­ç»ƒè´¨é‡ï¼Œè€Œéç»´åº¦

        2. ä¸åŒé¢†åŸŸçš„æ–‡æœ¬å¦‚ä½•é€‰æ‹©æ¨¡å‹ï¼Ÿ
           
           âœ… ç­”æ¡ˆï¼š
           - é€šç”¨æ–‡æœ¬ï¼šGemini/OpenAI é€šç”¨æ¨¡å‹
           - ä¸­æ–‡æ–‡æœ¬ï¼šBGE-zhã€M3E ç­‰ä¸­æ–‡æ¨¡å‹
           - ä»£ç ï¼šCodeBERTã€StarCoder ç­‰
           - åŒ»å­¦/æ³•å¾‹ï¼šé¢†åŸŸä¸“ç”¨æ¨¡å‹
           - å»ºè®®ï¼šæµ‹è¯•å¤šä¸ªæ¨¡å‹ï¼Œé€‰æ‹©æ•ˆæœæœ€å¥½çš„
    """)


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Embedding æ¨¡å‹")
    print("=" * 60)

    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯ï¼šæœªè®¾ç½® GOOGLE_API_KEY")
        return

    try:
        embedding_concept()
        gemini_embedding()
        vector_similarity()
        semantic_search()
        other_embeddings()
        exercises()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        return

    print("\n" + "=" * 60)
    print("âœ… è¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š05-vector-stores-intro.py")
    print("=" * 60)


if __name__ == "__main__":
    main()
