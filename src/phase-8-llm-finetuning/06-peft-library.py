"""
PEFT åº“ä½¿ç”¨
===========

å­¦ä¹ ç›®æ ‡ï¼š
    1. æŒæ¡ PEFT åº“çš„ä½¿ç”¨
    2. äº†è§£å¤šç§ PEFT æ–¹æ³•
    3. å­¦ä¼šä¿å­˜å’ŒåŠ è½½ PEFT æ¨¡å‹

æ ¸å¿ƒæ¦‚å¿µï¼š
    - PEFT (Parameter-Efficient Fine-Tuning)
    - Adapters
    - Prefix Tuning

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install peft transformers
"""

import os
from dotenv import load_dotenv

load_dotenv()


def peft_overview():
    """PEFT æ¦‚è¿°"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šPEFT åº“æ¦‚è¿°")
    print("=" * 60)

    print("""
    PEFT: Parameter-Efficient Fine-Tuning
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    HuggingFace å¼€å‘çš„ç»Ÿä¸€ PEFT æ¡†æ¶ï¼Œæ”¯æŒå¤šç§æ–¹æ³•ã€‚
    
    
    æ”¯æŒçš„æ–¹æ³•
    â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    PEFT æ–¹æ³•                             â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                         â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚   â”‚  LoRA   â”‚  â”‚ AdaLoRA â”‚  â”‚  IAÂ³    â”‚  â”‚Prefix   â”‚   â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚Tuning   â”‚   â”‚
    â”‚                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚   â”‚ Prompt  â”‚  â”‚  P-     â”‚  â”‚ (IA)Â³   â”‚  â”‚LoHa/    â”‚   â”‚
    â”‚   â”‚ Tuning  â”‚  â”‚ Tuning  â”‚  â”‚         â”‚  â”‚LoKR     â”‚   â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    
    æ–¹æ³•å¯¹æ¯”
    â”€â”€â”€â”€â”€â”€â”€
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    æ–¹æ³•     â”‚  å‚æ•°æ•ˆç‡   â”‚    æ•ˆæœ    â”‚   å¤æ‚åº¦   â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚   LoRA      â”‚   é«˜       â”‚    å¥½      â”‚    ä½      â”‚
    â”‚   AdaLoRA   â”‚   æ›´é«˜     â”‚    å¥½      â”‚    ä¸­      â”‚
    â”‚   IAÂ³       â”‚   æœ€é«˜     â”‚    ä¸€èˆ¬    â”‚    ä½      â”‚
    â”‚   Prefix    â”‚   é«˜       â”‚    ä¸€èˆ¬    â”‚    ä¸­      â”‚
    â”‚   Prompt    â”‚   æœ€é«˜     â”‚    ä¸€èˆ¬    â”‚    ä½      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)


def lora_adapter():
    """LoRA Adapter"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šLoRA Adapter")
    print("=" * 60)

    code_example = """
    from peft import LoraConfig, get_peft_model, TaskType
    from transformers import AutoModelForCausalLM

    # åŠ è½½æ¨¡å‹
    model = AutoModelForCausalLM.from_pretrained("model_name")

    # LoRA é…ç½®
    config = LoraConfig(
        task_type=TaskType.CAUSAL_LM,
        r=8,
        lora_alpha=16,
        lora_dropout=0.1,
        target_modules=["q_proj", "v_proj"],
    )

    # åº”ç”¨ LoRA
    peft_model = get_peft_model(model, config)
    """

    print("ğŸ“Œ LoRA é…ç½®ç¤ºä¾‹ï¼š")
    print(code_example)


def other_methods():
    """å…¶ä»– PEFT æ–¹æ³•"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šå…¶ä»– PEFT æ–¹æ³•")
    print("=" * 60)

    print("""
    1. Prefix Tuning
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    åœ¨æ¯å±‚æ·»åŠ å¯è®­ç»ƒçš„å‰ç¼€å‘é‡
    """)

    prefix_code = """
    from peft import PrefixTuningConfig

    config = PrefixTuningConfig(
        task_type="CAUSAL_LM",
        num_virtual_tokens=20,  # å‰ç¼€é•¿åº¦
        prefix_projection=True,
    )
    """
    print(prefix_code)

    print("""
    2. Prompt Tuning
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    åªåœ¨è¾“å…¥åµŒå…¥å±‚æ·»åŠ å¯è®­ç»ƒçš„è½¯æç¤º
    """)

    prompt_code = """
    from peft import PromptTuningConfig

    config = PromptTuningConfig(
        task_type="CAUSAL_LM",
        num_virtual_tokens=8,
        prompt_tuning_init="TEXT",      # åˆå§‹åŒ–æ–¹å¼
        prompt_tuning_init_text="åˆ†ç±»è¿™æ®µæ–‡æœ¬çš„æƒ…æ„Ÿï¼š",
    )
    """
    print(prompt_code)

    print("""
    3. IAÂ³ (Infused Adapter by Inhibiting and Amplifying)
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    é€šè¿‡å­¦ä¹ ç¼©æ”¾å‘é‡è°ƒæ•´æ¿€æ´»å€¼
    """)

    ia3_code = """
    from peft import IA3Config

    config = IA3Config(
        task_type="CAUSAL_LM",
        target_modules=["k_proj", "v_proj", "down_proj"],
        feedforward_modules=["down_proj"],
    )
    """
    print(ia3_code)


def model_management():
    """æ¨¡å‹ç®¡ç†"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šæ¨¡å‹ä¿å­˜ä¸åŠ è½½")
    print("=" * 60)

    print("""
    ä¿å­˜å’ŒåŠ è½½ PEFT æ¨¡å‹
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    """)

    code_example = """
    from peft import PeftModel, PeftConfig
    from transformers import AutoModelForCausalLM

    # ============ ä¿å­˜ ============

    # 1. åªä¿å­˜ adapter æƒé‡ (æ¨è)
    peft_model.save_pretrained("./adapter_weights")
    # ä¿å­˜çš„æ–‡ä»¶:
    # - adapter_config.json
    # - adapter_model.safetensors

    # 2. åˆå¹¶åä¿å­˜å®Œæ•´æ¨¡å‹
    merged_model = peft_model.merge_and_unload()
    merged_model.save_pretrained("./merged_model")


    # ============ åŠ è½½ ============

    # 1. åŠ è½½ adapter
    base_model = AutoModelForCausalLM.from_pretrained("base_model_name")
    peft_model = PeftModel.from_pretrained(base_model, "./adapter_weights")

    # 2. æŸ¥çœ‹ adapter é…ç½®
    config = PeftConfig.from_pretrained("./adapter_weights")
    print(config)

    # 3. ç¦ç”¨ adapter (ä½¿ç”¨åŸå§‹æ¨¡å‹)
    with peft_model.disable_adapter():
        output = peft_model.generate(...)

    # 4. å¤š adapter ç®¡ç†
    peft_model.load_adapter("./adapter2", adapter_name="task2")
    peft_model.set_adapter("task2")  # åˆ‡æ¢ adapter
    """

    print(code_example)


def multi_adapter():
    """å¤š Adapter"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šå¤š Adapter ç®¡ç†")
    print("=" * 60)

    print("""
    å¤šä»»åŠ¡ Adapter
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   Base Model (å†»ç»“)                      â”‚
    â”‚                                                         â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
    â”‚   â”‚Adapter Aâ”‚   â”‚Adapter Bâ”‚   â”‚Adapter Câ”‚              â”‚
    â”‚   â”‚ ç¿»è¯‘    â”‚   â”‚ æ‘˜è¦    â”‚   â”‚ é—®ç­”    â”‚              â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
    â”‚        â”‚             â”‚             â”‚                    â”‚
    â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
    â”‚                      â”‚                                  â”‚
    â”‚              æ¨ç†æ—¶åŠ¨æ€åˆ‡æ¢                               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)

    multi_code = """
    # è®­ç»ƒå¤šä¸ª adapter
    model.add_adapter(lora_config, adapter_name="translate")
    model.add_adapter(lora_config, adapter_name="summarize")

    # åˆ‡æ¢ adapter
    model.set_adapter("translate")
    output1 = model.generate(...)

    model.set_adapter("summarize")
    output2 = model.generate(...)

    # åˆå¹¶å¤šä¸ª adapter
    model.add_weighted_adapter(
        adapters=["translate", "summarize"],
        weights=[0.5, 0.5],
        adapter_name="combined",
    )
    """
    print(multi_code)


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šå¯¹æ¯”å®éªŒ
        æ¯”è¾ƒ LoRA, Prefix Tuning, IAÂ³ æ•ˆæœ
    
    ç»ƒä¹  2ï¼šå¤š Adapter
        ä¸ºä¸åŒä»»åŠ¡è®­ç»ƒå¤šä¸ª adapter
    
    ç»ƒä¹  3ï¼šAdapter åˆå¹¶
        å®éªŒä¸åŒæƒé‡çš„ adapter åˆå¹¶
    
    æ€è€ƒé¢˜ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€
    1. å¦‚ä½•é€‰æ‹©é€‚åˆä»»åŠ¡çš„ PEFT æ–¹æ³•ï¼Ÿ
    2. å¤š Adapter çš„åº”ç”¨åœºæ™¯ï¼Ÿ
    """)


def main():
    print("ğŸ“¦ PEFT åº“ä½¿ç”¨")
    print("=" * 60)
    peft_overview()
    lora_adapter()
    other_methods()
    model_management()
    multi_adapter()
    exercises()
    print("\nâœ… è¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š07-supervised-finetuning.py")


if __name__ == "__main__":
    main()
