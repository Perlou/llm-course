"""
æ¨¡å‹åˆå¹¶
========

å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£æ¨¡å‹åˆå¹¶çš„æ¦‚å¿µ
    2. æŒæ¡ LoRA æƒé‡åˆå¹¶
    3. äº†è§£å¤šæ¨¡å‹åˆå¹¶æŠ€æœ¯

æ ¸å¿ƒæ¦‚å¿µï¼š
    - Merge and Unload
    - æ¨¡å‹èåˆ
    - TIES/DARE Merge

ç¯å¢ƒè¦æ±‚ï¼š
    - pip install peft transformers
"""

import os
from dotenv import load_dotenv

load_dotenv()


def merge_overview():
    """åˆå¹¶æ¦‚è¿°"""
    print("=" * 60)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šæ¨¡å‹åˆå¹¶æ¦‚è¿°")
    print("=" * 60)

    print("""
    ä¸ºä»€ä¹ˆéœ€è¦æ¨¡å‹åˆå¹¶ï¼Ÿ
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    1. æ¨ç†æ•ˆç‡
       - åˆå¹¶ååªéœ€åŠ è½½ä¸€ä¸ªæ¨¡å‹
       - æ— é¢å¤–è®¡ç®—å¼€é”€
    
    2. èƒ½åŠ›ç»„åˆ
       - åˆå¹¶å¤šä¸ªä¸“ä¸šæ¨¡å‹
       - è·å¾—ç»¼åˆèƒ½åŠ›
    
    3. éƒ¨ç½²ç®€åŒ–
       - æ— éœ€ç®¡ç†å¤šä¸ª adapter
       - ç»Ÿä¸€æ¨¡å‹æ ¼å¼
    
    
    åˆå¹¶ç±»å‹
    â”€â”€â”€â”€â”€â”€â”€
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    æ¨¡å‹åˆå¹¶ç±»å‹                          â”‚
    â”‚                                                         â”‚
    â”‚   1. LoRA åˆå¹¶                                          â”‚
    â”‚      Base + LoRA â†’ Merged Model                         â”‚
    â”‚                                                         â”‚
    â”‚   2. å¤š Adapter åˆå¹¶                                    â”‚
    â”‚      Base + LoRA1 + LoRA2 â†’ Combined Model              â”‚
    â”‚                                                         â”‚
    â”‚   3. å¤šæ¨¡å‹èåˆ                                         â”‚
    â”‚      Model A + Model B â†’ Hybrid Model                   â”‚
    â”‚                                                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)


def lora_merge():
    """LoRA åˆå¹¶"""
    print("\n" + "=" * 60)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šLoRA æƒé‡åˆå¹¶")
    print("=" * 60)

    print("""
    LoRA åˆå¹¶åŸç†
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    W' = W + BA
    
    åˆå¹¶åå¾—åˆ°ä¸€ä¸ªæ ‡å‡†æ¨¡å‹ï¼Œæ²¡æœ‰é¢å¤–çš„ adapter æƒé‡ã€‚
    """)

    code_example = """
    from peft import PeftModel
    from transformers import AutoModelForCausalLM, AutoTokenizer
    import torch

    # 1. åŠ è½½åŸºç¡€æ¨¡å‹
    base_model = AutoModelForCausalLM.from_pretrained(
        "meta-llama/Llama-2-7b-hf",
        torch_dtype=torch.float16,
        device_map="auto",
    )

    # 2. åŠ è½½ PEFT æ¨¡å‹
    peft_model = PeftModel.from_pretrained(
        base_model,
        "./lora_adapter",
    )

    # 3. åˆå¹¶æƒé‡
    merged_model = peft_model.merge_and_unload()

    # 4. ä¿å­˜åˆå¹¶åçš„æ¨¡å‹
    merged_model.save_pretrained("./merged_model")

    # åŒæ—¶ä¿å­˜ tokenizer
    tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-2-7b-hf")
    tokenizer.save_pretrained("./merged_model")

    # 5. éªŒè¯åˆå¹¶ç»“æœ
    # åŠ è½½åˆå¹¶æ¨¡å‹
    loaded_model = AutoModelForCausalLM.from_pretrained("./merged_model")
    """

    print(code_example)


def multi_adapter_merge():
    """å¤š Adapter åˆå¹¶"""
    print("\n" + "=" * 60)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šå¤š Adapter åˆå¹¶")
    print("=" * 60)

    print("""
    åŠ æƒåˆå¹¶å¤šä¸ª Adapter
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    åœºæ™¯ï¼šç»„åˆå¤šä¸ªä»»åŠ¡ç‰¹å®šçš„ adapter
    """)

    code_example = """
    from peft import PeftModel

    # åŠ è½½åŸºç¡€æ¨¡å‹
    model = AutoModelForCausalLM.from_pretrained("base_model")

    # åŠ è½½ç¬¬ä¸€ä¸ª adapter
    model = PeftModel.from_pretrained(model, "./adapter_translate")

    # åŠ è½½ç¬¬äºŒä¸ª adapter
    model.load_adapter("./adapter_summarize", adapter_name="summarize")

    # æ–¹æ³• 1: åˆ‡æ¢ä½¿ç”¨
    model.set_adapter("default")  # translate
    output1 = model.generate(...)

    model.set_adapter("summarize")
    output2 = model.generate(...)

    # æ–¹æ³• 2: åŠ æƒåˆå¹¶
    model.add_weighted_adapter(
        adapters=["default", "summarize"],
        weights=[0.6, 0.4],
        adapter_name="combined",
        combination_type="linear",  # æˆ– "svd", "ties"
    )
    model.set_adapter("combined")

    # æ–¹æ³• 3: åˆå¹¶å¹¶å¸è½½
    merged = model.merge_and_unload()
    """

    print(code_example)


def advanced_merge():
    """é«˜çº§åˆå¹¶æŠ€æœ¯"""
    print("\n" + "=" * 60)
    print("ç¬¬å››éƒ¨åˆ†ï¼šé«˜çº§åˆå¹¶æŠ€æœ¯")
    print("=" * 60)

    print("""
    æ¨¡å‹èåˆæŠ€æœ¯
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    1. çº¿æ€§æ’å€¼ (Linear Interpolation)
       W_merged = Î± Ã— W_A + (1-Î±) Ã— W_B
    
    2. SLERP (Spherical Linear Interpolation)
       å¯¹æƒé‡å‘é‡è¿›è¡Œçƒé¢æ’å€¼
    
    3. TIES Merge
       - ä¿ç•™æœ€é‡è¦çš„å‚æ•°å˜åŒ–
       - è§£å†³ç¬¦å·å†²çª
       - æ•ˆæœé€šå¸¸æ›´å¥½
    
    4. DARE (Drop And REscale)
       - éšæœºä¸¢å¼ƒéƒ¨åˆ†å˜åŒ–
       - é‡æ–°ç¼©æ”¾å‰©ä½™å˜åŒ–
    """)

    merge_code = '''
    # ä½¿ç”¨ mergekit è¿›è¡Œé«˜çº§åˆå¹¶
    # pip install mergekit

    # YAML é…ç½®æ–‡ä»¶ (merge_config.yaml):
    """
    models:
      - model: ./model_a
        parameters:
          weight: 0.6
      - model: ./model_b
        parameters:
          weight: 0.4
    merge_method: ties  # æˆ– linear, slerp, dare_ties
    base_model: meta-llama/Llama-2-7b-hf
    parameters:
      density: 0.5
      normalize: true
    dtype: float16
    """

    # å‘½ä»¤è¡Œæ‰§è¡Œ
    # mergekit-yaml merge_config.yaml ./merged_output
    '''

    print(merge_code)


def merge_tips():
    """åˆå¹¶æŠ€å·§"""
    print("\n" + "=" * 60)
    print("ç¬¬äº”éƒ¨åˆ†ï¼šåˆå¹¶æœ€ä½³å®è·µ")
    print("=" * 60)

    print("""
    æœ€ä½³å®è·µ
    â”€â”€â”€â”€â”€â”€â”€
    
    1. åˆå¹¶å‰
       - ç¡®ä¿åŸºç¡€æ¨¡å‹å®Œå…¨ç›¸åŒ
       - æ£€æŸ¥ adapter å…¼å®¹æ€§
       - å¤‡ä»½åŸå§‹æ¨¡å‹
    
    2. æƒé‡é€‰æ‹©
       - æ ¹æ®ä»»åŠ¡é‡è¦æ€§è°ƒæ•´æƒé‡
       - å¯ä»¥è¿›è¡Œæ¶ˆèå®éªŒ
    
    3. éªŒè¯åˆå¹¶
       - åœ¨å¤šä¸ªä»»åŠ¡ä¸Šæµ‹è¯•
       - æ£€æŸ¥æ˜¯å¦æœ‰èƒ½åŠ›ä¸¢å¤±
    
    4. ç²¾åº¦æ³¨æ„
       - åˆå¹¶æ—¶ä¿æŒé«˜ç²¾åº¦
       - é‡åŒ–åœ¨åˆå¹¶åè¿›è¡Œ
    
    
    å¸¸è§é—®é¢˜
    â”€â”€â”€â”€â”€â”€â”€
    
    Q: åˆå¹¶åæ¨¡å‹å˜å¤§äº†ï¼Ÿ
    A: æ­£å¸¸ï¼Œå› ä¸º adapter æƒé‡è¢«èå…¥ã€‚
    
    Q: èƒ½åŠ›å‘ç”Ÿå†²çªæ€ä¹ˆåŠï¼Ÿ
    A: è°ƒæ•´æƒé‡æˆ–ä½¿ç”¨ TIES åˆå¹¶ã€‚
    
    Q: QLoRA æ¨¡å‹èƒ½åˆå¹¶å—ï¼Ÿ
    A: éœ€è¦å…ˆåé‡åŒ–åŸºç¡€æ¨¡å‹ã€‚
    """)


def exercises():
    """ç»ƒä¹ é¢˜"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹ ä¸æ€è€ƒ")
    print("=" * 60)

    print("""
    ç»ƒä¹  1ï¼šLoRA åˆå¹¶
        è®­ç»ƒä¸€ä¸ª LoRA å¹¶åˆå¹¶åˆ°åŸºç¡€æ¨¡å‹
    
    ç»ƒä¹  2ï¼šå¤š Adapter å®éªŒ
        æ¯”è¾ƒä¸åŒæƒé‡çš„åˆå¹¶æ•ˆæœ
    
    ç»ƒä¹  3ï¼šTIES åˆå¹¶
        ä½¿ç”¨ mergekit è¿›è¡Œé«˜çº§åˆå¹¶
    
    æ€è€ƒé¢˜ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€
    1. åˆå¹¶åèƒ½å¦æ¢å¤åŸå§‹ adapterï¼Ÿ
    2. å¦‚ä½•è‡ªåŠ¨é€‰æ‹©æœ€ä½³åˆå¹¶æƒé‡ï¼Ÿ
    """)


def main():
    print("ğŸ”— æ¨¡å‹åˆå¹¶")
    print("=" * 60)
    merge_overview()
    lora_merge()
    multi_adapter_merge()
    advanced_merge()
    merge_tips()
    exercises()
    print("\nâœ… è¯¾ç¨‹å®Œæˆï¼ä¸‹ä¸€æ­¥ï¼š10-finetuning-evaluation.py")


if __name__ == "__main__":
    main()
