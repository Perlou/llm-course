"""
LLM æ¨ç†æœåŠ¡
==============

ç”Ÿäº§çº§ LLM æ¨ç† API æœåŠ¡
"""

from contextlib import asynccontextmanager
from fastapi import FastAPI
from rich.console import Console

from app.config import settings
from app.api import router
from app.middleware import LoggingMiddleware, CORSMiddleware
from app.engine import get_engine


console = Console()


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    console.print("\n[bold blue]ğŸš€ LLM æ¨ç†æœåŠ¡[/bold blue]\n")
    console.print(f"æ¨¡å‹: {settings.model_name}")
    console.print(f"å¼•æ“: {settings.inference_engine}")
    console.print("æ­£åœ¨åŠ è½½æ¨¡å‹...")

    # é¢„åŠ è½½æ¨¡å‹
    try:
        engine = get_engine()
        console.print("[green]âœ… æ¨¡å‹åŠ è½½å®Œæˆ[/green]")
    except Exception as e:
        console.print(f"[red]æ¨¡å‹åŠ è½½å¤±è´¥: {e}[/red]")

    console.print(f"\næœåŠ¡åœ°å€: http://{settings.host}:{settings.port}")
    console.print("API æ–‡æ¡£: http://{settings.host}:{settings.port}/docs\n")

    yield

    console.print("\n[dim]æœåŠ¡å…³é—­[/dim]")


# åˆ›å»ºåº”ç”¨
app = FastAPI(
    title="LLM æ¨ç†æœåŠ¡",
    description="ç”Ÿäº§çº§ LLM æ¨ç† APIï¼Œå…¼å®¹ OpenAI æ¥å£",
    version="1.0.0",
    lifespan=lifespan,
)

# æ·»åŠ ä¸­é—´ä»¶
app.add_middleware(LoggingMiddleware)
app.add_middleware(CORSMiddleware)

# æ³¨å†Œè·¯ç”±
app.include_router(router)


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "service": "LLM æ¨ç†æœåŠ¡",
        "version": "1.0.0",
        "model": settings.model_name,
        "docs": "/docs",
    }


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "main:app",
        host=settings.host,
        port=settings.port,
        workers=settings.workers,
        reload=False,
    )
