# 模型配置
MODEL_NAME=Qwen/Qwen2.5-0.5B-Instruct
MODEL_PATH=

# 推理引擎: transformers / vllm / tgi
INFERENCE_ENGINE=transformers

# 服务配置
HOST=0.0.0.0
PORT=8000
WORKERS=1

# 推理参数
MAX_NEW_TOKENS=512
TEMPERATURE=0.7
TOP_P=0.9

# 性能配置
MAX_BATCH_SIZE=8
MAX_CONCURRENT_REQUESTS=100
TIMEOUT_SECONDS=60

# 量化
LOAD_IN_8BIT=false
LOAD_IN_4BIT=false

# GPU
DEVICE_MAP=auto
