"""
æ¨ç†æµ‹è¯•è„šæœ¬
æµ‹è¯•å¾®è°ƒåçš„æ¨¡å‹
"""

import argparse
import os
import sys

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from rich.console import Console
from rich.panel import Panel
from rich.markdown import Markdown

from scripts.model_utils import generate_response


console = Console()


def load_model(model_path: str, use_lora: bool = False, adapter_path: str = None):
    """åŠ è½½æ¨¡å‹"""
    import torch
    from transformers import AutoModelForCausalLM, AutoTokenizer

    console.print(f"åŠ è½½æ¨¡å‹: {model_path}")

    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)

    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32

    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch_dtype,
        device_map="auto",
        trust_remote_code=True,
    )

    if use_lora and adapter_path:
        from peft import PeftModel

        console.print(f"åŠ è½½ LoRA é€‚é…å™¨: {adapter_path}")
        model = PeftModel.from_pretrained(model, adapter_path)

    return model, tokenizer


def format_prompt(message: str) -> str:
    """æ ¼å¼åŒ–æç¤º"""
    return f"<|im_start|>user\n{message}<|im_end|>\n<|im_start|>assistant\n"


def main():
    parser = argparse.ArgumentParser(description="æ¨¡å‹æ¨ç†æµ‹è¯•")
    parser.add_argument("--model", "-m", required=True, help="æ¨¡å‹è·¯å¾„")
    parser.add_argument("--adapter", "-a", help="LoRA é€‚é…å™¨è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--max-tokens", type=int, default=512, help="æœ€å¤§ç”Ÿæˆé•¿åº¦")
    parser.add_argument("--temperature", type=float, default=0.7, help="æ¸©åº¦")

    args = parser.parse_args()

    console.print("\n[bold blue]ğŸ§ª æ¨¡å‹æ¨ç†æµ‹è¯•[/bold blue]\n")

    # åŠ è½½æ¨¡å‹
    use_lora = args.adapter is not None
    model, tokenizer = load_model(args.model, use_lora, args.adapter)

    console.print("[green]âœ… æ¨¡å‹åŠ è½½å®Œæˆ[/green]\n")
    console.print("è¾“å…¥é—®é¢˜è¿›è¡Œæµ‹è¯•ï¼Œè¾“å…¥ /quit é€€å‡º\n")
    console.print("â”" * 50)

    while True:
        try:
            user_input = console.input("\n[bold blue]é—®:[/bold blue] ").strip()

            if not user_input:
                continue

            if user_input.lower() in ["/quit", "/exit", "/q"]:
                console.print("\nå†è§ï¼")
                break

            # ç”Ÿæˆå“åº”
            prompt = format_prompt(user_input)

            with console.status("ç”Ÿæˆä¸­..."):
                response = generate_response(
                    model=model,
                    tokenizer=tokenizer,
                    prompt=prompt,
                    max_new_tokens=args.max_tokens,
                    temperature=args.temperature,
                )

            # æ˜¾ç¤ºå“åº”
            console.print("\n[bold green]ç­”:[/bold green]")
            console.print(Panel(Markdown(response), border_style="green"))

        except KeyboardInterrupt:
            console.print("\n\nå†è§ï¼")
            break
        except Exception as e:
            console.print(f"[red]é”™è¯¯: {e}[/red]")


if __name__ == "__main__":
    main()
